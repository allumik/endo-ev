---
title: "Extracellular Vesicle Spatiotemporal Deconvolution Recapitulates the Dynamic Nature of the Human Endometrium"
format:
  html:
    code-fold: true
    code-tools: true
    embed-resources: true
    self-contained-math: true
jupyter: python3
---

This document contains the condensed form of analysis, figures and some more technical parts of the final article.

> **This** is a commentary text, it will not be included in the final report.

This is a citation as a [simple link](doi:10.1101/2023.11.03.564728), I will collect the links later on and put them in the references section.

# Prelude

## Load data and environment

Setup the environment and import dependencies.

1. Load the dependencies, set up multithreading.
2. Set color groups and values.

```{python}
#| output: false

import re
import glob
import warnings
import numpy as np
import pandas as pd
import anndata as an
import scanpy as sc
import squidpy as sq
import altair as alt
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as mpatches
from os import getenv
from pathlib import Path
from dotenv import load_dotenv
from IPython.display import HTML
from sklearn.decomposition import PCA
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
from sklearn.preprocessing import normalize

## import the functions used in this report (got too long to include them in the report)
try: from analysis.helpers.deconvo_functions import *
except ImportError: from helpers.deconvo_functions import *

## import the functions used in this report (got too long to include them in the report)
try: from analysis.helpers.projection_functions import *
except ImportError: from helpers.projection_functions import *

## load the environment variables from the .env file
load_dotenv()
if getenv("DATA_FOLDER") is None:
  load_dotenv(Path.cwd() / ".env")

proj_folder = getenv("PROJ_FOLDER")
anndata_folder = getenv("ANNDATA_FOLDER")
atlas_folder = getenv("ATLAS_FOLDER")
data_folder = getenv("DATA_FOLDER")
st_folder = getenv("ST_FOLDER")
raw_data_folder = getenv("RAW_DATA_FOLDER")

# some other dataset locations
snapshot_an_loc = Path(data_folder).expanduser() / "sc_deconv_snapshot.h5ad"
ccht_data_loc = Path(data_folder).expanduser() / "filtered" / "annot_raw.feather"
comb_data_loc = Path(data_folder).expanduser() / "combined" / "comb_all_batch.feather"
comb_raw_data_loc = Path(data_folder).expanduser() / "combined" / "comb_all_raw.feather"
ccht_pheno_loc = Path(data_folder).expanduser() / "filtered" / "phenotype.tsv"
comb_pheno_loc = Path(data_folder).expanduser() / "combined" / "comb_all_pheno.tsv"
fractions_folder = Path(data_folder) / "tape_fractions"
fractions_file_loc = fractions_folder / "ccht_fracs.tsv"
fractions_file_loc_comb = fractions_folder / "comb_uf_fracs.tsv"
fractions_file_loc_comb_raw = fractions_folder / "comb_fracs_raw.tsv"
```

Load in the datasets:

* the reference single cell dataset from the HECAv2 (`sc_dat`).
* bulk transcriptomes from UF derived EV's of endometrium and biopsies (`ccht_uf_raw`).
* phenotype table for the EV and biopsy samples (`ccht_uf_pheno`).
* bulk transcriptomes from UF derived EV's of endometrium and Vigano et al. EV transcriptomes (`comb_uf_raw`).
* phenotype table for the EV and Vigano et al. samples (`comb_uf_pheno`).

```{python}
#| output: false

## load in the modified HECA atlas
sc_dat = an.read_h5ad(snapshot_an_loc)

## load in the EV CCHT only data
terminator = ["HUT26_UF", "HUT17_UF", "HUT53_UF", "HUT71_UF"] # some samples to exclude
ccht_uf_raw = pd.read_feather(ccht_data_loc).set_index("gene_id").iloc[:-1]
ccht_uf_pheno = pd.read_table(ccht_pheno_loc).set_index("samplename").assign(
    cyclephase=lambda x: 
      pd.Categorical(x.cyclephase, categories=["pro", "pre", "rec", "post"], ordered=True)
    )
ccht_uf_pheno = ccht_uf_pheno.query("samplename not in @terminator and samplename in @ccht_uf_raw.columns")
ccht_uf_raw = ccht_uf_raw.drop(columns=terminator)

## load in the EV combined dataset phenotype for the fractions
comb_batch = pd.read_feather(comb_data_loc).set_index("gene_id").drop(columns=terminator)
comb_raw = pd.read_feather(comb_raw_data_loc).set_index("external_gene_name").drop(columns=terminator)
comb_all_pheno = (
  pd.read_table(comb_pheno_loc)
  .set_index("samplename")
  .query("samplename not in @terminator")
)
comb_uf_pheno = (
  comb_all_pheno
  .assign(dataset = lambda x: np.where(x.dataset == "HUT", x.dataset, "Vigano"))
  .query("cyclephase in ['rec', 'pre'] and group == 'UF'")
)

## load in the fractions predicted by the latest trained model
frac_pred = pd.read_table(fractions_file_loc, sep="\t", index_col=0)
frac_comb = pd.read_table(fractions_file_loc_comb, sep="\t", index_col=0)
frac_comb_raw = pd.read_table(fractions_file_loc_comb_raw, sep="\t", index_col=0)

general_cells = ( # associate celltypes with the lineage information in the sc_dat.obs
  sc_dat.obs
  .loc[:, ["lineage", "celltype"]]
  .drop_duplicates("celltype")
  .set_index("celltype", drop=True)
  .reindex(frac_pred.columns.values)
)

# Color scale for the celltypes - TODO: extende the color range to not repeat
global_color_scale = alt.Scale(domain=general_cells.index.unique().tolist())
```

We also load in the different statistical testing tables for CCHT dataset.

```{python}
ccht_bio_stat = pd.read_excel(fractions_folder / "ccht_bio.xlsx", index_col=0)
ccht_uf_stat = pd.read_excel(fractions_folder / "ccht_uf.xlsx", index_col=0)
ccht_comp_stat = pd.read_excel(fractions_folder / "ccht_comp.xlsx", index_col=0)
```

And the featurecounts results for the samples from the MultiQC report.

```{python}
features_ev = (
  pd.read_table(
    Path(raw_data_folder) / "multiqc_star_rsem/multiqc_data/multiqc_featurecounts_biotype_plot.txt"
    )
  .rename(columns={"Sample": "samplename"})
  .query("samplename in @frac_pred.index")
  .set_index("samplename")
)
```

The preprocessed spatial slides with spatial deconvolution

```{python}
gen_sc_file = Path(anndata_folder).expanduser() / "gen_sc_ev.h5ad"
gen_ccht_ev = sc.read_h5ad(gen_sc_file, backed="r").to_memory()
gen_sc_file = Path(anndata_folder).expanduser() / "gen_sc_biopsy.h5ad"
gen_ccht_bio = sc.read_h5ad(gen_sc_file, backed="r").to_memory()
```

```{python}
slide_ids = ["152807", "152811"]
data_directory = Path(anndata_folder).expanduser()
# load only the early secretory samples
adata_collection = load_spatial_data(data_directory)
# create the subset using a dictionary comprehension
adata_collection = {key: value for key, value in adata_collection.items() if key[0] in set(slide_ids)}
```

```{python}
# some preliminary metrics
jaccard_thresh = 0.25 # Use lower quartile for Jaccard and Centroid distance
# but then read in the stats table anyways
stats_df = pd.read_csv(Path(data_folder).expanduser() / "st_stats_table.csv", index_col=0)
```

# Methods

## Pre-processing pipeline for the RNA-seq data

```{bash}
#| code-fold: false
#| eval: false
#| echo: true

## nf-core/rnaseq v3.12 (https://nf-co.re/rnseq/3.12.0)
nextflow run nf-core/rnaseq \
  -r 3.12.0 \
  --input samplesheet_mrna.csv \
  --genome GRCh37 \
  --aligner star_rsem \
  --outdir "./results_mrna/" \
  -c nextflow.config \
  -profile singularity
```

## Differential expression analysis

>Not used currently in the report, but left in here for future reference.

Differential expression (DE) analysis was done in R (v4.3) programming language. For differential analysis, we used both DESeq2 and limma-voom algorithms to measure the differences between gene expression levels in different sample groups and to perform statistical testing on the gene-wise differences [[DESeq2](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8), [limma-voom](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29)]. While DESeq2 DE results were used for downstream analysis, we used the limma-voom toolset as an alternative approach as it has been shown to have more stringent multiple hypothesis testing in regards to type I error [[Robles et al.](https://link.springer.com/article/10.1186/1471-2164-13-484), [Soneson et al.](https://link.springer.com/article/10.1186/1471-2105-14-91)].

```{python}
# de_ccht_phases = pd.read_feather(Path(data_folder) / "filtered" / "de" / "voom_phases.feather").set_index("locus")
# de_ccht_group = pd.read_feather(Path(data_folder) / "filtered" / "de" / "voom_methods.feather").set_index("locus")
```

## Sample selection and quality control

> Related scripts are `scripts/ev_raw.r`, `ev_biomarker.rmd` and `ev_deconvolution.qmd`, with the `ev_raw.r` being the main filtering step and `ev_biomarker.rmd` chapter 1.2 being the main analysis step for filtering criteria.
> Add plots from 1.1, 1.2.4, 1.2.2, 1.2.3, 1.2.6 and 1.2.7 as supplementary figures, exclude the training samples in figures 1.1 and 1.2.4

The following code is an excerpt from the `ev_raw.r` script, describing the main filtering step:
```{r}
#| code-fold: false
#| eval: false
#| echo: true
#### FILTER
removals <- c(
  "HUT10_UF", "HUT1_UF", "HUT1_biopsy", "HUT35_UF",
  "HUT42_UF", "HUT71_biopsy_2", "HUT71_biopsy_3"
)

# switch and filter some samples
raw_mat <-
  raw_mat %>%
  rename(
    ## this takes too much time to figure out how to switch by sample codes
    ## just switch manually
    HUT23_biopsy = HUT23_UF,
    HUT23_UF = HUT23_biopsy
  ) %>%
  select(-removals[removals %in% colnames(raw_mat)])
```

> The patient selection criteria is missing. @Elina or @Andres to provide the details.

TODO:

* rerun featureCounts with the new sample names and add the new featureCounts table to the report.
* filter out featureCounts samples with less than 5% mRNA reads and report the number of samples.
* run correlation for the technical replicates of HUT71.

## Deconvolutional model parameters

>Create supplementary figures visualising the training loss and the model performance.

```{python}
#| code-fold: false
#| eval: false
#| echo: true

model_params = {
  "celltype_key": "celltype",
  "top_marker_num": 250, # reduce it from the default parameter of 500
  "max_single_cells": round(len(sc_dat.obs.index) / 8),
  "ratio_num": 1,
  "gpu": 0
}

frac_params = {
  "batch_size": 512,
  "epochs": 1000, # looking at loss plot then 500 seems to be already enough, but 1000 seems to have more accurate representatoin of the cell types.
  "method": "tape", # define this, otherwise defaults for scaden
  "scaler": "ss", # harmonises distributions better
  "mode": "high-resolution" # for using VAE's for cell type inference
}
```

# Results with Figures

## FIG 1: Study Design

Main points of interest:

* Bulk samples are paired, biopsy and EV samples are taken from the same patients.
* We observed the featureCounts mRNA ratio to other transcript types to indicate the quality of the samples, especially in the EV samples with lower genomic input.
* We have also included samples from the late-secretory phase of the menstrual cycle to show the differences in the cell type proportions leading up to the decidualisation of the endometrium.

The deconvolutional model was trained on the HECAv2 dataset, which was then used to generate pseudo-single-cell data from the bulk samples. The pSC data was then projected onto the spatial transcriptomic slides using a combination of Tangram and cell2location methods [cite the methods]. Instead of using more traditional regression based methods for deconvolution, we used generative models to generate pseudo-single-cell data from the bulk samples for both deconvolution and projection to spatial omic data. This approach allows us to generalise the cell type expression profiles and detect those representative profiles in endometrium-derived extracellular vesicles (EVs). Although regression-based methods are more interpretable, they are also more prone to overfitting and can be less robust in the presence of noise or outliers [source? TAPE article?]. Generative models, on the other hand, can capture complex relationships between features as latent representations and can be more resilient to noise, making them a powerful tool for deconvolution tasks for extracellular vesicules. Although recent benchmarking studies have shown that regressional methods can be used successfully for deconvolution of liquid biopsy samples, then it is still unclear how well they perform compared to generative models [[Larsen et al](https://onlinelibrary.wiley.com/doi/abs/10.1002/jev2.12511)]. Therefore, it can be argued that representation based deconvolution methods relax the assumption that RNA molecules in EV's recapituliate only the origin tissue transcriptional profiles. Finally, generative autoencoder models can also be used to generate synthetic single-cell data from bulk samples, which can be subsequently integrated with a spatial transcriptomic dataset to visualise possible origins of the EVs.

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Analysis Steps {.unnumbered .unlisted}

```{python}
# placeholder image
study_schema = spacer_with_text(height=400, width=580)
```

### Overview of the Samples {.unnumbered .unlisted}

```{python}
# barplot of the number of samples throughout the cycle phase
barplot_ev_sum = alt.Chart(ccht_uf_pheno).mark_bar().encode(
  x=alt.X("cyclephase:N").title(""),
  y=alt.Y("count(group):Q").title("Nr. of Samples"),
  color=alt.Color("group:N").legend(orient="bottom", titleOrient="left")
).properties(width=150, height=225)


# include single cell data overview as extra column
barplot_sc_sum = alt.Chart(
  sc_dat.obs[["cyclephase", "samplename", "dataset"]].drop_duplicates()
).mark_bar().encode(
  x=alt.X("cyclephase:N").title("").axis(labelAngle=-45),
  y=alt.Y("count(dataset):Q").title("Nr. of Donors"),
  color=alt.Color("dataset:N").legend(orient="bottom", titleOrient="top", columns=2)
).properties(width=150, height=225)

(barplot_ev_sum & barplot_sc_sum).resolve_scale(color="independent")
```

### Feature Counts {.unnumbered .unlisted}

Plot top features per FeatureCounts output on log scale. Show the cutoff point for QC of 5% miRNA reads.

```{python}
# Identify biotype columns and calculate total counts
biotype_cols = features_ev.columns
biotype_counts = features_ev[biotype_cols].sum().sort_values(ascending=False)

# Get the top 15 biotypes
top_biotypes = biotype_counts.head(15).index.tolist()

# Melt the DataFrame for plotting, including only the top 5 biotypes
df_melted = (
  features_ev
  .reset_index()
  .melt(id_vars=['samplename'], value_vars=top_biotypes, var_name='biotype', value_name='count')
)

# Create a new column for the sample group
df_melted['sample_group'] = df_melted['samplename'].apply(lambda x: 'biopsy' if 'biopsy' in x else 'UF')

# Create the grouped boxplot
featurecounts_chart = alt.Chart(df_melted).mark_boxplot(extent=1.5).encode(
  x=alt.X('biotype:N', title='Biotype', sort=top_biotypes).axis(labelAngle=-30),
  y=alt.Y('count:Q', title='Count (log)').scale(type="log", nice=True).axis(values=[1e3, 1e4, 1e5, 1e6, 1e7, 1e8]),
  color=alt.Color('sample_group:N', title='Sample Group').legend(orient="top", titleOrient="left"),
  xOffset='sample_group:N',
  tooltip=['samplename', 'biotype', 'count', 'sample_group'],
).properties(
  height=150,
  width=550
)

featurecounts_chart.show()
```

:::

```{python}
(
  (study_schema & featurecounts_chart).resolve_scale(color="independent") | 
  (barplot_ev_sum & barplot_sc_sum).resolve_scale(color="independent")
)
```

## FIG 2: Cell Type Deconvolution Profiles throughout the Menstrual Cycle

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Proportions Plot of both Biopsy and EV {.unnumbered .unlisted}

```{python}
fractions_long = peruvian_transform(
  fractions=frac_pred,
  phenotype=ccht_uf_pheno,
  general_cells=general_cells,
  grouping_ids=["cyclephase", "group"]
)

peruvian_bio_ev = peruvian_grouped(
  fractions_df=fractions_long,
  grouping_id="group",
  global_color_scale=global_color_scale,
  dims=(200, 150)
)

peruvian_bio_ev.show()
```

### Biplot of the Fractions {.unnumbered .unlisted}

```{python}
biplot, pca = biplot_fractions(
  frac_pred,
  ccht_uf_pheno,
  color_field="cyclephase", 
  style_field="group",
  text_limit = 0.04, # controls on how much labels are shown
  dims = (400, 400)
  )
biplot.show()
```

In addition, make a histogram of the main loadings to make the contributions more clearer. `TODO: make it into percentages?`

```{python}
def format_loadings(pca_obj, celltypes):
  """
  Get the euclidean distance of explained variance per component of `pca_obj`.
  Generate a dataframe with the "Variance Explained" and the "Feature" column from `celltypes` list.
  """
  loadings = np.linalg.norm(pca_obj.components_.T * np.sqrt(pca_obj.explained_variance_), axis=1)
  return pd.DataFrame({
    "Variance Explained": loadings, "Feature": celltypes
  }).sort_values("Variance Explained", ascending=False).reset_index(drop=True)

pca_all = pca # save it with another name for clarity
loadings_all = format_loadings(pca_all, frac_pred.columns).rename(columns={"Variance Explained": "Combined"}).set_index("Feature")

pheno_tmp = ccht_uf_pheno.query("group == 'UF'")
_, pca_uf = biplot_fractions(frac_pred.loc[pheno_tmp.index], pheno_tmp, color_field="cyclephase")
loadings_uf = format_loadings(pca_uf, frac_pred.columns).rename(columns={"Variance Explained": "UF"}).set_index("Feature")

pheno_tmp = ccht_uf_pheno.query("group == 'biopsy'")
_, pca_bio = biplot_fractions(frac_pred.loc[pheno_tmp.index], pheno_tmp)
loadings_bio = format_loadings(pca_bio, frac_pred.columns).rename(columns={"Variance Explained": "Biopsy"}).set_index("Feature")


## The plot part - visualise all the different loadings
loadings_combined = (
  pd.concat([loadings_all, loadings_uf, loadings_bio], axis=1)
  .stack()
  .reset_index()
  .rename(columns={"level_1": "Group", 0: "Variance Explained"})
  )

loadings_plt = alt.Chart(loadings_combined).mark_line(
    point=alt.OverlayMarkDef(filled=False, fill="white", size=10)
  ).encode(
  x=alt.X("Feature:N", sort=None).axis(labelAngle=-60),
  y=alt.Y("Variance Explained:Q"),
  color=alt.Color("Group:N")
).properties(
  title='Loadings for Principal Component',
  width=400,
  height=150
)

loadings_plt.show()
```

### Testing the Differences of the Deconvolution Proportions through Cycle Phases {.unnumbered .unlisted}

Here we create a visual representation of the statistical testing and correlation analysis results of the UF and Biopsy samples. We present the most statistically significant changes throughout the cycle phases.

```{python}
def swap_groups(df, to_swap):
  for g1, g2 in to_swap:
    # find that combination of pairs in the dataframe
    stats_view = (df.group1==g1) & (df.group2==g2)
    # swap the column names for those pairs of groups
    swapped_view = df.loc[stats_view].rename(columns={"group1": "group2", "group2": "group1"})
    # also invert the diff bc the groups have swapped
    swapped_view["meandiff"] *= -1
    # and now replace that part of the dataframe
    df.loc[stats_view] = swapped_view
  return df

swapper = [("post", "rec"), ("rec", "pre"), ("pre", "pro")]
excluder = ["post_vs_pre", "pro_vs_rec", "post_vs_pro"]
comp_order = ["pro_vs_pre", "pre_vs_rec", "rec_vs_post"]
cycle_order = ["pro", "pre", "rec", "post"]
plt_width, plt_height = (1000, 150)

stat_comb_prim = (
  pd.concat([ccht_bio_stat.assign(method="bio"), ccht_uf_stat.assign(method="uf")])
  .query("`anova p-val` <= 0.05")
  .pipe(swap_groups, swapper)
  .assign(
    p_stars=lambda x:
      np.select(
          [ x["p-adj"] <= 0.001, x["p-adj"] <= 0.01, x["p-adj"] <= 0.05, True],
          ["***", "**", "*", ""],
          default=""  # Add this default value
      ),
    comparison=lambda x: x.group1 + "_vs_" + x.group2,
    meandiff_format=lambda x: "Î” " + round(x.meandiff * 100, 2).astype(str) + "%",
    padj_format=lambda x: np.where(x["p-adj"] < 0.01, "FDR <0.01", "FDR " + round(x["p-adj"], 2).astype(str))
  )
  # the great filter
  .query("comparison not in @excluder")
  .dropna(subset=["comparison"])
  .join(general_cells, on="celltype")
  .sort_values(["lineage", "celltype"])
  .reset_index(drop=True)
)
```

For the Biopsy samples comparison:

```{python}
stat_comb = stat_comb_prim.query("method == 'bio'")

# create a dummy dataframes for the custom scale hack
stat_tmp_groups = pd.DataFrame({
  "base": cycle_order,
  "celltype": stat_comb.celltype.drop_duplicates().values[0], 
  "loc": np.linspace(0,1,len(cycle_order))
  })

# set up basechart for the X axis, sadly we'll have to redefine the Y axis for 
# both the text and heatmap due to differences in handling of ticks
base_chart = alt.Chart(stat_comb).encode(
  x=alt.X("celltype:N", sort=stat_comb.celltype.drop_duplicates().values).axis(labelAngle=-45, orient="top", title="Biopsy"),
  y=alt.Y("comparison:N", sort=comp_order[::-1]).axis(labels=False, tickBand="extent", title=None)
)

heatmap = base_chart.mark_rect().encode(
  color=alt.Color("meandiff:Q").scale(scheme="blueorange", domain=[-.2,.2]).legend(None)
  )

# the significance testing texty part
base_text = base_chart.encode(
  # have to override yaxis ticks here, otherwise it'll add it to the right side later
  y=alt.Y("comparison:N", sort=comp_order[::-1]).axis(labels=False, ticks=False, title=None) 
)
text_overlay_stars = base_text.mark_text(fontWeight="bold", fontSize=24, dy=-6).encode(
  text=alt.Text("p_stars"))
text_overlay_diff = base_text.mark_text(fontSize=10, dy=14).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("meandiff_format:N")))
text_overlay_pval = base_text.mark_text(fontSize=10, dy=2).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("padj_format:N")))

# create a pseudoaxis plot where we create custom labels for the marks
yaxis_group = alt.Chart(stat_tmp_groups).mark_text(clip=False, align="right").encode(
  x=alt.X("celltype:N", sort=stat_comb.celltype.drop_duplicates().values),
  y=alt.Y("loc:Q").axis(None),
  xOffset=alt.value(-15),
  text=alt.Text("base")
)

# create another pseudoaxis plot to show the lineages of celltypes as a colored line above heatmap values
xaxis_group_colors = alt.Chart(stat_comb).mark_rect().encode(
  x=alt.X("celltype:N", sort=stat_comb.celltype.drop_duplicates().values).axis(orient="top"),
  yOffset=alt.value(plt_height + 10), # set it to +10 of the plot height so that it would overlap
  color=alt.Color("lineage:N").legend(None)
)

comp_stats_bio_plt = (
  xaxis_group_colors + heatmap + text_overlay_stars + text_overlay_diff + text_overlay_pval + yaxis_group
).properties(width=plt_width, height=plt_height)

comp_stats_bio_plt.show()
```

For the UF samples comparison:

```{python}
stat_comb = stat_comb_prim.query("method == 'uf'")

# create a dummy dataframes for the custom scale hack
stat_tmp_groups = pd.DataFrame({
  "base": cycle_order,
  "celltype": stat_comb.celltype.drop_duplicates().values[0], 
  "loc": np.linspace(0,1,len(cycle_order))
  })

# set up basechart for the X axis, sadly we'll have to redefine the Y axis for 
# both the text and heatmap due to differences in handling of ticks
base_chart = alt.Chart(stat_comb).encode(
  x=alt.X("celltype:N", sort=stat_comb.celltype.drop_duplicates().values).axis(labelAngle=-45, title="UF"),
  y=alt.Y("comparison:N", sort=comp_order[::-1]).axis(labels=False, tickBand="extent", title=None)
)

heatmap = base_chart.mark_rect().encode(
  color=alt.Color("meandiff:Q")
    .scale(scheme="blueorange", domain=[-.2,.2])
  )

# the significance testing texty part
base_text = base_chart.encode(
  # have to override yaxis ticks here, otherwise it'll add it to the right side later
  y=alt.Y("comparison:N", sort=comp_order[::-1]).axis(labels=False, ticks=False, title=None) 
)
text_overlay_stars = base_text.mark_text(fontWeight="bold", fontSize=24, dy=-6).encode(
  text=alt.Text("p_stars"))
text_overlay_diff = base_text.mark_text(fontSize=10, dy=14).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("meandiff_format:N")))
text_overlay_pval = base_text.mark_text(fontSize=10, dy=2).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("padj_format:N")))

# create a pseudoaxis plot where we create custom labels for the marks
yaxis_group = alt.Chart(stat_tmp_groups).mark_text(clip=False, align="right").encode(
  x=alt.X("celltype:N", sort=stat_comb.celltype.drop_duplicates().values),
  y=alt.Y("loc:Q").axis(None),
  xOffset=alt.value(-15),
  text=alt.Text("base")
)

# create another pseudoaxis plot to show the lineages of celltypes as a colored line above heatmap values
xaxis_group_colors = alt.Chart(stat_comb).mark_rect().encode(
  x=alt.X("celltype:N", sort=stat_comb.celltype.drop_duplicates().values),
  yOffset=alt.value(-10), # offset to overlay on the top
  y2=alt.value(0), # set to 0 to not draw it behind the main heatmap (shows small lines)
  color=alt.Color("lineage:N")
)

comp_stats_uf_plt = (
  xaxis_group_colors + heatmap + text_overlay_stars + text_overlay_diff + text_overlay_pval + yaxis_group
).properties(width=plt_width, height=plt_height)

comp_stats_uf_plt.show()
```

And combined on top of each other

```{python}
# remove the legend from one of those plots, id does not sync it for some reason
# TODO: the lineage colors are still not synchronised
comp_stats_plt = (comp_stats_bio_plt & comp_stats_uf_plt).resolve_scale(x="independent")
comp_stats_plt.show()
```

:::

Combining them all into one.

```{python}
# have to resolve the color scale, otherwise the loadings_plt will override the biplot's scale
((peruvian_bio_ev | (biplot & loadings_plt)) & comp_stats_plt
  ).resolve_scale(color="independent").show()
# below both of them there should be the directionality plot of DE proportions
```

## FIG 3: Comparison of Biopsy and EV Sampling Methods

Here we focus on the comparison of the paired sample profiles from **both** biopsy and UF origin.

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Dendro-barplot of Fractions {.unnumbered .unlisted}

```{python}
# the dendrogram part
linkage_mat = linkage(frac_pred, method="complete", optimal_ordering=True)
dend_obj = dendrogram(linkage_mat, labels=ccht_uf_pheno.index, no_plot=True)
dendro_marks = pd.DataFrame({"labels": dend_obj["ivl"]}).reset_index().rename(columns={"index": "i"})
dendro_coord = get_df_coord(dend_obj)

# and transform the x and y coords to a suitable scale
scaler = .25
cols_xk = ["xk1", "xk2", "xk3", "xk4"]
cols_yk = ["yk1", "yk2", "yk3", "yk4"]
x_min, x_max = (dendro_coord[cols_xk].min(axis=None), dendro_coord[cols_xk].max(axis=None))
dendro_coord[cols_xk] = (dendro_coord[cols_xk] - x_min) / (x_max - x_min)
dendro_coord[cols_xk] *= (dendro_marks.shape[0] - 1)
dendro_coord[cols_yk] *= scaler/dendro_coord[cols_yk].max(axis=None) # scale the y heights
dendro_coord[cols_yk] += 1.18 # and shift up whole unit

base = alt.Chart(dendro_coord, view=alt.ViewConfig(strokeWidth=0))
# the U shape is composed of a shoulder plus two arms, made with separate lines...
shoulder = base.mark_rule().encode(
    x=alt.X("xk2:Q", title="").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    x2=alt.X2("xk3:Q"),
    y=alt.Y("yk2:Q", title="").axis(None))
arm1 = base.mark_rule().encode(
    x=alt.X("xk1:Q").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    y=alt.Y("yk1:Q").axis(None),
    y2=alt.Y2("yk2:Q"))
arm2 = base.mark_rule().encode(
    x=alt.X("xk3:Q").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    y=alt.Y("yk3:Q").axis(None),
    y2=alt.Y2("yk4:Q"))

# chart_den = (shoulder + arm1 + arm2).properties(width=.98*plt_width, height=50)
chart_den = shoulder + arm1 + arm2
```

```{python}
# the barplot part
# make fracs long again - reuse previous peruvian_transform
fractions_long = (
  peruvian_transform(
    fractions=frac_pred,
    phenotype=ccht_uf_pheno,
    general_cells=general_cells
  )
  .rename(columns={"level_0": "samplename"})
  .set_index("samplename")
  .join(dendro_marks.set_index("labels"))
  .join(ccht_uf_pheno)
  .reset_index()
  .sort_values("i")
)

custom_labels = fractions_long.samplename.drop_duplicates().values.tolist()
# custom printer - by default the list is printed with newlines so that the js parses the list transposed
custom_labels_str =  ', '.join(f"'{label}'" for label in custom_labels)

base_bar = alt.Chart(fractions_long, view=alt.ViewConfig(strokeWidth=0))
barplot = base_bar.mark_bar(
  width=12
).encode(
  x=alt.X("i:Q").axis(
    title=None, grid=False, domain=False,
    tickCount=len(custom_labels),
    labelAngle=90,
    labelOverlap=False, 
    labelExpr=f"[{custom_labels_str}][datum.value]" # custom label values mapped
  ).scale(domain=[0,len(custom_labels)-1], padding=10),
  y=alt.Y("fractions:Q").axis(grid=False).scale(domain=[0,1]),
  color=alt.Color("lineage:N").scale(scheme="category10").legend(columns=1)
  )

# add the color groupings 
x_cycle_colors = barplot.mark_rect(clip=False, width=20).encode(
    y=alt.value(0), # for some reason this works
    y2=alt.value(-4),
    yOffset=alt.value(-12),
    color=alt.Color("cyclephase:N").scale(scheme="set1")
  )
x_method_colors = barplot.mark_rect(clip=False, width=20).encode(
    y=alt.value(0), # for some reason this works
    y2=alt.value(-16),
    yOffset=alt.value(-24),
    color=alt.Color("group:N").scale(scheme="set2")
  )
```

```{python}
dendro_barplot = (
  (chart_den + barplot + x_cycle_colors + x_method_colors)
  .resolve_scale(x="shared", y="shared", color="independent")
  .resolve_axis(y="independent")
  .properties(width=700, height=150)
)
dendro_barplot.show()
```

### Correlation Heatmap of the Paired Samples {.unnumbered .unlisted}

```{python}
# calculate the correlation matrix and prepare data for the plot
# first we create a phenotype file to order the samples after
prepped_pheno = (
  ccht_uf_pheno
  .loc[frac_pred.index]
  .assign(HUT=lambda x: x.index.str.extract(r"(HUT\d+)", expand=False))
  .sort_values(["cyclephase", "HUT"])
)

# select only samples with corresponding HUT pair
paired_samples_stem = prepped_pheno.HUT.value_counts().to_frame().query("count > 1").index
prepped_pheno = prepped_pheno.query("HUT in @paired_samples_stem")

# run a corr matrix with itself
corr_mat = (
  # transpose to run correlation against the samples
  frac_pred.loc[prepped_pheno.index].T.corr(method="spearman")
  # select out only cols with UF in columns and biopsy in rows
  .filter(regex="UF", axis=0).filter(regex="biopsy", axis=1)
  # stack it into long version for Altair
  .stack().rename("correlation").to_frame().reset_index(names=["y_vars", "x_vars"])
  # now add a cols with the locations of last groups
  .join(prepped_pheno[["cyclephase"]], on="x_vars")
  .join(prepped_pheno[["cyclephase"]], on="y_vars", lsuffix="_y")
)
```

```{python}
# Create Altair plot
base_heatmap = alt.Chart(corr_mat).mark_rect().encode(
    x=alt.X('x_vars:O', sort=corr_mat.x_vars.unique(), title=None).axis(offset=10),
    y=alt.Y('y_vars:O', sort=corr_mat.y_vars.unique(), title=None).axis(orient="right", offset=10),
    color=alt.Color('correlation:Q').scale(scheme='magma') # Quantitative for correlation values, using magma colormap
  )

# add the color groupings 
x_group_colors = base_heatmap.mark_rect().encode(
  x=alt.X('x_vars:O', sort=corr_mat.x_vars.unique(), title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase:N"),
  xOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

y_group_colors = base_heatmap.mark_rect().encode(
  y=alt.Y('y_vars:O', sort=corr_mat.y_vars.unique(), title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase_y:N").legend(None),
  yOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

# Layer heatmap and colors
final_chart = (x_group_colors + y_group_colors + base_heatmap).resolve_scale(
  x='shared', y='shared', color='shared'
)

# Display the chart
final_chart
```

### Volcano plot with the difference in deconvolution profiles {.unnumbered .unlisted}

Here we transform the deconvolution profiles into a volcano plot, where we show the differences in the proportions of the cell types between the biopsy and UF samples.

```{python}
## calculate the diffs
avg_uf = frac_pred.loc[prepped_pheno.query("group == 'UF'").index,].agg("mean")
avg_bio = frac_pred.loc[prepped_pheno.query("group == 'biopsy'").index,].agg("mean")
diff_df = pd.DataFrame({"diff": avg_uf - avg_bio}).join(ccht_comp_stat).rename(columns={"p-val": "pval"})
threshold_p = .05 / len(ccht_comp_stat.index)

## base plot
volcano_base = alt.Chart(
  diff_df.reset_index(), view=alt.ViewConfig(strokeWidth=0)
).mark_point(
  filled=True, opacity=.7
).encode(
  x=alt.X("diff:Q").scale(domain=[-.12, .12]).axis(title="difference", tickCount=4),
  y=alt.Y("pval:Q").scale(type="log", base=10, reverse=True).axis(title="p-value", tickCount=8),
  color=alt.condition(alt.datum.pval < threshold_p, alt.value("red"), alt.value("grey"))
)

## the text for the top two diff celltypes
volcano_annot = alt.Chart(
  diff_df.reset_index().sort_values("pval").head(4).assign(text_angle=lambda x: np.where(x["diff"] < 0, 330, 30))
).mark_text(align="center", dy=-8, angle=alt.expr(alt.datum.text_angle)).encode(
  x=alt.X("diff:Q"), y=alt.Y("pval:Q"),
  text=alt.Text("celltype:N")
)

## the dividing line
rule_tmp = pd.DataFrame({"threshold_p": [ threshold_p ]})
rule_y = alt.Chart(rule_tmp).mark_rule(color='black', strokeDash=[3,3]).encode(y="threshold_p")
volcano = volcano_base + volcano_annot + rule_y
volcano
```

:::

```{python}
(dendro_barplot & (final_chart | volcano)).resolve_scale(color="independent")
```

## FIG 4: Comparison of Vigano et al. and our sampling methods

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Dendro-barplot of Fractions {.unnumbered .unlisted}

```{python}
# the dendrogram part
linkage_mat = linkage(frac_comb.loc[comb_uf_pheno.index,], method="complete", optimal_ordering=True)
dend_obj = dendrogram(linkage_mat, labels=comb_uf_pheno.index, no_plot=True)
dendro_marks = pd.DataFrame({"labels": dend_obj["ivl"]}).reset_index().rename(columns={"index": "i"})
dendro_coord = get_df_coord(dend_obj)

# and transform the x and y coords to a suitable scale
scaler = .25
cols_xk = ["xk1", "xk2", "xk3", "xk4"]
cols_yk = ["yk1", "yk2", "yk3", "yk4"]
x_min, x_max = (dendro_coord[cols_xk].min(axis=None), dendro_coord[cols_xk].max(axis=None))
dendro_coord[cols_xk] = (dendro_coord[cols_xk] - x_min) / (x_max - x_min)
dendro_coord[cols_xk] *= (dendro_marks.shape[0] - 1)
dendro_coord[cols_yk] *= scaler/dendro_coord[cols_yk].max(axis=None) # scale the y heights
dendro_coord[cols_yk] += 1.18 # and shift up whole unit

base = alt.Chart(dendro_coord, view=alt.ViewConfig(strokeWidth=0))
# the U shape is composed of a shoulder plus two arms, made with separate lines...
shoulder = base.mark_rule().encode(
    x=alt.X("xk2:Q", title="").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    x2=alt.X2("xk3:Q"),
    y=alt.Y("yk2:Q", title="").axis(None))
arm1 = base.mark_rule().encode(
    x=alt.X("xk1:Q").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    y=alt.Y("yk1:Q").axis(None),
    y2=alt.Y2("yk2:Q"))
arm2 = base.mark_rule().encode(
    x=alt.X("xk3:Q").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    y=alt.Y("yk3:Q").axis(None),
    y2=alt.Y2("yk4:Q"))

# chart_den = (shoulder + arm1 + arm2).properties(width=.98*plt_width, height=50)
chart_den = shoulder + arm1 + arm2
```

```{python}
# the barplot part
# make fracs long again - reuse previous peruvian_transform
fractions_long = (
  peruvian_transform(
    fractions=frac_comb.loc[comb_uf_pheno.index],
    phenotype=comb_uf_pheno,
    general_cells=general_cells
  )
  .rename(columns={"level_0": "samplename"})
  .set_index("samplename")
  .join(dendro_marks.set_index("labels"))
  .join(comb_uf_pheno)
  .reset_index()
  .sort_values("i")
)

custom_labels = fractions_long.samplename.drop_duplicates().values.tolist()
# custom printer - by default the list is printed with newlines so that the js parses the list transposed
custom_labels_str =  ', '.join(f"'{label}'" for label in custom_labels)

base_bar = alt.Chart(fractions_long, view=alt.ViewConfig(strokeWidth=0))
barplot = base_bar.mark_bar(
  width=8
).encode(
  x=alt.X("i:Q").axis(
    title=None, grid=False, domain=False,
    tickCount=len(custom_labels),
    labelAngle=90,
    labelOverlap=False, 
    labelExpr=f"[{custom_labels_str}][datum.value]" # custom label values mapped
  ).scale(domain=[0,len(custom_labels)-1], padding=10),
  y=alt.Y("fractions:Q").axis(grid=False).scale(domain=[0,1]),
  color=alt.Color("lineage:N").scale(scheme="category10").legend(columns=1)
  )

# add the color groupings 
x_cycle_colors = barplot.mark_rect(clip=False, width=14).encode(
    y=alt.value(0), # for some reason this works
    y2=alt.value(-4),
    yOffset=alt.value(-12),
    color=alt.Color("cyclephase:N").scale(scheme="set1")
  )
x_method_colors = barplot.mark_rect(clip=False, width=14).encode(
    y=alt.value(0), # for some reason this works
    y2=alt.value(-16),
    yOffset=alt.value(-24),
    color=alt.Color("dataset:N").scale(scheme="set2")
  )
```

```{python}
dendro_bar = (
  (chart_den + barplot + x_cycle_colors + x_method_colors)
  .resolve_scale(x="shared", y="shared", color="independent")
  .resolve_axis(y="independent")
  .properties(width=500, height=150)
)
dendro_bar.show()
```


### Correlation Heatmap of UF samples {.unnumbered .unlisted}

```{python}
# run a corr matrix with itself and select out the interesting rows
corr_mat = (
  # transpose to run correlation against the samples, not celltypes
  frac_comb.loc[comb_uf_pheno.index].T.corr(method="spearman")
  # select out Vigano and CCHT in both axes
  .filter(regex="plus", axis=0).filter(regex="UF", axis=1)
)

corr_long = (
  corr_mat
  # stack it into long version for Altair
  .stack().rename("correlation").to_frame().reset_index(names=["y_vars", "x_vars"])
  # now add a cols with the locations of last groups
  .join(comb_uf_pheno[["cyclephase"]], on="x_vars")
  .join(comb_uf_pheno[["cyclephase"]], on="y_vars", lsuffix="_y")
)
```

Generate the X axis linkage plots.

```{python}
# the dendrogram part for axis X
linkage_mat = linkage(corr_mat.T, method="complete", optimal_ordering=True)
dend_obj = dendrogram(linkage_mat, labels=comb_uf_pheno.query("dataset == 'HUT'").index, no_plot=True)
dendro_marks_x = pd.DataFrame({"labels": dend_obj["ivl"]}).reset_index().rename(columns={"index": "i"})
dendro_coord = get_df_coord(dend_obj)

base = alt.Chart(dendro_coord, view=alt.ViewConfig(strokeWidth=0)) 
# the U shape is composed of a shoulder plus two arms, made with separate lines...
shoulder = base.mark_rule().encode(
    x=alt.X("xk2:Q", title="").axis(None),
    x2=alt.X2("xk3:Q"),
    y=alt.Y("yk2:Q", title="").axis(None))
arm1 = base.mark_rule().encode(
    x=alt.X("xk1:Q"),
    y=alt.Y("yk1:Q"),
    y2=alt.Y2("yk2:Q"))
arm2 = base.mark_rule().encode(
    x=alt.X("xk3:Q"),
    y=alt.Y("yk3:Q"),
    y2=alt.Y2("yk4:Q"))

chart_den_x = (shoulder + arm1 + arm2).properties(height=50, width=200)
```

Generate the Y axis linkage plots.

```{python}
# the dendrogram part for axis Y
linkage_mat = linkage(corr_mat, method="complete", optimal_ordering=True)
dend_obj = dendrogram(linkage_mat, labels=comb_uf_pheno.query("dataset == 'Vigano'").index, no_plot=True)
dendro_marks_y = pd.DataFrame({"labels": dend_obj["ivl"]}).reset_index().rename(columns={"index": "i"})
dendro_coord = get_df_coord(dend_obj)

base = alt.Chart(dendro_coord, view=alt.ViewConfig(strokeWidth=0))
# the U shape is composed of a shoulder plus two arms, made with separate lines...
shoulder = base.mark_rule().encode(
    y=alt.Y("xk2:Q", title="").axis(None),
    y2=alt.Y2("xk3:Q"),
    x=alt.X("yk2:Q", title="").axis(None).scale(reverse=True))
arm1 = base.mark_rule().encode(
    y=alt.Y("xk1:Q"),
    x=alt.X("yk1:Q").scale(reverse=True),
    x2=alt.X2("yk2:Q"))
arm2 = base.mark_rule().encode(
    y=alt.Y("xk3:Q"),
    x=alt.X("yk3:Q").scale(reverse=True),
    x2=alt.X2("yk4:Q"))

chart_den_y = (shoulder + arm1 + arm2).properties(width=50, height=600)
```

```{python}
# Create Altair plot
base_heatmap = alt.Chart(corr_long).mark_rect().encode(
    x=alt.X('x_vars:O', sort=dendro_marks_x.labels, title=None).axis(offset=10),
    y=alt.Y('y_vars:O', sort=dendro_marks_y.labels, title=None).axis(orient="right", offset=10),
    color=alt.Color('correlation:Q').scale(scheme='magma') # Quantitative for correlation values, using magma colormap
  )

# add the color groupings 
x_group_colors = base_heatmap.mark_rect().encode(
  x=alt.X('x_vars:O', sort=dendro_marks_x.labels, title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase:N"),
  xOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

y_group_colors = base_heatmap.mark_rect().encode(
  y=alt.Y('y_vars:O', sort=dendro_marks_y.labels, title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase_y:N").legend(None),
  yOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

# Layer heatmap and colors
final_chart = (x_group_colors + y_group_colors + base_heatmap).properties(width=150, height=600)

# Display the chart
final_chart
```

```{python}
dendro_corrplot = (
  (chart_den_y | chart_den_x & final_chart)
  .resolve_scale(x="independent", y="independent")
  .resolve_axis(x="independent", y="independent")
)

dendro_corrplot.show()
```

### PCA of UF Vigano and HUT samples

```{python}
# some params for the pcas
shape_range = ["diamond", "square"]
dims = {"height": 200, "width": 200}
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(frac_comb), columns=["PC1", "PC2"])
  .set_index(frac_comb.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_one = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N"),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Deconvolution with batch correction", **dims)
pca_one
```

### PCA of UF combined without batch correction

```{python}
# filter out biopsy samples
frac_tmp = frac_comb_raw.loc[~frac_comb_raw.index.str.contains("biopsy")]
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(frac_tmp), columns=["PC1", "PC2"])
  .set_index(frac_tmp.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_two = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N"),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Deconvolution without batch correction", **dims)
pca_two
```

### PCA of raw counts of combined UF

```{python}
# filter out biopsy samples
counts_tmp = comb_batch.T.loc[~comb_batch.T.index.str.contains("biopsy")]
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(counts_tmp), columns=["PC1", "PC2"])
  .set_index(counts_tmp.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_three = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N"),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Raw counts with batch correction", **dims)
pca_three
```

### PCA of batch adjusted counts of combined UF

```{python}
# filter out biopsy samples
counts_tmp = comb_raw.T.loc[~comb_raw.T.index.str.contains("biopsy")]
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(counts_tmp), columns=["PC1", "PC2"])
  .set_index(counts_tmp.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_four = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N"),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Raw counts without batch correction", **dims)
pca_four
```


:::

```{python}
pca_block = (pca_one & pca_two) | (pca_three & pca_four)
(
  (dendro_corrplot | pca_block & dendro_bar)
  .resolve_scale(x="independent", y="independent", color="independent", shape="independent")
)
```

## FIG 5: Spatial Projections

Given the nature of the data, we expect to see a high correlation between the projected biopsy and the reference raw scRNA-seq data. The projected UF data should be more dispersed, as the UF samples are not directly comparable to the biopsy samples. Still, the UF samples should show a similar pattern of cell type distribution as the biopsy samples, per the assumption that the abundances of cell types in the UF samples indicate where the EV's are coming from in the tissue.

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Example of a ST slide

```{python}
# show the example slide sample
adat = adata_collection[(slide_ids[0], "ref")].to_memory()
crop_coords = get_spatial_crop_coords(adat)
sq.pl.spatial_scatter(
  adat,
  color=[None], crop_coord=crop_coords,
  ncols=2
  )
```

### Example of the projected abundcances with single cell type

```{python}
# and then show a single exemplary cell type in different projections
# TODO: find a way to get the crop_coord from the adata object
cts = ["Glandular"]

sq.pl.spatial_scatter(
  adat,
  cmap='magma',
  color=cts,
  crop_coord=crop_coords,
  size=1.3, title="Reference"
)
sq.pl.spatial_scatter(
  adata_collection[(slide_ids[0], "ev")],
  cmap='magma',
  color=cts,
  crop_coord=crop_coords,
  size=1.3, title="EV"
)
sq.pl.spatial_scatter(
  adata_collection[(slide_ids[0], "bio")],
  cmap='magma',
  color=cts,
  crop_coord=crop_coords,
  size=1.3, title="Biopsy"
)
```

### Example of the UMAP clustering of generated single cell data

```{python}
# Plot with smaller size
sc.pl.embedding(gen_ccht_ev, basis='X_umap', color='lineage', title="EV pSC UMAP", legend_loc="on data")
sc.pl.embedding(gen_ccht_bio, basis='X_umap', color='lineage', title="Biopsy pSC UMAP", legend_loc="on data")
```

### The boxplots of different comparison methods

```{python}
# --- Data Preparation ---
plot_df_pairwise = stats_df[stats_df['comparison'].isin(['ev_vs_ref', 'bio_vs_ref'])].copy()
exclude_metrics = ["Pearson Correlation"]  # Metrics to exclude from visualization
col_wrap = 3  # Number of columns for facet wrapping

# Filter out excluded metrics
filtered_df = plot_df_pairwise[~plot_df_pairwise['metric'].isin(exclude_metrics)]

# --- Altair Plot Construction ---
# 1. Define the base boxplot
boxplot = alt.Chart(filtered_df).mark_boxplot(extent='min-max').encode(
  x=alt.X('lineage:N', title=None, axis=alt.Axis(labelAngle=45)),  # Rotate x-axis labels
  y=alt.Y('value:Q', title='Value'),  # Statistic value on Y-axis
  xOffset=alt.XOffset('comparison:N', title=None),  # Rotate x-axis labels
  color=alt.Color('comparison:N', legend=alt.Legend(title='Comparison'))  # Color by comparison
)

# 2. Apply faceting
boxplots = boxplot.facet(
  column=alt.Column('metric:N', title=None, header=alt.Header(labelOrient='top')),  # Facet by metric
  row=alt.Row('cyclephase:N', title=None, header=alt.Header(labelOrient='right'))  # Facet by cyclephase
).resolve_scale(
  x='independent',
  y='independent'
).properties(
  title=alt.TitleParams(
    'Boxplots of Statistics by Metric and Comparison',
    anchor='middle'  # Center the title
  )
)

# To display in a Jupyter environment:
boxplots
```

### Pearson correlation

```{python}
# 0. Prepare the data for the scatter plot
metric_to_plot = 'Pearson Correlation' # Choose a metric
scatter_df = (
  plot_df_pairwise[plot_df_pairwise['metric'] == metric_to_plot]
  # Add cyclephase to the index for faceting
  .pivot_table(index=['slide_id', 'celltype', 'lineage', 'cyclephase'], columns='comparison', values='value')
  .reset_index()
)
scatter_df.dropna(inplace=True) # Drop rows if one comparison is missing

# 1. Define the base scatter plot layer
# Data will be passed during faceting because we layer first
points = alt.Chart().mark_point(filled=True, size=60, opacity=0.7).encode(
  x=alt.X('ev_vs_ref', title='EV vs REF'), # Set axis title
  y=alt.Y('bio_vs_ref', title='BIO vs REF'), # Set axis title
  color=alt.Color('celltype', legend=alt.Legend(title="Celltype", orient='bottom-right', labelFontSize=9, offset=0)), # Add legend title
  tooltip=['slide_id', 'celltype', 'lineage', 'ev_vs_ref', 'bio_vs_ref'] # Tooltips
)

# 2. Prepare data for the y=x diagonal line
# Calculate overall min/max across both relevant columns IN THE FILTERED DATA
min_val = min(scatter_df['ev_vs_ref'].min(), scatter_df['bio_vs_ref'].min())
max_val = max(scatter_df['ev_vs_ref'].max(), scatter_df['bio_vs_ref'].max())
# Add a small buffer to ensure the line extends slightly beyond points
buffer = (max_val - min_val) * 0.05
min_val = min_val - buffer if min_val - buffer is not np.nan else 0 # Handle potential NaN from empty df
max_val = max_val + buffer if max_val + buffer is not np.nan else 1 # Handle potential NaN

# 3. Define the diagonal line layer and the connecting line layer
line_df = pd.DataFrame({'x': [min_val, max_val], 'y': [min_val, max_val]})
diagonal_line = alt.Chart(line_df).mark_line(
  color='black',
  strokeDash=[5,5], # Dashed line style
  opacity=0.25      # Corresponds to alpha=0.25
).encode(x='x', y='y')

# Create the line layer connecting points within each celltype per facet
lines = points.mark_line(opacity=0.2).encode(order='celltype')

# 4. Layer the diagonal line and the points
# Line first so points are drawn on top
chart_layers = diagonal_line + lines + points

# 5. Apply faceting to the layered chart
corr_plots = chart_layers.facet(
  data=scatter_df, # Provide the data for faceting here
  # Add row faceting by cyclephase
  row=alt.Row('cyclephase', header=alt.Header(titleOrient="right", labelOrient="right", title=None)),
  column=alt.Column('lineage', header=alt.Header(titleOrient="top", labelOrient="top", title=None)), # Facet by lineage, remove default header title
  columns=3 # Corresponds to col_wrap=3
).resolve_scale(
  x='independent', # Don't share x-axis scale/limits
  y='independent', # Don't share y-axis scale/limits
  color='independent' # Don't share color scale/limits
).properties(
  title=alt.TitleParams( # Set overall title
      f'{metric_to_plot}: EV vs REF & BIO vs REF',
      anchor='middle' # Center the title
      )
)

# Display the chart
corr_plots.interactive() # Enable zooming and panning and tooltips and selection and other fun interactivity
```

### Moran's autocorrelation

And now for the Moran's I compared to the Morans' simulated FDR (based on 1000 iterations). The Moran's I is a measure of spatial autocorrelation, and the FDR is a measure of how significant the Moran's I is compared to random distributions. We will plot the Moran's I against the FDR for each cell type and lineage, with a horizontal line at FDR = 0.05 to indicate significance.

```{python}
# Filter for Moran's I metrics
moran_df = stats_df[stats_df['metric'].isin(['Moran I', 'Moran I FDR'])].copy()

# Pivot the table to get metrics as columns
moran_pivot = (
  moran_df.pivot_table(
    index=['slide_id', 'celltype', 'lineage', 'comparison', 'cyclephase'],
    columns='metric',
    values='value'
  )
  .reset_index()
  .rename_axis(None, axis=1) # Remove the 'metric' name from columns index
)

# Create dummy slide_id by appending comparison
moran_pivot['dummy_slide_id'] = moran_pivot['slide_id'].astype(str) + '_' + moran_pivot['comparison']

# --- Pivot for Heatmap Data and Mask ---
# Pivot for Moran I values (contains NaNs where data is missing)
heatmap_data = moran_pivot.pivot(index='celltype', columns='dummy_slide_id', values='Moran I')

# Pivot for Moran I FDR values (contains NaNs where data is missing)
fdr_data = moran_pivot.pivot(index='celltype', columns='dummy_slide_id', values='Moran I FDR')

# Create the mask: True where FDR >= 0.05 OR where FDR is NaN (missing)
# Mask should hide non-significant values.
mask = (fdr_data >= 0.05) | fdr_data.isna()

# --- Create column colors ---
# Need info for *all* columns in heatmap_data
col_info = moran_pivot[['dummy_slide_id', 'cyclephase', 'comparison']].drop_duplicates().set_index('dummy_slide_id')
# Ensure order matches heatmap columns and handle potential missing columns
heatmap_cols_info = col_info.reindex(heatmap_data.columns)

# 1. Cyclephase colors
unique_cyclephases = heatmap_cols_info['cyclephase'].dropna().unique()
palette_cycle = sns.color_palette("husl", len(unique_cyclephases))
cyclephase_color_map = dict(zip(unique_cyclephases, palette_cycle))
cyclephase_colors = heatmap_cols_info['cyclephase'].map(cyclephase_color_map)

# 2. Comparison colors
unique_comparisons = heatmap_cols_info['comparison'].dropna().unique()
palette_comp = sns.color_palette("Set2", len(unique_comparisons))
comparison_color_map = dict(zip(unique_comparisons, palette_comp))
comparison_colors = heatmap_cols_info['comparison'].map(comparison_color_map)

# Combine into a DataFrame for clustermap
# Providing a DataFrame to col_colors automatically triggers legend creation by seaborn
col_colors_df = pd.DataFrame({
  'Cycle Phase': cyclephase_colors,
  'Projection dataset': comparison_colors
})
col_colors_df.index = heatmap_data.columns # Ensure index matches heatmap columns

# Generate clustermap
g = sns.clustermap(
  heatmap_data.fillna(0), # Pass data with NaNs and significant/non-significant values
  mask=mask, # Pass the mask to hide non-significant values (where mask is True)
  row_cluster=True,
  col_cluster=True,
  col_colors=col_colors_df, # Pass the DataFrame with multiple annotations
  cmap="magma", # Or a diverging map like "vlag" if center is not None
  cbar_pos=(0.02, .82, .05, .16), # Adjust colorbar position
  figsize=(9, 9) # Adjust figsize if legends are cramped or cut off
)

# Create handles for Cycle Phase legend
cycle_handles = [mpatches.Patch(color=cyclephase_color_map[name], label=name) for name in unique_cyclephases]
# Add the first legend - Position relative to the FIGURE edge
legend1 = g.fig.legend(handles=cycle_handles, title='Cycle Phase', bbox_to_anchor=(0.78, 1), loc='upper left', borderaxespad=0.)

# Create handles for Projection dataset legend
comp_handles = [mpatches.Patch(color=comparison_color_map[name], label=name) for name in unique_comparisons]
# Add the second legend - Position below the first one
legend2 = g.fig.legend(handles=comp_handles, title='Projection dataset', bbox_to_anchor=(0.78, 0.92), loc='upper left', borderaxespad=0.)

plt.suptitle("Clustered Heatmap of Significant Moran's I (FDR < 0.05)", y=1.02) # Add title
plt.show() # Display the plot
```

:::

> As these plots can't be visualised using a single framework (contains both matplotlib and Altair libraries), then these are the subplots that are generated separately and compiled later manually

```{python}
# Try to make a layout plot with the spacers placeholder image
<<<<<<< HEAD
# raw_st_example = spacer_with_text(height=550, width=400)
# projection_example = spacer_with_text(height=550, width=400)
# (
#   (raw_st_example & projection_example) |
#   (boxplots & corr_plots)
# )
```


# Discussion

The results of the deconvolution and the spatial projections show that the deconvolution method is able to accurately predict the cell type abundances in the tissue samples. The dendrogram and barplot show that the deconvolution profiles are consistent across different samples, and the correlation heatmap shows that the deconvolution profiles are highly correlated with each other. The PCA plots show that the deconvolution profiles are able to separate the different samples based on their cell type abundances, and the spatial projections show that the deconvolution profiles are able to accurately predict the cell type abundances in the tissue samples.

The results of the Moran's I analysis show that the deconvolution profiles are spatially autocorrelated, indicating that the cell type abundances are not randomly distributed in the tissue samples. The FDR analysis shows that the Moran's I values are significant, indicating that the deconvolution profiles are able to accurately predict the cell type abundances in the tissue samples.


Weaknesses and improvements:

* We assume that the cell type abundances in the tissue samples are the same as the cell type abundances in the EVs, which may not be true. Further work is needed to validate this assumption.
* Further work is needed to benchmark VAE models against other deconvolution methods, such as CIBERSORTx and MuSiC.
* The deconvolution method is not able to accurately predict the cell type abundances in all samples, and further work is needed to improve the accuracy of the deconvolution method.
* This study only focuses on the mRNA of the EVs, and further work could be done to detect the origin of EV's based on the protein content of the EVs, the surface markers of the EVs, or the lipid content of the EVs.
=======
raw_st_example = spacer_with_text(height=550, width=400)
projection_example = spacer_with_text(height=550, width=400)
(
  (raw_st_example & projection_example) |
  (boxplots & corr_plots & morans_chart)
)
```
>>>>>>> refs/remotes/origin/master
