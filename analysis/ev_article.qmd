---
title: "Extracellular Vesicle Spatiotemporal Deconvolution Recapitulates the Dynamic Nature of the Human Endometrium"
format:
  html:
    code-fold: true
    code-tools: true
    embed-resources: true
    self-contained-math: true
jupyter: python3
---

This document contains the condensed form of analysis, figures and some more technical parts of the final article.

> **This** is a commentary text, it will not be included in the final report.

This is a citation as a [simple link](doi:10.1101/2023.11.03.564728), I will collect the links later on and put them in the references section.

# Prelude

## Load data and environment

Setup the environment and import dependencies.

1. Load the dependencies, set up multithreading.
2. Set color groups and values.

```{python}
#| output: false

import re
import glob
import warnings
import numpy as np
import pandas as pd
import anndata as an
import scanpy as sc
import squidpy as sq
import altair as alt
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as mpatches
from os import getenv
from pathlib import Path
from dotenv import load_dotenv
from IPython.display import HTML
from sklearn.decomposition import PCA
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
from umap import UMAP # Changed import style
from sklearn.preprocessing import normalize

## import the functions used in this report (got too long to include them in the report)
try: from analysis.helpers.deconvo_functions import *
except ImportError: from helpers.deconvo_functions import *

## import the functions used in this report (got too long to include them in the report)
try: from analysis.helpers.projection_functions import *
except ImportError: from helpers.projection_functions import *

## load the environment variables from the .env file
load_dotenv()
if getenv("DATA_FOLDER") is None:
  load_dotenv(Path.cwd() / ".env")

proj_folder = getenv("PROJ_FOLDER")
anndata_folder = getenv("ANNDATA_FOLDER")
atlas_folder = getenv("ATLAS_FOLDER")
data_folder = getenv("DATA_FOLDER")
st_folder = getenv("ST_FOLDER")
raw_data_folder = getenv("RAW_DATA_FOLDER")

# some other dataset locations
snapshot_an_loc = Path(data_folder).expanduser() / "sc_deconv_snapshot.h5ad"
comb_data_loc = Path(data_folder).expanduser() / "combined" / "comb_all_batch.feather"
comb_raw_data_loc = Path(data_folder).expanduser() / "combined" / "comb_all_raw.feather"
comb_pheno_loc = Path(data_folder).expanduser() / "combined" / "comb_all_pheno.tsv"
ccht_data_loc = Path(data_folder).expanduser() / "filtered" / "annot_raw.feather"
ccht_tpm_loc = Path(data_folder).expanduser() / "filtered" / "annot_tpm.feather"
ccht_data_unfilt_loc = Path(data_folder).expanduser() / "filtered" / "annot_raw_unfilt.feather"
ccht_tpm_unfilt_loc = Path(data_folder).expanduser() / "filtered" / "annot_tpm_unfilt.feather"
ccht_pheno_loc = Path(data_folder).expanduser() / "filtered" / "phenotype.tsv"
ccht_pheno_unfilt_loc = Path(data_folder).expanduser() / "filtered" / "phenotype_unfilt.tsv"
fractions_folder = Path(data_folder) / "tape_fractions"
fractions_file_loc = fractions_folder / "ccht_fracs.tsv"
fractions_file_loc_comb = fractions_folder / "comb_uf_fracs.tsv"
fractions_file_loc_comb_raw = fractions_folder / "comb_fracs_raw.tsv"
```

Load in the datasets:

* the reference single cell dataset from the HECAv2 (`sc_dat`).
* bulk transcriptomes from UF derived EV's of endometrium and biopsies (`ccht_uf_raw`).
* phenotype table for the EV and biopsy samples (`ccht_uf_pheno`).
* bulk transcriptomes from UF derived EV's of endometrium and Vigano et al. EV transcriptomes (`comb_uf_raw`).
* phenotype table for the EV and Vigano et al. samples (`comb_uf_pheno`).

```{python}
#| output: false

## load in the modified HECA atlas
sc_dat = an.read_h5ad(snapshot_an_loc)

## load in the EV CCHT only data
terminator = [] # some samples to exclude
ccht_uf_raw = pd.read_feather(ccht_data_loc).set_index("gene_id").iloc[:-1]
ccht_uf_tpm = pd.read_feather(ccht_tpm_loc).set_index("gene_id").iloc[:-1]
ccht_uf_pheno = pd.read_table(ccht_pheno_loc).set_index("samplename").assign(
    cyclephase=lambda x: 
      pd.Categorical(x.cyclephase, categories=["pro", "pre", "rec", "post"], ordered=True)
    )
ccht_uf_pheno = ccht_uf_pheno.query("samplename not in @terminator and samplename in @ccht_uf_raw.columns")
ccht_uf_unfilt_raw = pd.read_feather(ccht_data_unfilt_loc).set_index("gene_id").iloc[:-1]
ccht_uf_unfilt_tpm = pd.read_feather(ccht_tpm_unfilt_loc).set_index("gene_id").iloc[:-1]
ccht_uf_pheno_unfilt = pd.read_table(ccht_pheno_unfilt_loc).set_index("samplename").assign(
    cyclephase=lambda x: 
      pd.Categorical(x.cyclephase, categories=["pro", "pre", "rec", "post"], ordered=True)
    )
ccht_uf_raw = ccht_uf_raw.drop(columns=terminator)

## load in the EV combined dataset phenotype for the fractions
comb_batch = pd.read_feather(comb_data_loc).set_index("gene_id").drop(columns=terminator)
comb_raw = pd.read_feather(comb_raw_data_loc).set_index("external_gene_name").drop(columns=terminator)
comb_all_pheno = (
  pd.read_table(comb_pheno_loc)
  .set_index("samplename")
  .query("samplename not in @terminator")
)
comb_uf_pheno = (
  comb_all_pheno
  .assign(dataset = lambda x: np.where(x.dataset == "HUT", x.dataset, "Vigano"))
  .query("cyclephase in ['rec', 'pre'] and group == 'UF'")
)

## load in the fractions predicted by the latest trained model
frac_pred = pd.read_table(fractions_file_loc, sep="\t", index_col=0)
frac_comb = pd.read_table(fractions_file_loc_comb, sep="\t", index_col=0)
frac_comb_raw = pd.read_table(fractions_file_loc_comb_raw, sep="\t", index_col=0)

general_cells = ( # associate celltypes with the lineage information in the sc_dat.obs
  sc_dat.obs
  .loc[:, ["lineage", "celltype"]]
  .drop_duplicates("celltype")
  .set_index("celltype", drop=True)
  .reindex(frac_pred.columns.values)
)

# Color scale for the celltypes - TODO: extende the color range to not repeat
global_color_scale = alt.Scale(domain=general_cells.index.unique().tolist(), scheme="category20")
```

We also load in the different statistical testing tables for CCHT dataset.

```{python}
ccht_bio_stat = pd.read_excel(fractions_folder / "ccht_bio.xlsx", index_col=0)
ccht_uf_stat = pd.read_excel(fractions_folder / "ccht_uf.xlsx", index_col=0)
ccht_comp_stat = pd.read_excel(fractions_folder / "ccht_comp.xlsx", index_col=0)
```

Featurecounts results for the samples from the MultiQC report.

```{python}
features_ev = (
  pd.read_table(
    Path(raw_data_folder) / "multiqc/star_rsem/multiqc_data/multiqc_featurecounts_biotype_plot.txt"
    )
  .rename(columns={"Sample": "samplename"})
  # .query("samplename in @frac_pred.index") # don't filter out  here
  .set_index("samplename")
)
```

QualiMap results for the samples from the MultiQC report.

```{python}
qualimap_ev = (
  pd.read_table(
    Path(raw_data_folder) / "multiqc/star_rsem/multiqc_data/qualimap_rnaseq_genome_results.txt"
    )
  .rename(columns={"Sample": "samplename"})
  .set_index("samplename")
)
```


The preprocessed spatial slides with spatial deconvolution

```{python}
gen_sc_file = Path(anndata_folder).expanduser() / "gen_sc_ev.h5ad"
gen_ccht_ev = sc.read_h5ad(gen_sc_file, backed="r").to_memory()
gen_sc_file = Path(anndata_folder).expanduser() / "gen_sc_biopsy.h5ad"
gen_ccht_bio = sc.read_h5ad(gen_sc_file, backed="r").to_memory()
```

```{python}
slide_ids = ["152807", "152811"]
data_directory = Path(anndata_folder).expanduser()
# load only the early secretory samples
adata_collection = load_spatial_data(data_directory)
# create the subset using a dictionary comprehension
adata_collection = {key: value for key, value in adata_collection.items() if key[0] in set(slide_ids)}
```

```{python}
# some preliminary metrics
jaccard_thresh = 0.25 # Use lower quartile for Jaccard and Centroid distance
# but then read in the stats table anyways
stats_df = pd.read_csv(Path(data_folder).expanduser() / "st_stats_table.csv", index_col=0)
```

# Methods

## Pre-processing pipeline for the RNA-seq data

```{bash}
#| code-fold: false
#| eval: false
#| echo: true

## nf-core/rnaseq v3.12 (https://nf-co.re/rnseq/3.12.0)
nextflow run nf-core/rnaseq \
  -r 3.12.0 \
  --input samplesheet_mrna.csv \
  --genome GRCh37 \
  --aligner star_rsem \
  --outdir "./results_mrna/" \
  -c nextflow.config \
  -profile singularity
```

## Differential expression analysis

>Not used currently in the report, but left in here for future reference.

Differential expression (DE) analysis was done in R (v4.3) programming language. For differential analysis, we used both DESeq2 and limma-voom algorithms to measure the differences between gene expression levels in different sample groups and to perform statistical testing on the gene-wise differences [[DESeq2](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8), [limma-voom](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29)]. While DESeq2 DE results were used for downstream analysis, we used the limma-voom toolset as an alternative approach as it has been shown to have more stringent multiple hypothesis testing in regards to type I error [[Robles et al.](https://link.springer.com/article/10.1186/1471-2164-13-484), [Soneson et al.](https://link.springer.com/article/10.1186/1471-2105-14-91)].

```{python}
# de_ccht_phases = pd.read_feather(Path(data_folder) / "filtered" / "de" / "voom_phases.feather").set_index("locus")
# de_ccht_group = pd.read_feather(Path(data_folder) / "filtered" / "de" / "voom_methods.feather").set_index("locus")
```

## Sample selection and quality control

The following code is an excerpt from the `ev_raw.r` script, describing the main filtering step:
```{r}
#| code-fold: false
#| eval: false
#| echo: true
#### FILTER
# HUT10, HUT1, HUT71, HUT53, HUT17 were excluded due to poor clustering
# HUT10 does not have a paired biopsy sample
# HUT33, HUT53, HUT17 were excluded due to low intronic proportion
removals <- c(
  "HUT71_UF", "HUT71_biopsy", "HUT71_biopsy_2", "HUT71_biopsy_3",
  "HUT10_UF", "HUT1_UF", "HUT1_biopsy",
  "HUT53_UF", "HUT53_biopsy", "HUT17_UF", "HUT17_biopsy"
)
# HUT23_UF was swapped with HUT23_biopsy based on clustering
```

## Deconvolutional model parameters

>Create supplementary figures visualising the training loss and the model performance.

```{python}
#| code-fold: false
#| eval: false
#| echo: true

model_params = {
  "celltype_key": "celltype",
  "top_marker_num": 250, # reduce it from the default parameter of 500
  "max_single_cells": round(len(sc_dat.obs.index) / 8),
  "ratio_num": 1,
  "gpu": 0
}

frac_params = {
  "batch_size": 512,
  "epochs": 1000, # looking at loss plot then 500 seems to be already enough, but 1000 seems to have more accurate representatoin of the cell types.
  "method": "tape", # define this, otherwise defaults for scaden
  "scaler": "ss", # harmonises distributions better
  "mode": "high-resolution" # for using VAE's for cell type inference
}
```

# Results with Figures

## FIG 1: Study Design

Main points of interest:

* Bulk samples are paired, biopsy and EV samples are taken from the same patients.
* We observed the featureCounts mRNA ratio to other transcript types to indicate the quality of the samples, especially in the EV samples with lower genomic input.
* We have also included samples from the late-secretory phase of the menstrual cycle to show the differences in the cell type proportions leading up to the decidualisation of the endometrium.

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Analysis Steps {.unnumbered .unlisted}

```{python}
# placeholder image
study_schema = spacer_with_text(height=400, width=580)
```

### Overview of the Samples {.unnumbered .unlisted}

> Figure out how to visualise all the different celltypes in per cycle phase.

```{python}
# barplot of the number of samples throughout the cycle phase
barplot_ev_sum = alt.Chart(ccht_uf_pheno).mark_bar().encode(
  x=alt.X("cyclephase:N").title(""),
  y=alt.Y("count(group):Q").title("Nr. of Samples"),
  color=alt.Color("group:N").legend(orient="bottom", titleOrient="left")
).properties(width=150, height=225)


# include single cell data overview as extra column
barplot_sc_sum = alt.Chart(
  sc_dat.obs[["cyclephase", "samplename", "dataset"]].drop_duplicates()
).mark_bar().encode(
  x=alt.X("cyclephase:N").title("").axis(labelAngle=-45),
  y=alt.Y("count(dataset):Q").title("Nr. of Donors"),
  color=alt.Color("dataset:N").legend(orient="bottom", titleOrient="top", columns=2)
).properties(width=150, height=225)

(barplot_ev_sum & barplot_sc_sum).resolve_scale(color="independent").interactive()
```

### Feature Counts {.unnumbered .unlisted}

Here we look at only the final samples that were selected for the analysis, the raw featurecounts table is in Supplementary Fig 1.

Plot 10 top features per FeatureCounts output on log scale. Show the cutoff point for QC of 15% proteion coding RNA reads.

```{python}
# Identify biotype columns and calculate total counts
biotype_cols = features_ev.columns
biotype_counts = features_ev[biotype_cols].sum().sort_values(ascending=False)

# Get the top 10 biotypes
top_biotypes = biotype_counts.head(10).index.tolist()
# Calculate total counts per sample for the initially selected top_biotypes
sample_totals = features_ev[top_biotypes].sum(axis=1)

# Melt the DataFrame for plotting, including only the top biotypes
df_melted = (
  features_ev
  .reset_index()
  .query("samplename in @frac_pred.index")
  .melt(id_vars=['samplename'], value_vars=top_biotypes, var_name='biotype', value_name='count')
)

# Calculate percentage relative to the sum of these top_biotypes for that sample
df_melted['percentage'] = df_melted.apply(
  lambda row: (row['count'] / sample_totals[row['samplename']]) * 100 if sample_totals[row['samplename']] > 0 else 0, 
  axis=1
)

# Create a new column for the sample group
df_melted['sample_group'] = df_melted['samplename'].apply(lambda x: 'biopsy' if 'biopsy' in x else 'UF')

# --- Plotting logic starts here ---

# Separate data for protein_coding and other biotypes
df_protein_coding = df_melted[df_melted['biotype'] == 'protein_coding'].copy()
df_other_biotypes = df_melted[df_melted['biotype'] != 'protein_coding'].copy()

# Define the sort order for other biotypes (maintaining original sort order from top_biotypes)
# Ensure 'protein_coding' is excluded if it was in top_biotypes
other_biotypes_sorted_list = [bt for bt in top_biotypes if bt != 'protein_coding']

# Plot for protein_coding
protein_coding_plot = alt.Chart(df_protein_coding).mark_boxplot(extent=1.5).encode(
  x=alt.X('biotype:N', title=None).axis(labelAngle=-30),
  y=alt.Y('percentage:Q', title='Percentage (%)').scale(domain=(80, 100)),
  color=alt.Color('sample_group:N', title='Sample Group').legend(orient="top", titleOrient="left"),
  xOffset='sample_group:N'
).properties(height=150, width=60)

threshold_line = alt.Chart(pd.DataFrame({'y': [90]})).mark_rule(strokeDash=[5,5], color='grey').encode(y='y:Q')
protein_coding_chart_final = protein_coding_plot + threshold_line

# Plot for other top biotypes
other_biotypes_plot = alt.Chart(df_other_biotypes).mark_boxplot(extent=1.5).encode(
  x=alt.X('biotype:N', title='10 Top Biotypes', sort=other_biotypes_sorted_list).axis(labelAngle=-30),
  y=alt.Y('percentage:Q', title=None), # Independent y-axis scale
  color=alt.Color('sample_group:N').legend(None), # Hide legend, will be shared
  xOffset='sample_group:N'
).properties(height=150, width=450)

featurecounts_chart = protein_coding_chart_final | other_biotypes_plot
featurecounts_chart.show()
```

:::

```{python}
(
  (study_schema & featurecounts_chart).resolve_scale(color="independent") | 
  (barplot_ev_sum & barplot_sc_sum).resolve_scale(color="independent")
)
```

## FIG 2: Cell Type Deconvolution Profiles throughout the Menstrual Cycle

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Proportions Plot of both Biopsy and EV {.unnumbered .unlisted}

```{python}
fractions_long = peruvian_transform(
  fractions=frac_pred,
  phenotype=ccht_uf_pheno,
  general_cells=general_cells,
  grouping_ids=["cyclephase", "group"]
)

peruvian_bio_ev = peruvian_grouped(
  fractions_df=fractions_long,
  grouping_id="group",
  global_color_scale=global_color_scale,
  dims=(200, 150)
)

peruvian_bio_ev.show()
```

### Biplot of the Fractions {.unnumbered .unlisted}

```{python}
biplot, pca = biplot_fractions(
  frac_pred,
  ccht_uf_pheno,
  color_field="cyclephase",
  style_field="group",
  text_limit = 0.04, # controls on how much labels are shown
  dims = (400, 400)
  )
biplot.show()
```

In addition, make a histogram of the main loadings to make the contributions more clearer. `TODO: make it into percentages?`

```{python}
def format_loadings(pca_obj, celltypes):
  """
  Get the euclidean distance of explained variance per component of `pca_obj`.
  Generate a dataframe with the "Variance Explained" and the "Feature" column from `celltypes` list.
  """
  loadings = np.linalg.norm(pca_obj.components_.T * np.sqrt(pca_obj.explained_variance_), axis=1)
  return pd.DataFrame({
    "Variance Explained": loadings, "Feature": celltypes
  }).sort_values("Variance Explained", ascending=False).reset_index(drop=True)

pca_all = pca # save it with another name for clarity
loadings_all = format_loadings(pca_all, frac_pred.columns).rename(columns={"Variance Explained": "Combined"}).set_index("Feature")

pheno_tmp = ccht_uf_pheno.query("group == 'UF'")
_, pca_uf = biplot_fractions(frac_pred.loc[pheno_tmp.index], pheno_tmp, color_field="cyclephase")
loadings_uf = format_loadings(pca_uf, frac_pred.columns).rename(columns={"Variance Explained": "UF"}).set_index("Feature")

pheno_tmp = ccht_uf_pheno.query("group == 'biopsy'")
_, pca_bio = biplot_fractions(frac_pred.loc[pheno_tmp.index], pheno_tmp)
loadings_bio = format_loadings(pca_bio, frac_pred.columns).rename(columns={"Variance Explained": "Biopsy"}).set_index("Feature")


## The plot part - visualise all the different loadings
loadings_combined = (
  pd.concat([loadings_all, loadings_uf, loadings_bio], axis=1)
  .stack()
  .reset_index()
  .rename(columns={"level_1": "Group", 0: "Variance Explained"})
  )

loadings_plt = alt.Chart(loadings_combined).mark_line(
    point=alt.OverlayMarkDef(filled=False, fill="white", size=10)
  ).encode(
  x=alt.X("Feature:N", sort=None).axis(labelAngle=-60),
  y=alt.Y("Variance Explained:Q"),
  color=alt.Color("Group:N")
).properties(
  title='Loadings for Principal Component',
  width=400,
  height=150
)

loadings_plt.show()
```

### Testing the Differences of the Deconvolution Proportions through Cycle Phases {.unnumbered .unlisted}

Here we create a visual representation of the statistical testing and correlation analysis results of the UF and Biopsy samples. We present the most statistically significant changes throughout the cycle phases.

```{python}
# Helper function to swap group1 and group2 in the DataFrame for specified pairs
def swap_groups(df, to_swap):
  for g1, g2 in to_swap:
    stats_view = (df.group1 == g1) & (df.group2 == g2)
    swapped_view = df.loc[stats_view].rename(columns={"group1": "group2", "group2": "group1"})
    swapped_view["meandiff"] *= -1
    df.loc[stats_view] = swapped_view
  return df

# Configuration for data processing and plotting
swapper = [("post", "rec"), ("rec", "pre"), ("pre", "pro")]
comp_order = ["pro_vs_pre", "pre_vs_rec", "rec_vs_post"]
cycle_order = ["pro", "pre", "rec", "post"]
plt_width, plt_height = (1000, 150) # Plot dimensions

from itertools import product

# Prepare base statistical data
base_data = (
  pd.concat([ccht_bio_stat.assign(method="bio"), ccht_uf_stat.assign(method="uf")])
  .query("`anova p-val` <= 0.05")
  .pipe(swap_groups, swapper)
  .assign(comparison_orig=lambda x: x.group1 + "_vs_" + x.group2)
)

# Create a scaffold for all desired combinations
unique_celltypes = base_data.celltype.unique()
all_methods = ['bio', 'uf']
full_scaffold = pd.DataFrame(
  list(product(unique_celltypes, all_methods, comp_order)),
  columns=['celltype', 'method', 'comparison']
)

# Merge scaffold with base_data and derive final columns
stat_comb_prim = (
  pd.merge(
    full_scaffold,
    base_data.rename(columns={'comparison_orig': 'comparison'}),
    on=['celltype', 'method', 'comparison'],
    how='left' # Keep all scaffold rows, fill missing data with NaN
  ).assign(
    group1=lambda df: df['comparison'].str.split('_vs_', expand=True)[0],
    group2=lambda df: df['comparison'].str.split('_vs_', expand=True)[1],
    p_stars=lambda x: np.select(
        [x["p-adj"] <= 0.001, x["p-adj"] <= 0.01, x["p-adj"] <= 0.05, True],
        ["***", "**", "*", ""], default=""
    ),
    meandiff_format=lambda x: "Î” " + x.meandiff.mul(100).round(2).astype(str) + "%",
    padj_format=lambda x: np.select(
        [x["p-adj"].isna(), x["p-adj"] < 0.01],
        ["FDR NA", "FDR <0.01"],
        default="FDR " + x["p-adj"].round(2).astype(str)
    )
  ).join(general_cells, on="celltype") # Add lineage information
  .assign(comparison_cat=lambda df: pd.Categorical(df['comparison'], categories=comp_order, ordered=True))
  .sort_values(["lineage", "celltype", "method", "comparison_cat"])
  .drop(columns=['comparison_cat'])
  .reset_index(drop=True)
)

# Define heatmap cell height and calculate total plot height
heatmap_target_cell_height = 50
num_y_categories = stat_comb_prim.celltype.nunique()
calculated_heatmap_height = heatmap_target_cell_height * num_y_categories if num_y_categories > 0 else plt_width

```

For the Biopsy samples comparison:

```{python}
stat_comb = stat_comb_prim.query("method == 'bio'")
stat_comb_celltypes = stat_comb.celltype.drop_duplicates().values

# create a dummy dataframes for the custom scale hack
# This dataframe seems intended for a very specific annotation,
# as 'celltype' is fixed to the first unique celltype.
stat_tmp_groups = pd.DataFrame({
  "base": cycle_order,
  "celltype": stat_comb_celltypes[-1],
  "loc": np.linspace(0,1,len(cycle_order))
  })

# set up basechart for the Y axis (previously X) and X axis (previously Y)
base_chart = alt.Chart(stat_comb).encode(
  x=alt.X("comparison:N", sort=comp_order).axis(labels=False, ticks=False, title=None),
  y=alt.Y("celltype:N", sort=stat_comb_celltypes).axis(labels=True, title=None)
)

# the base heatmap
heatmap = base_chart.mark_rect().encode(
  color=alt.Color("meandiff:Q").scale(scheme="blueorange", domain=[-.2,.2]).legend(None))

# the grey background for the missing values
grey_background = base_chart.mark_rect().encode(
  color=alt.condition(alt.datum.meandiff == None, alt.value("lightgrey"), alt.value(None)))

# This layer creates a color strip for lineages, positioned to the right of the main plot.
yaxis_color_strip = alt.Chart(stat_comb).mark_rect().encode(
  y=alt.Y("celltype:N", sort=stat_comb_celltypes),
  xOffset=alt.value(10), # was yOffset, using o, increased for spacing
  color=alt.Color("lineage:N").legend(None)
)

# the significance testing texty part
base_text = base_chart.encode(
  x=alt.X("comparison:N", sort=comp_order).axis(labels=False, ticks=False, title=None))
# Use dy for vertical positioning, dx for horizontal if needed (or align)
text_overlay_stars = base_text.mark_text(fontWeight="bold", fontSize=24, align="center", dy=-10).encode(
  text=alt.Text("p_stars"))
text_overlay_pval = base_text.mark_text(fontSize=10, align="center", dy=0).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("padj_format:N")))
text_overlay_diff = base_text.mark_text(fontSize=10, align="center", dy=12).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("meandiff_format:N")))

# This layer creates custom text labels.
custom_annotation_layer = alt.Chart(stat_tmp_groups).mark_text(clip=False, align="center").encode(
  y=alt.Y("celltype:N", sort=stat_comb_celltypes),
  x=alt.X("loc:Q").axis(labels=False, ticks=False, title="Biopsy"),
  yOffset=alt.value(heatmap_target_cell_height + 10), # Adjust as needed to position above x-axis title/labels
  text=alt.Text("base")
)

comp_stats_bio_plt = (
  yaxis_color_strip + grey_background + heatmap +
  text_overlay_stars + text_overlay_diff + text_overlay_pval +
  custom_annotation_layer
).properties(width=plt_height, height=calculated_heatmap_height) # Use calculated height

comp_stats_bio_plt.show()
```

For the UF samples comparison:

```{python}
stat_comb = stat_comb_prim.query("method == 'uf'")
stat_comb_celltypes = stat_comb.celltype.drop_duplicates().values

# create a dummy dataframes for the custom scale hack
stat_tmp_groups = pd.DataFrame({
  "base": cycle_order,
  "celltype": stat_comb_celltypes[-1],
  "loc": np.linspace(0,1,len(cycle_order))
  })

# set up basechart for the Y axis (previously X) and X axis (previously Y)
base_chart = alt.Chart(stat_comb).encode(
  x=alt.X("comparison:N", sort=comp_order).axis(labels=False, ticks=False, title=None, titleY=25),
  y=alt.Y("celltype:N", sort=stat_comb_celltypes).axis(labels=False, ticks=False, title=None)
)

# the base heatmap
heatmap = base_chart.mark_rect().encode(
  color=alt.Color("meandiff:Q").scale(scheme="blueorange", domain=[-.2,.2]).legend(None))

# the grey background for the missing values
grey_background = base_chart.mark_rect().encode(
  color=alt.condition(alt.datum.meandiff == None, alt.value("lightgrey"), alt.value(None)))

# This layer creates a color strip for lineages, positioned to the right of the main plot.
yaxis_color_strip = alt.Chart(stat_comb).mark_rect().encode(
  y=alt.Y("celltype:N", sort=stat_comb_celltypes).axis(title=None),
  x2=alt.value(-10), # set to 0 to not draw it behind the main heatmap (shows small lines)
  color=alt.Color("lineage:N").legend(None)
)

# the significance testing texty part
# base_text overrides the x-axis of the base_chart for text mark positioning
base_text = base_chart.encode(
  x=alt.X("comparison:N", sort=comp_order).axis(labels=False, ticks=False, title=None))
# Use dy for vertical positioning of text
text_overlay_stars = base_text.mark_text(fontWeight="bold", fontSize=24, align="center", dy=-10).encode(
  text=alt.Text("p_stars"))
text_overlay_pval = base_text.mark_text(fontSize=10, align="center", dy=0).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("padj_format:N")))
text_overlay_diff = base_text.mark_text(fontSize=10, align="center", dy=12).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("meandiff_format:N")))

# This layer creates custom text labels for the x-axis.
custom_annotation_layer = alt.Chart(stat_tmp_groups).mark_text(clip=False, align="center").encode(
  y=alt.Y("celltype:N", sort=stat_comb_celltypes),
  x=alt.X("loc:Q").axis(labels=False, ticks=False, title="UF"),
  yOffset=alt.value(heatmap_target_cell_height + 10),
  text=alt.Text("base")
)

comp_stats_uf_plt = (
  yaxis_color_strip + grey_background + heatmap +
  text_overlay_stars + text_overlay_diff + text_overlay_pval +
  custom_annotation_layer
).properties(width=plt_height, height=calculated_heatmap_height) # Use calculated height

comp_stats_uf_plt.show()
```

And combined on top of each other

```{python}
# remove the legend from one of those plots, id does not sync it for some reason
# TODO: the lineage colors are still not synchronised
comp_stats_plt = (comp_stats_bio_plt | comp_stats_uf_plt).resolve_scale(x="independent")
comp_stats_plt.show()
```

:::

Combining them all into one.

```{python}
# have to resolve the color scale, otherwise the loadings_plt will override the biplot's scale
(
  peruvian_bio_ev | 
  (biplot & loadings_plt).resolve_scale(color="independent", shape="independent") | 
  comp_stats_plt
).resolve_scale(color="independent", shape="independent").show()
```

## FIG 3: Comparison of Biopsy and EV Sampling Methods

Here we focus on the comparison of the paired sample profiles from **both** biopsy and UF origin.

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Dendro-barplot of Fractions {.unnumbered .unlisted}

```{python}
# the dendrogram part
linkage_mat = linkage(frac_pred, method="complete", optimal_ordering=True)
dend_obj = dendrogram(linkage_mat, labels=ccht_uf_pheno.index, no_plot=True)
dendro_marks = pd.DataFrame({"labels": dend_obj["ivl"]}).reset_index().rename(columns={"index": "i"})
dendro_coord = get_df_coord(dend_obj)

# and transform the x and y coords to a suitable scale
scaler = .25
cols_xk = ["xk1", "xk2", "xk3", "xk4"]
cols_yk = ["yk1", "yk2", "yk3", "yk4"]
x_min, x_max = (dendro_coord[cols_xk].min(axis=None), dendro_coord[cols_xk].max(axis=None))
dendro_coord[cols_xk] = (dendro_coord[cols_xk] - x_min) / (x_max - x_min)
dendro_coord[cols_xk] *= (dendro_marks.shape[0] - 1)
dendro_coord[cols_yk] *= scaler/dendro_coord[cols_yk].max(axis=None) # scale the y heights
dendro_coord[cols_yk] += 1.18 # and shift up whole unit

base = alt.Chart(dendro_coord, view=alt.ViewConfig(strokeWidth=0))
# the U shape is composed of a shoulder plus two arms, made with separate lines...
shoulder = base.mark_rule().encode(
    x=alt.X("xk2:Q", title="").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    x2=alt.X2("xk3:Q"),
    y=alt.Y("yk2:Q", title="").axis(None))
arm1 = base.mark_rule().encode(
    x=alt.X("xk1:Q").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    y=alt.Y("yk1:Q").axis(None),
    y2=alt.Y2("yk2:Q"))
arm2 = base.mark_rule().encode(
    x=alt.X("xk3:Q").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    y=alt.Y("yk3:Q").axis(None),
    y2=alt.Y2("yk4:Q"))

# chart_den = (shoulder + arm1 + arm2).properties(width=.98*plt_width, height=50)
chart_den = shoulder + arm1 + arm2
```

```{python}
# the barplot part
# make fracs long again - reuse previous peruvian_transform
fractions_long = (
  peruvian_transform(
    fractions=frac_pred,
    phenotype=ccht_uf_pheno,
    general_cells=general_cells
  )
  .rename(columns={"level_0": "samplename"})
  .set_index("samplename")
  .join(dendro_marks.set_index("labels"))
  .join(ccht_uf_pheno)
  .reset_index()
  .sort_values("i")
)

custom_labels = fractions_long.samplename.drop_duplicates().values.tolist()
# custom printer - by default the list is printed with newlines so that the js parses the list transposed
custom_labels_str =  ', '.join(f"'{label}'" for label in custom_labels)

base_bar = alt.Chart(fractions_long, view=alt.ViewConfig(strokeWidth=0))
barplot = base_bar.mark_bar(
  width=12
).encode(
  x=alt.X("i:Q").axis(
    title=None, grid=False, domain=False,
    tickCount=len(custom_labels),
    labelAngle=90,
    labelOverlap=False, 
    labelExpr=f"[{custom_labels_str}][datum.value]" # custom label values mapped
  ).scale(domain=[0,len(custom_labels)-1], padding=10),
  y=alt.Y("fractions:Q").axis(grid=False).scale(domain=[0,1]),
  color=alt.Color("lineage:N").scale(scheme="category10").legend(columns=1)
  )

# add the color groupings 
x_cycle_colors = barplot.mark_rect(clip=False, width=20).encode(
    y=alt.value(0), # for some reason this works
    y2=alt.value(-4),
    yOffset=alt.value(-12),
    color=alt.Color("cyclephase:N").scale(scheme="set1")
  )
x_method_colors = barplot.mark_rect(clip=False, width=20).encode(
    y=alt.value(0), # for some reason this works
    y2=alt.value(-16),
    yOffset=alt.value(-24),
    color=alt.Color("group:N").scale(scheme="set2")
  )
```

```{python}
dendro_barplot = (
  (chart_den + barplot + x_cycle_colors + x_method_colors)
  .resolve_scale(x="shared", y="shared", color="independent")
  .resolve_axis(y="independent")
  .properties(width=700, height=150)
)
dendro_barplot.show()
```

### Correlation Heatmap of the Paired Samples {.unnumbered .unlisted}

```{python}
# calculate the correlation matrix and prepare data for the plot
# first we create a phenotype file to order the samples after
prepped_pheno = (
  ccht_uf_pheno
  .loc[frac_pred.index]
  .assign(HUT=lambda x: x.index.str.extract(r"(HUT\d+)", expand=False))
  .sort_values(["cyclephase", "HUT"])
)

# select only samples with corresponding HUT pair
paired_samples_stem = prepped_pheno.HUT.value_counts().to_frame().query("count > 1").index
prepped_pheno = prepped_pheno.query("HUT in @paired_samples_stem")

# run a corr matrix with itself
corr_mat = (
  # transpose to run correlation against the samples
  frac_pred.loc[prepped_pheno.index].T.corr(method="spearman")
  # select out only cols with UF in columns and biopsy in rows
  .filter(regex="UF", axis=0).filter(regex="biopsy", axis=1)
  # stack it into long version for Altair
  .stack().rename("correlation").to_frame().reset_index(names=["y_vars", "x_vars"])
  # now add a cols with the locations of last groups
  .join(prepped_pheno[["cyclephase"]], on="x_vars")
  .join(prepped_pheno[["cyclephase"]], on="y_vars", lsuffix="_y")
)
```

```{python}
# Create Altair plot
base_heatmap = alt.Chart(corr_mat).mark_rect().encode(
    x=alt.X('x_vars:O', sort=corr_mat.x_vars.unique(), title=None).axis(offset=10),
    y=alt.Y('y_vars:O', sort=corr_mat.y_vars.unique(), title=None).axis(orient="right", offset=10),
    color=alt.Color('correlation:Q').scale(scheme='magma') # Quantitative for correlation values, using magma colormap
  )

# add the color groupings 
x_group_colors = base_heatmap.mark_rect().encode(
  x=alt.X('x_vars:O', sort=corr_mat.x_vars.unique(), title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase:N"),
  xOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

y_group_colors = base_heatmap.mark_rect().encode(
  y=alt.Y('y_vars:O', sort=corr_mat.y_vars.unique(), title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase_y:N").legend(None),
  yOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

# Layer heatmap and colors
final_chart = (x_group_colors + y_group_colors + base_heatmap).resolve_scale(
  x='shared', y='shared', color='shared'
)

# Display the chart
final_chart
```

### Volcano plot with the difference in deconvolution profiles {.unnumbered .unlisted}

Here we transform the deconvolution profiles into a volcano plot, where we show the differences in the proportions of the cell types between the biopsy and UF samples.

```{python}
## calculate the diffs
avg_uf = frac_pred.loc[prepped_pheno.query("group == 'UF'").index,].agg("mean")
avg_bio = frac_pred.loc[prepped_pheno.query("group == 'biopsy'").index,].agg("mean")
diff_df = pd.DataFrame({"diff": avg_uf - avg_bio}).join(ccht_comp_stat).rename(columns={"p-val": "pval"})
threshold_p = .05 / len(ccht_comp_stat.index)

## base plot
volcano_base = alt.Chart(
  diff_df.reset_index(), view=alt.ViewConfig(strokeWidth=0)
).mark_point(
  filled=True, opacity=.7
).encode(
  x=alt.X("diff:Q").scale(domain=[-.12, .12]).axis(title="difference", tickCount=4),
  y=alt.Y("pval:Q").scale(type="log", base=10, reverse=True).axis(title="p-value", tickCount=8),
  color=alt.condition(alt.datum.pval < threshold_p, alt.value("red"), alt.value("grey"))
)

## the text for the top two diff celltypes
volcano_annot = alt.Chart(
  diff_df.reset_index().sort_values("pval").head(4).assign(text_angle=lambda x: np.where(x["diff"] < 0, 330, 30))
).mark_text(align="center", dy=-8, angle=alt.expr(alt.datum.text_angle)).encode(
  x=alt.X("diff:Q"), y=alt.Y("pval:Q"),
  text=alt.Text("celltype:N")
)

## the dividing line
rule_tmp = pd.DataFrame({"threshold_p": [ threshold_p ]})
rule_y = alt.Chart(rule_tmp).mark_rule(color='black', strokeDash=[3,3]).encode(y="threshold_p")
volcano = volcano_base + volcano_annot + rule_y
volcano
```

:::

```{python}
(dendro_barplot & (final_chart | volcano)).resolve_scale(color="independent")
```

## FIG 4: Comparison of Vigano et al. and our sampling methods

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Dendro-barplot of Fractions {.unnumbered .unlisted}

```{python}
# the dendrogram part
linkage_mat = linkage(frac_comb.loc[comb_uf_pheno.index,], method="complete", optimal_ordering=True)
dend_obj = dendrogram(linkage_mat, labels=comb_uf_pheno.index, no_plot=True)
dendro_marks = pd.DataFrame({"labels": dend_obj["ivl"]}).reset_index().rename(columns={"index": "i"})
dendro_coord = get_df_coord(dend_obj)

# and transform the x and y coords to a suitable scale
scaler = .25
cols_xk = ["xk1", "xk2", "xk3", "xk4"]
cols_yk = ["yk1", "yk2", "yk3", "yk4"]
x_min, x_max = (dendro_coord[cols_xk].min(axis=None), dendro_coord[cols_xk].max(axis=None))
dendro_coord[cols_xk] = (dendro_coord[cols_xk] - x_min) / (x_max - x_min)
dendro_coord[cols_xk] *= (dendro_marks.shape[0] - 1)
dendro_coord[cols_yk] *= scaler/dendro_coord[cols_yk].max(axis=None) # scale the y heights
dendro_coord[cols_yk] += 1.18 # and shift up whole unit

base = alt.Chart(dendro_coord, view=alt.ViewConfig(strokeWidth=0))
# the U shape is composed of a shoulder plus two arms, made with separate lines...
shoulder = base.mark_rule().encode(
    x=alt.X("xk2:Q", title="").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    x2=alt.X2("xk3:Q"),
    y=alt.Y("yk2:Q", title="").axis(None))
arm1 = base.mark_rule().encode(
    x=alt.X("xk1:Q").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    y=alt.Y("yk1:Q").axis(None),
    y2=alt.Y2("yk2:Q"))
arm2 = base.mark_rule().encode(
    x=alt.X("xk3:Q").axis(grid=False).scale(domain=[0,len(dend_obj["ivl"])-1]),
    y=alt.Y("yk3:Q").axis(None),
    y2=alt.Y2("yk4:Q"))

# chart_den = (shoulder + arm1 + arm2).properties(width=.98*plt_width, height=50)
chart_den = shoulder + arm1 + arm2
```

```{python}
# the barplot part
# make fracs long again - reuse previous peruvian_transform
fractions_long = (
  peruvian_transform(
    fractions=frac_comb.loc[comb_uf_pheno.index],
    phenotype=comb_uf_pheno,
    general_cells=general_cells
  )
  .rename(columns={"level_0": "samplename"})
  .set_index("samplename")
  .join(dendro_marks.set_index("labels"))
  .join(comb_uf_pheno)
  .reset_index()
  .sort_values("i")
)

custom_labels = fractions_long.samplename.drop_duplicates().values.tolist()
# custom printer - by default the list is printed with newlines so that the js parses the list transposed
custom_labels_str =  ', '.join(f"'{label}'" for label in custom_labels)

base_bar = alt.Chart(fractions_long, view=alt.ViewConfig(strokeWidth=0))
barplot = base_bar.mark_bar(
  width=8
).encode(
  x=alt.X("i:Q").axis(
    title=None, grid=False, domain=False,
    tickCount=len(custom_labels),
    labelAngle=90,
    labelOverlap=False, 
    labelExpr=f"[{custom_labels_str}][datum.value]" # custom label values mapped
  ).scale(domain=[0,len(custom_labels)-1], padding=10),
  y=alt.Y("fractions:Q").axis(grid=False).scale(domain=[0,1]),
  color=alt.Color("lineage:N").scale(scheme="category10").legend(columns=1)
  )

# add the color groupings 
x_cycle_colors = barplot.mark_rect(clip=False, width=14).encode(
    y=alt.value(0), # for some reason this works
    y2=alt.value(-4),
    yOffset=alt.value(-12),
    color=alt.Color("cyclephase:N").scale(scheme="set1")
  )
x_method_colors = barplot.mark_rect(clip=False, width=14).encode(
    y=alt.value(0), # for some reason this works
    y2=alt.value(-16),
    yOffset=alt.value(-24),
    color=alt.Color("dataset:N").scale(scheme="set2")
  )
```

```{python}
dendro_bar = (
  (chart_den + barplot + x_cycle_colors + x_method_colors)
  .resolve_scale(x="shared", y="shared", color="independent")
  .resolve_axis(y="independent")
  .properties(width=500, height=150)
)
dendro_bar.show()
```


### Correlation Heatmap of UF samples {.unnumbered .unlisted}

```{python}
# run a corr matrix with itself and select out the interesting rows
corr_mat = (
  # transpose to run correlation against the samples, not celltypes
  frac_comb.loc[comb_uf_pheno.index].T.corr(method="spearman")
  # select out Vigano and CCHT in both axes
  .filter(regex="plus", axis=0).filter(regex="UF", axis=1)
)

corr_long = (
  corr_mat
  # stack it into long version for Altair
  .stack().rename("correlation").to_frame().reset_index(names=["y_vars", "x_vars"])
  # now add a cols with the locations of last groups
  .join(comb_uf_pheno[["cyclephase"]], on="x_vars")
  .join(comb_uf_pheno[["cyclephase"]], on="y_vars", lsuffix="_y")
)
```

Generate the X axis linkage plots.

```{python}
# the dendrogram part for axis X
linkage_mat = linkage(corr_mat.T, method="complete", optimal_ordering=True)
dend_obj = dendrogram(linkage_mat, labels=comb_uf_pheno.query("dataset == 'HUT'").index, no_plot=True)
dendro_marks_x = pd.DataFrame({"labels": dend_obj["ivl"]}).reset_index().rename(columns={"index": "i"})
dendro_coord = get_df_coord(dend_obj)

base = alt.Chart(dendro_coord, view=alt.ViewConfig(strokeWidth=0)) 
# the U shape is composed of a shoulder plus two arms, made with separate lines...
shoulder = base.mark_rule().encode(
    x=alt.X("xk2:Q", title="").axis(None),
    x2=alt.X2("xk3:Q"),
    y=alt.Y("yk2:Q", title="").axis(None))
arm1 = base.mark_rule().encode(
    x=alt.X("xk1:Q"),
    y=alt.Y("yk1:Q"),
    y2=alt.Y2("yk2:Q"))
arm2 = base.mark_rule().encode(
    x=alt.X("xk3:Q"),
    y=alt.Y("yk3:Q"),
    y2=alt.Y2("yk4:Q"))

chart_den_x = (shoulder + arm1 + arm2).properties(height=50, width=200)
```

Generate the Y axis linkage plots.

```{python}
# the dendrogram part for axis Y
linkage_mat = linkage(corr_mat, method="complete", optimal_ordering=True)
dend_obj = dendrogram(linkage_mat, labels=comb_uf_pheno.query("dataset == 'Vigano'").index, no_plot=True)
dendro_marks_y = pd.DataFrame({"labels": dend_obj["ivl"]}).reset_index().rename(columns={"index": "i"})
dendro_coord = get_df_coord(dend_obj)

base = alt.Chart(dendro_coord, view=alt.ViewConfig(strokeWidth=0))
# the U shape is composed of a shoulder plus two arms, made with separate lines...
shoulder = base.mark_rule().encode(
    y=alt.Y("xk2:Q", title="").axis(None),
    y2=alt.Y2("xk3:Q"),
    x=alt.X("yk2:Q", title="").axis(None).scale(reverse=True))
arm1 = base.mark_rule().encode(
    y=alt.Y("xk1:Q"),
    x=alt.X("yk1:Q").scale(reverse=True),
    x2=alt.X2("yk2:Q"))
arm2 = base.mark_rule().encode(
    y=alt.Y("xk3:Q"),
    x=alt.X("yk3:Q").scale(reverse=True),
    x2=alt.X2("yk4:Q"))

chart_den_y = (shoulder + arm1 + arm2).properties(width=50, height=600)
```

```{python}
# Create Altair plot
base_heatmap = alt.Chart(corr_long).mark_rect().encode(
    x=alt.X('x_vars:O', sort=dendro_marks_x.labels, title=None).axis(offset=10),
    y=alt.Y('y_vars:O', sort=dendro_marks_y.labels, title=None).axis(orient="right", offset=10),
    color=alt.Color('correlation:Q').scale(scheme='magma') # Quantitative for correlation values, using magma colormap
  )

# add the color groupings 
x_group_colors = base_heatmap.mark_rect().encode(
  x=alt.X('x_vars:O', sort=dendro_marks_x.labels, title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase:N"),
  xOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

y_group_colors = base_heatmap.mark_rect().encode(
  y=alt.Y('y_vars:O', sort=dendro_marks_y.labels, title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase_y:N").legend(None),
  yOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

# Layer heatmap and colors
final_chart = (x_group_colors + y_group_colors + base_heatmap).properties(width=150, height=600)

# Display the chart
final_chart
```

```{python}
dendro_corrplot = (
  (chart_den_y | chart_den_x & final_chart)
  .resolve_scale(x="independent", y="independent")
  .resolve_axis(x="independent", y="independent")
)

dendro_corrplot.show()
```

### PCA of UF Vigano and HUT samples

```{python}
# some params for the pcas
shape_range = ["diamond", "square"]
dims = {"height": 200, "width": 200}
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(frac_comb), columns=["PC1", "PC2"])
  .set_index(frac_comb.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_one = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N"),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Deconvolution with batch correction", **dims)
pca_one
```

### PCA of UF combined without batch correction

```{python}
# filter out biopsy samples
frac_tmp = frac_comb_raw.loc[~frac_comb_raw.index.str.contains("biopsy")]
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(frac_tmp), columns=["PC1", "PC2"])
  .set_index(frac_tmp.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_two = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N"),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Deconvolution without batch correction", **dims)
pca_two
```

### PCA of raw counts of combined UF

```{python}
# filter out biopsy samples
counts_tmp = comb_batch.T.loc[~comb_batch.T.index.str.contains("biopsy")]
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(counts_tmp), columns=["PC1", "PC2"])
  .set_index(counts_tmp.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_three = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N"),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Raw counts with batch correction", **dims)
pca_three
```

### PCA of batch adjusted counts of combined UF

```{python}
# filter out biopsy samples
counts_tmp = comb_raw.T.loc[~comb_raw.T.index.str.contains("biopsy")]
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(counts_tmp), columns=["PC1", "PC2"])
  .set_index(counts_tmp.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_four = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N"),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Raw counts without batch correction", **dims)
pca_four
```


:::

```{python}
pca_block = (pca_one & pca_two) | (pca_three & pca_four)
(
  (dendro_corrplot | pca_block & dendro_bar)
  .resolve_scale(x="independent", y="independent", color="independent", shape="independent")
)
```

## FIG 5: Spatial Projections

Given the nature of the data, we expect to see a high correlation between the projected biopsy and the reference raw scRNA-seq data. The projected UF data should be more dispersed, as the UF samples are not directly comparable to the biopsy samples. Still, the UF samples should show a similar pattern of cell type distribution as the biopsy samples, per the assumption that the abundances of cell types in the UF samples indicate where the EV's are coming from in the tissue.

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Example of a ST slide

```{python}
# show the example slide sample
adat = adata_collection[(slide_ids[0], "ref")].to_memory()
crop_coords = get_spatial_crop_coords(adat)
sq.pl.spatial_scatter(
  adat,
  color=[None], crop_coord=crop_coords,
  ncols=2
  )
```

### Example of the projected abundcances with single cell type

```{python}
# and then show a single exemplary cell type in different projections
# TODO: find a way to get the crop_coord from the adata object
cts = ["Glandular"]

sq.pl.spatial_scatter(
  adat,
  cmap='magma',
  color=cts,
  crop_coord=crop_coords,
  size=1.3, title="Reference"
)
sq.pl.spatial_scatter(
  adata_collection[(slide_ids[0], "ev")],
  cmap='magma',
  color=cts,
  crop_coord=crop_coords,
  size=1.3, title="EV"
)
sq.pl.spatial_scatter(
  adata_collection[(slide_ids[0], "bio")],
  cmap='magma',
  color=cts,
  crop_coord=crop_coords,
  size=1.3, title="Biopsy"
)
```

### Example of the UMAP clustering of generated single cell data

```{python}
# Plot with smaller size
sc.pl.embedding(gen_ccht_ev, basis='X_umap', color='lineage', title="EV pSC UMAP", legend_loc="on data")
sc.pl.embedding(gen_ccht_bio, basis='X_umap', color='lineage', title="Biopsy pSC UMAP", legend_loc="on data")
```

### The boxplots of different comparison methods

```{python}
# --- Data Preparation ---
plot_df_pairwise = stats_df[stats_df['comparison'].isin(['ev_vs_ref', 'bio_vs_ref'])].copy()
exclude_metrics = ["Pearson Correlation"]  # Metrics to exclude from visualization
col_wrap = 3  # Number of columns for facet wrapping

# Filter out excluded metrics
filtered_df = plot_df_pairwise[~plot_df_pairwise['metric'].isin(exclude_metrics)]

# --- Altair Plot Construction ---
# 1. Define the base boxplot
boxplot = alt.Chart(filtered_df).mark_boxplot(extent='min-max').encode(
  x=alt.X('lineage:N', title=None, axis=alt.Axis(labelAngle=45)),  # Rotate x-axis labels
  y=alt.Y('value:Q', title='Value'),  # Statistic value on Y-axis
  xOffset=alt.XOffset('comparison:N', title=None),  # Rotate x-axis labels
  color=alt.Color('comparison:N', legend=alt.Legend(title='Comparison'))  # Color by comparison
)

# 2. Apply faceting
boxplots = boxplot.facet(
  column=alt.Column('metric:N', title=None, header=alt.Header(labelOrient='top')),  # Facet by metric
  row=alt.Row('cyclephase:N', title=None, header=alt.Header(labelOrient='right'))  # Facet by cyclephase
).resolve_scale(
  x='independent',
  y='independent'
).properties(
  title=alt.TitleParams(
    'Boxplots of Statistics by Metric and Comparison',
    anchor='middle'  # Center the title
  )
)

# To display in a Jupyter environment:
boxplots
```

### Pearson correlation

```{python}
# 0. Prepare the data for the scatter plot
metric_to_plot = 'Pearson Correlation' # Choose a metric
scatter_df = (
  plot_df_pairwise[plot_df_pairwise['metric'] == metric_to_plot]
  # Add cyclephase to the index for faceting
  .pivot_table(index=['slide_id', 'celltype', 'lineage', 'cyclephase'], columns='comparison', values='value')
  .reset_index()
)
scatter_df.dropna(inplace=True) # Drop rows if one comparison is missing

# 1. Define the base scatter plot layer
# Data will be passed during faceting because we layer first
points = alt.Chart().mark_point(filled=True, size=60, opacity=0.7).encode(
  x=alt.X('ev_vs_ref', title='EV vs REF'), # Set axis title
  y=alt.Y('bio_vs_ref', title='BIO vs REF'), # Set axis title
  color=alt.Color('celltype', legend=alt.Legend(title="Celltype", orient='bottom-right', labelFontSize=9, offset=0)), # Add legend title
  tooltip=['slide_id', 'celltype', 'lineage', 'ev_vs_ref', 'bio_vs_ref'] # Tooltips
)

# 2. Prepare data for the y=x diagonal line
# Calculate overall min/max across both relevant columns IN THE FILTERED DATA
min_val = min(scatter_df['ev_vs_ref'].min(), scatter_df['bio_vs_ref'].min())
max_val = max(scatter_df['ev_vs_ref'].max(), scatter_df['bio_vs_ref'].max())
# Add a small buffer to ensure the line extends slightly beyond points
buffer = (max_val - min_val) * 0.05
min_val = min_val - buffer if min_val - buffer is not np.nan else 0 # Handle potential NaN from empty df
max_val = max_val + buffer if max_val + buffer is not np.nan else 1 # Handle potential NaN

# 3. Define the diagonal line layer and the connecting line layer
line_df = pd.DataFrame({'x': [min_val, max_val], 'y': [min_val, max_val]})
diagonal_line = alt.Chart(line_df).mark_line(
  color='black',
  strokeDash=[5,5], # Dashed line style
  opacity=0.25      # Corresponds to alpha=0.25
).encode(x='x', y='y')

# Create the line layer connecting points within each celltype per facet
lines = points.mark_line(opacity=0.2).encode(order='celltype')

# 4. Layer the diagonal line and the points
# Line first so points are drawn on top
chart_layers = diagonal_line + lines + points

# 5. Apply faceting to the layered chart
corr_plots = chart_layers.facet(
  data=scatter_df, # Provide the data for faceting here
  # Add row faceting by cyclephase
  row=alt.Row('cyclephase', header=alt.Header(titleOrient="right", labelOrient="right", title=None)),
  column=alt.Column('lineage', header=alt.Header(titleOrient="top", labelOrient="top", title=None)), # Facet by lineage, remove default header title
  columns=3 # Corresponds to col_wrap=3
).resolve_scale(
  x='independent', # Don't share x-axis scale/limits
  y='independent', # Don't share y-axis scale/limits
  color='independent' # Don't share color scale/limits
).properties(
  title=alt.TitleParams( # Set overall title
      f'{metric_to_plot}: EV vs REF & BIO vs REF',
      anchor='middle' # Center the title
      )
)

# Display the chart
corr_plots.interactive() # Enable zooming and panning and tooltips and selection and other fun interactivity
```

### Moran's autocorrelation

And now for the Moran's I compared to the Morans' simulated FDR (based on 1000 iterations). The Moran's I is a measure of spatial autocorrelation, and the FDR is a measure of how significant the Moran's I is compared to random distributions. We will plot the Moran's I against the FDR for each cell type and lineage, with a horizontal line at FDR = 0.05 to indicate significance.

```{python}
# Filter for Moran's I metrics
moran_df = stats_df[stats_df['metric'].isin(['Moran I', 'Moran I FDR'])].copy()

# Pivot the table to get metrics as columns
moran_pivot = (
  moran_df.pivot_table(
    index=['slide_id', 'celltype', 'lineage', 'comparison', 'cyclephase'],
    columns='metric',
    values='value'
  )
  .reset_index()
  .rename_axis(None, axis=1) # Remove the 'metric' name from columns index
)

# Create dummy slide_id by appending comparison
moran_pivot['dummy_slide_id'] = moran_pivot['slide_id'].astype(str) + '_' + moran_pivot['comparison']

# --- Pivot for Heatmap Data and Mask ---
# Pivot for Moran I values (contains NaNs where data is missing)
heatmap_data = moran_pivot.pivot(index='celltype', columns='dummy_slide_id', values='Moran I')

# Pivot for Moran I FDR values (contains NaNs where data is missing)
fdr_data = moran_pivot.pivot(index='celltype', columns='dummy_slide_id', values='Moran I FDR')

# Create the mask: True where FDR >= 0.05 OR where FDR is NaN (missing)
# Mask should hide non-significant values.
mask = (fdr_data >= 0.05) | fdr_data.isna()

# --- Create column colors ---
# Need info for *all* columns in heatmap_data
col_info = moran_pivot[['dummy_slide_id', 'cyclephase', 'comparison']].drop_duplicates().set_index('dummy_slide_id')
# Ensure order matches heatmap columns and handle potential missing columns
heatmap_cols_info = col_info.reindex(heatmap_data.columns)

# 1. Cyclephase colors
unique_cyclephases = heatmap_cols_info['cyclephase'].dropna().unique()
palette_cycle = sns.color_palette("husl", len(unique_cyclephases))
cyclephase_color_map = dict(zip(unique_cyclephases, palette_cycle))
cyclephase_colors = heatmap_cols_info['cyclephase'].map(cyclephase_color_map)

# 2. Comparison colors
unique_comparisons = heatmap_cols_info['comparison'].dropna().unique()
palette_comp = sns.color_palette("Set2", len(unique_comparisons))
comparison_color_map = dict(zip(unique_comparisons, palette_comp))
comparison_colors = heatmap_cols_info['comparison'].map(comparison_color_map)

# Combine into a DataFrame for clustermap
# Providing a DataFrame to col_colors automatically triggers legend creation by seaborn
col_colors_df = pd.DataFrame({
  'Cycle Phase': cyclephase_colors,
  'Projection dataset': comparison_colors
})
col_colors_df.index = heatmap_data.columns # Ensure index matches heatmap columns

# Generate clustermap
g = sns.clustermap(
  heatmap_data.fillna(0), # Pass data with NaNs and significant/non-significant values
  mask=mask, # Pass the mask to hide non-significant values (where mask is True)
  row_cluster=True,
  col_cluster=True,
  col_colors=col_colors_df, # Pass the DataFrame with multiple annotations
  cmap="magma", # Or a diverging map like "vlag" if center is not None
  cbar_pos=(0.02, .82, .05, .16), # Adjust colorbar position
  figsize=(9, 9) # Adjust figsize if legends are cramped or cut off
)

# Create handles for Cycle Phase legend
cycle_handles = [mpatches.Patch(color=cyclephase_color_map[name], label=name) for name in unique_cyclephases]
# Add the first legend - Position relative to the FIGURE edge
legend1 = g.fig.legend(handles=cycle_handles, title='Cycle Phase', bbox_to_anchor=(0.78, 1), loc='upper left', borderaxespad=0.)

# Create handles for Projection dataset legend
comp_handles = [mpatches.Patch(color=comparison_color_map[name], label=name) for name in unique_comparisons]
# Add the second legend - Position below the first one
legend2 = g.fig.legend(handles=comp_handles, title='Projection dataset', bbox_to_anchor=(0.78, 0.92), loc='upper left', borderaxespad=0.)

plt.suptitle("Clustered Heatmap of Significant Moran's I (FDR < 0.05)", y=1.02) # Add title
plt.show() # Display the plot
```

:::

> As these plots can't be visualised using a single framework (contains both matplotlib and Altair libraries), then these are the subplots that are generated separately and compiled later manually

```{python}
# # Try to make a layout plot with the spacers placeholder image
# raw_st_example = spacer_with_text(height=550, width=400)
# projection_example = spacer_with_text(height=550, width=400)
# (
#   (raw_st_example & projection_example) |
#   (boxplots & corr_plots & morans_chart)
# )
```


## SUPP FIG 1: QC and sample selection

We have excluded the following samples with their corresponding pair due to

* HUT10, HUT1, HUT71, HUT53, HUT17 were excluded due to poor clustering
* HUT10 does not have a paired biopsy sample
* HUT71, HUT53, HUT17 were excluded due to low biotype proportion
* HUT23_UF was swapped with HUT23_biopsy based on clustering, but excluded for the analysis

The correlation between techical replicates HUT71_biopsy, HUT71_biopsy_2, HUT71_biopsy_3 for TPM reads (average and the correlation matrix) is shown below.

```{python}
# Select columns containing "HUT71_biopsy"
hut71_biopsy_samples = ccht_uf_unfilt_tpm.filter(regex="HUT71_biopsy")

# Calculate the correlation between these samples
correlation_hut71 = hut71_biopsy_samples.corr(method='spearman')

# Average correlation between replicates is
# take it from the entry above the diagonal
print_corr = correlation_hut71.where(np.triu(np.ones(correlation_hut71.shape), k=1).astype(bool)).stack().mean()
print(f"Average correlation between HUT71 biopsy replicates: {print_corr:.2f}")

# Optional: visualize with seaborn if desired for a nicer output in the report
plt.figure(figsize=(4, 3))
sns.heatmap(correlation_hut71, annot=True, cmap="viridis", fmt=".2f")
plt.title("Correlation of HUT71 Biopsy Replicates")
plt.show()
```

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### UMAP of the unfiltered and filtered samplesets {.unnumbered .unlisted}

```{python}
# Prepare data for UMAP
data_for_umap = ccht_uf_unfilt_tpm.T  # Transpose so samples are rows

# Perform UMAP
reducer = UMAP(random_state=42, n_neighbors=10, min_dist=0.5) # Use UMAP directly
embedding = reducer.fit_transform(data_for_umap)

# Create DataFrame for plotting
umap_df = pd.DataFrame(embedding, columns=['UMAP1', 'UMAP2'], index=data_for_umap.index)
umap_df = umap_df.join(ccht_uf_pheno_unfilt[["cyclephase", "group"]]).reset_index().rename(columns={"index": "samplename"})

# Create Altair plot
umap_plot_unfilt = alt.Chart(umap_df).mark_point(size=60, filled=True).encode(
  x=alt.X('UMAP1:Q', title='UMAP 1').scale(zero=False),
  y=alt.Y('UMAP2:Q', title='UMAP 2').scale(zero=False),
  color=alt.Color('cyclephase:N', title='Cycle Phase'),
  shape=alt.Shape('group:N', title='Sample Group'),
  tooltip=['samplename', 'cyclephase', 'group']
).properties(
  title='UMAP of unfiltered samples',
  width=250,
  height=250
)
```

```{python}
# Prepare data for UMAP
data_for_umap = ccht_uf_tpm.T  # Transpose so samples are rows

# Perform UMAP
reducer = UMAP(random_state=42, n_neighbors=10, min_dist=0.5) # Use UMAP directly
embedding = reducer.fit_transform(data_for_umap)

# Create DataFrame for plotting
umap_df = pd.DataFrame(embedding, columns=['UMAP1', 'UMAP2'], index=data_for_umap.index)
umap_df = umap_df.join(ccht_uf_pheno[["cyclephase", "group"]]).reset_index().rename(columns={"index": "samplename"})

# Create Altair plot
umap_plot = alt.Chart(umap_df).mark_point(size=60, filled=True).encode(
  x=alt.X('UMAP1:Q', title='UMAP 1').scale(zero=False),
  y=alt.Y('UMAP2:Q', title='UMAP 2').scale(zero=False),
  color=alt.Color('cyclephase:N', title='Cycle Phase'),
  shape=alt.Shape('group:N', title='Sample Group'),
  tooltip=['samplename', 'cyclephase', 'group']
).properties(
  title='UMAP of filtered samples',
  width=250,
  height=250
)
```

Plot the UMAPs side by side

```{python}
umap_plot_unfilt | umap_plot
```

### Correlation plot of the unfiltered sampleset {.unnumbered .unlisted}

```{python}
corr_mat_unfilt = ccht_uf_unfilt_tpm.corr(method='spearman')
pheno_unfilt_idx = ccht_uf_pheno_unfilt.query("samplename in @corr_mat_unfilt.index")

cyc_unfilt_u = pheno_unfilt_idx['cyclephase'].dropna().unique().tolist()
cyc_pal_unfilt = sns.color_palette("husl", len(cyc_unfilt_u))
cyc_map_unfilt = dict(zip(cyc_unfilt_u, cyc_pal_unfilt))
cyc_cols_unfilt = pd.Series([cyc_map_unfilt.get(phase) for phase in pheno_unfilt_idx['cyclephase']], index=pheno_unfilt_idx.index, name='cyclephase')

grp_unfilt_u = pheno_unfilt_idx['group'].dropna().unique().tolist()
grp_pal_unfilt = sns.color_palette("Set2", len(grp_unfilt_u))
grp_map_unfilt = dict(zip(grp_unfilt_u, grp_pal_unfilt))
grp_cols_unfilt = pd.Series([grp_map_unfilt.get(group) for group in pheno_unfilt_idx['group']], index=pheno_unfilt_idx.index, name='group')

row_colors_df = pd.DataFrame({"": cyc_cols_unfilt, " ": grp_cols_unfilt}, index=corr_mat_unfilt.index)

g_unfilt = sns.clustermap(
  corr_mat_unfilt.fillna(0), col_colors=row_colors_df, method="complete",
  cmap="magma", vmin=0, vmax=1, figsize=(6, 8), cbar_pos=(0.85, .82, .02, .16),
  xticklabels=True, yticklabels=False, dendrogram_ratio=(0, .25)
)

# Reduce the size of x-axis tick labels
g_unfilt.ax_heatmap.set_xticklabels(g_unfilt.ax_heatmap.get_xmajorticklabels(), fontsize = 7)
g_unfilt.ax_heatmap.set_yticklabels(g_unfilt.ax_heatmap.get_ymajorticklabels(), fontsize = 7)

cyc_handles = [mpatches.Patch(color=cyc_map_unfilt[name], label=name) for name in cyc_unfilt_u]
g_unfilt.fig.legend(handles=cyc_handles, title='Cycle Phase', bbox_to_anchor=(.8, .98), loc='upper right', borderaxespad=0.)
grp_handles = [mpatches.Patch(color=grp_map_unfilt[name], label=name) for name in grp_unfilt_u]
g_unfilt.fig.legend(handles=grp_handles, title='Sample Group', bbox_to_anchor=(.6, .98), loc='upper right', borderaxespad=0.)
g_unfilt.fig.suptitle("Correlation Heatmap of Unfiltered Samples (Spearman)", y=1.02)
plt.show()
```

### Correlation plot of the raw reads {.unnumbered .unlisted}

```{python}
corr_mat = ccht_uf_tpm.corr(method='spearman')
pheno = ccht_uf_pheno.query("samplename in @corr_mat.index")

cyc = pheno['cyclephase'].dropna().unique().tolist()
cyc_pal = sns.color_palette("husl", len(cyc))
cyc_map = dict(zip(cyc, cyc_pal))
cyc_cols = pd.Series([cyc_map.get(phase) for phase in pheno['cyclephase']], index=pheno.index, name='cyclephase')

grp = pheno['group'].dropna().unique().tolist()
grp_pal = sns.color_palette("Set2", len(grp))
grp_map = dict(zip(grp, grp_pal))
grp_cols = pd.Series([grp_map.get(group) for group in pheno['group']], index=pheno.index, name='group')

row_colors_df = pd.DataFrame({"": cyc_cols, " ": grp_cols}, index=corr_mat.index)

g = sns.clustermap(
  corr_mat.fillna(0), col_colors=row_colors_df, method="complete",
  cmap="magma", vmin=0, vmax=1, figsize=(6,8), cbar_pos=(0.85, .82, .02, .16),
  xticklabels=True, yticklabels=False, dendrogram_ratio=(0, .25)
)

# Reduce the size of x-axis tick labels
g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xmajorticklabels(), fontsize = 7)
g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_ymajorticklabels(), fontsize = 7)

cyc_handles = [mpatches.Patch(color=cyc_map[name], label=name) for name in cyc]
g.fig.legend(handles=cyc_handles, title='Cycle Phase', bbox_to_anchor=(.8, .98), loc='upper right', borderaxespad=0.)
grp_handles = [mpatches.Patch(color=grp_map[name], label=name) for name in grp]
g.fig.legend(handles=grp_handles, title='Sample Group', bbox_to_anchor=(.6, .98), loc='upper right', borderaxespad=0.)
g.fig.suptitle("Correlation Heatmap of TPM counts (Spearman)", y=1.02)
```

### Featurecounts plot too for unfiltered groups {.unnumbered .unlisted}

```{python}
# Calculate total counts for each biotype across all samples
biotype_counts = features_ev.sum().sort_values(ascending=False)

# Get the top 10 biotypes
top_biotypes = biotype_counts.head(10).index.tolist()

# Calculate total counts per sample for the selected top_biotypes (denominator for percentage)
sample_totals_top_biotypes = features_ev[top_biotypes].sum(axis=1)

# Melt the DataFrame for plotting, including only the top biotypes
df_melted = (
  features_ev
  .reset_index()
  .pipe(lambda df: df[df['samplename'].str.contains("HUT", na=False)])
  .melt(id_vars=['samplename'], value_vars=top_biotypes, var_name='biotype', value_name='count')
)

# Calculate percentage relative to the sum of these top_biotypes for that sample
df_melted['percentage'] = df_melted.apply(
  lambda row: (row['count'] / sample_totals_top_biotypes[row['samplename']])
  if sample_totals_top_biotypes[row['samplename']] > 0 else 0,
  axis=1
)

# Sort samples by the percentage of "protein_coding" if it's in top_biotypes
# If not, sample_order will be empty, and Altair will use default order.
protein_coding_percentages = df_melted[df_melted['biotype'] == 'protein_coding'].set_index('samplename')['percentage']
sample_order = protein_coding_percentages.sort_values(ascending=False).index.tolist()

# --- Plotting logic starts here ---
biotype_prop = alt.Chart(df_melted).mark_bar().encode(
  x=alt.X('samplename:N', title='Sample', sort=sample_order, axis=alt.Axis(labelAngle=-45)), # Swapped from y, added labelAngle
  y=alt.Y('percentage:Q', title='Percentage (%)', scale=alt.Scale(domain=(.8, 1)), axis=alt.Axis(format='%')), # Swapped from x
  color=alt.Color('biotype:N', title='Biotype', sort=top_biotypes, scale=alt.Scale(scheme='category10')),
  order=alt.Order('color_biotype_sort_index:Q') # sort by the color fields
).properties(
  width=alt.Step(12), # Adjust bar width by setting step, now applied to width
  height=100, # Was width, now height
  title="Biotype Proportions per Sample (Unfiltered, Top 10 Biotypes)"
)

biotype_prop.interactive()
```

### Qualimap read type plot for unfiltered groups {.unnumbered .unlisted}

```{python}
# Select relevant columns and samples
cols_to_plot = ["reads_aligned_exonic", "reads_aligned_intronic", "reads_aligned_intergenic"]
plot_data = qualimap_ev.reset_index().rename(columns={"index": "samplename"})
plot_data = plot_data[plot_data['samplename'].str.contains("HUT", na=False)][["samplename"] + cols_to_plot].copy()

# Calculate total reads for percentage calculation
plot_data['total_reads'] = plot_data[cols_to_plot].sum(axis=1)

# Calculate percentages
for col in cols_to_plot:
  plot_data[col + '_perc'] = (plot_data[col] / plot_data['total_reads'])

# Determine sort order based on intronic reads percentage BEFORE melting
sample_order = (
  plot_data
  .sort_values('reads_aligned_intronic_perc', ascending=False)['samplename']
  .tolist()
)

# Melt the DataFrame for Altair
plot_data_melted = plot_data.melt(
  id_vars=['samplename'],
  value_vars=[col + '_perc' for col in cols_to_plot],
  var_name='read_type',
  value_name='percentage'
)

# Clean up read_type names
plot_data_melted['read_type'] = plot_data_melted['read_type'].str.replace('reads_aligned_', '').str.replace('_perc', '')

# Create the Altair plot
qualimap_plot = alt.Chart(plot_data_melted).mark_bar().encode(
  x=alt.X('samplename:N', title='Sample', sort=sample_order, axis=alt.Axis(labelAngle=-45)),
  y=alt.Y('percentage:Q', axis=alt.Axis(format='%', title='Percentage of Reads'), stack='normalize'),
  color=alt.Color('read_type:N', title='Read Type', scale=alt.Scale(scheme='category10')),
  order=alt.Order(field='read_type', type='nominal'), # Ensures consistent stacking order
  tooltip=['samplename', 'read_type', alt.Tooltip('percentage:Q', format='.2%')]
).properties(
  title='Read Alignment Distribution (Exonic, Intronic, Intergenic)',
  width=alt.Step(12), # Adjust bar width for each sample
  height=100 # Overall height of the plot
)

# Add a rule (line) at y=85%
rule = alt.Chart(pd.DataFrame({'percentage': [0.85]})).mark_rule(strokeDash=[5, 5], color='red').encode(
  y=alt.Y('percentage:Q') # Rule is now horizontal
)

qualimap_plot = (qualimap_plot + rule)
qualimap_plot.interactive()
```

Lower half of supp. fig. 1

```{python}
supp_1 = (
  biotype_prop & qualimap_plot |
    (umap_plot_unfilt & umap_plot).resolve_scale( x="independent", y="independent") 
  ).resolve_scale(
    x="independent", y="independent", color="independent", shape="independent"
    )

supp_1.interactive()
```

:::

