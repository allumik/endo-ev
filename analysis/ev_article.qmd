---
title: "Extracellular Vesicle Spatiotemporal Deconvolution Recapitulates the Dynamic Nature of the Human Endometrium"
format:
  html:
    code-fold: true
    code-tools: true
    embed-resources: true
    self-contained-math: true
jupyter: python3
---

This document contains the condensed form of analysis, figures and some more technical parts of the final article.

> **This** is a commentary text, it will not be included in the final report.

This is a citation as a [simple link](doi:10.1101/2023.11.03.564728), I will collect the links later on and put them in the references section.

# Prelude

## Load data and environment

Setup the environment and import dependencies.

1. Load the dependencies, set up multithreading.
2. Set color groups and values.

```{python}
#| output: false

import re
import glob
import warnings
import numpy as np
import pandas as pd
import anndata as an
import scanpy as sc
import squidpy as sq
import altair as alt
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as mpatches
from os import getenv
from pathlib import Path
from dotenv import load_dotenv
from IPython.display import HTML
from sklearn.decomposition import PCA
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
from umap import UMAP # Changed import style
from sklearn.preprocessing import normalize

## import the functions used in this report (got too long to include them in the report)
try: from analysis.helpers.deconvo_functions import *
except ImportError: from helpers.deconvo_functions import *

try: from analysis.helpers.projection_functions import *
except ImportError: from helpers.projection_functions import *

## load the environment variables from the .env file
load_dotenv()
if getenv("DATA_FOLDER") is None:
  load_dotenv(Path.cwd() / ".env")

proj_folder = getenv("PROJ_FOLDER")
anndata_folder = getenv("ANNDATA_FOLDER")
atlas_folder = getenv("ATLAS_FOLDER")
data_folder = getenv("DATA_FOLDER")
st_folder = getenv("ST_FOLDER")
raw_data_folder = getenv("RAW_DATA_FOLDER")

# some other dataset locations
fig_loc = Path(proj_folder).expanduser() / "figures"
snapshot_an_loc = Path(data_folder).expanduser() / "sc_deconv_snapshot.h5ad"
comb_data_loc = Path(data_folder).expanduser() / "combined" / "comb_all_batch.feather"
comb_raw_data_loc = Path(data_folder).expanduser() / "combined" / "comb_all_raw.feather"
comb_pheno_loc = Path(data_folder).expanduser() / "combined" / "comb_all_pheno.tsv"
ccht_data_loc = Path(data_folder).expanduser() / "filtered" / "annot_raw.feather"
ccht_tpm_loc = Path(data_folder).expanduser() / "filtered" / "annot_tpm.feather"
ccht_data_unfilt_loc = Path(data_folder).expanduser() / "filtered" / "annot_raw_unfilt.feather"
ccht_tpm_unfilt_loc = Path(data_folder).expanduser() / "filtered" / "annot_tpm_unfilt.feather"
ccht_pheno_loc = Path(data_folder).expanduser() / "filtered" / "phenotype.tsv"
ccht_pheno_unfilt_loc = Path(data_folder).expanduser() / "filtered" / "phenotype_unfilt.tsv"
fractions_folder = Path(data_folder) / "tape_fractions"
fractions_file_loc = fractions_folder / "ccht_fracs.tsv"
fractions_file_loc_comb = fractions_folder / "comb_uf_fracs.tsv"
fractions_file_loc_comb_raw = fractions_folder / "comb_fracs_raw.tsv"
```

Load in the datasets:

* the reference single cell dataset from the HECAv2 (`sc_dat`).
* bulk transcriptomes from UF derived EV's of endometrium and biopsies (`ccht_uf_raw`).
* phenotype table for the EV and biopsy samples (`ccht_uf_pheno`).
* bulk transcriptomes from UF derived EV's of endometrium and Giacomini et al. (Vigano group) EV transcriptomes (`comb_uf_raw`).
* phenotype table for the EV and Giacomini et al. samples (Vigano group) (`comb_uf_pheno`).

Here we rename some variables, for example the "biopsy" becomes the "Tissue" group, and the "UF" becomes the "UF-EV" group. We also load in the fractions predicted by the latest trained deconvolutional model.

```{python}
#| output: false
## Load the single cell reference data
sc_dat = an.read_h5ad(snapshot_an_loc)
sc_dat.obs.replace({"lineage": {"Mesenchymal": "Stromal"}}, inplace=True)
```

```{python}
#| output: false
## Create name remappers for the groups
cyclephase_remap = { "pro": "P", "pre": "ES", "rec": "MS", "post": "LS" }
group_remap = { "UF": "UF-EV", "biopsy": "Tissue" }
group2_remap = { "HUT": "UF-EV", "Vigano": "Giacomini EV" }

## Load CCHT UF-EV and biopsy datasets (filtered)
terminator = [] # some samples to exclude
ccht_uf_raw = pd.read_feather(ccht_data_loc).set_index("gene_id").iloc[:-1]
ccht_uf_tpm = pd.read_feather(ccht_tpm_loc).set_index("gene_id").iloc[:-1]
ccht_uf_pheno = pd.read_table(ccht_pheno_loc).set_index("samplename").assign(
  group=lambda x: x.group.map(group_remap),
  cyclephase=lambda x:
    pd.Categorical(x.cyclephase.map(cyclephase_remap), categories=cyclephase_remap.values(), ordered=True)
  )
ccht_uf_pheno = ccht_uf_pheno.query("samplename not in @terminator and samplename in @ccht_uf_raw.columns")
ccht_uf_raw = ccht_uf_raw.drop(columns=terminator)

## Load CCHT UF-EV and biopsy datasets (unfiltered)
ccht_uf_unfilt_raw = pd.read_feather(ccht_data_unfilt_loc).set_index("gene_id").iloc[:-1]
ccht_uf_unfilt_tpm = pd.read_feather(ccht_tpm_unfilt_loc).set_index("gene_id").iloc[:-1]
ccht_uf_pheno_unfilt = pd.read_table(ccht_pheno_unfilt_loc).set_index("samplename").assign(
  group=lambda x: x.group.map(group_remap),
  cyclephase=lambda x:
    pd.Categorical(x.cyclephase.map(cyclephase_remap), categories=cyclephase_remap.values(), ordered=True)
  )

## Load combined UF-EV datasets (CCHT + Giacomini et al.)
comb_batch = pd.read_feather(comb_data_loc).set_index("gene_id").drop(columns=terminator)
comb_raw = pd.read_feather(comb_raw_data_loc).set_index("external_gene_name").drop(columns=terminator)
comb_all_pheno = (
  pd.read_table(comb_pheno_loc)
  .set_index("samplename")
  .query("samplename not in @terminator")
  .assign(
    dataset=lambda x: x.dataset.map(group2_remap),
    group=lambda x: x.group.map(group_remap),
    cyclephase=lambda x:
      pd.Categorical(x.cyclephase.map(cyclephase_remap), categories=cyclephase_remap.values(), ordered=True)
  )
)
comb_uf_pheno = (
  comb_all_pheno
  .assign(dataset = lambda x: np.where(x.dataset == "UF-EV", x.dataset, "Giacomini EV"))
  .query("cyclephase in ['MS', 'ES'] and group == 'UF-EV'")
)
```

```{python}
#| output: false
## Load deconvolution fraction predictions
frac_pred = pd.read_table(fractions_file_loc, sep="\t", index_col=0)
frac_comb = pd.read_table(fractions_file_loc_comb, sep="\t", index_col=0)
frac_comb_raw = pd.read_table(fractions_file_loc_comb_raw, sep="\t", index_col=0)

## Create cell type lineage mapping from single cell data
general_cells = ( # associate celltypes with the lineage information in the sc_dat.obs
  sc_dat.obs
  .loc[:, ["lineage", "celltype"]]
  .drop_duplicates("celltype")
  .set_index("celltype", drop=True)
  ## rename Mesenhymal to Stromal in the lineage column
  .replace({"lineage": {"Mesenchymal": "Stromal"}})
  .reindex(frac_pred.columns.values)
)
```

Define the sample name converter function that will be used to convert the sample names in the loaded in dataframes. It will take the HUT\d+ prefix for the sample names and assign random numbers to the samples with the prefix format S\d+. The pairings will be conserved, with "UF-EV" and "Tissue" groups being paired together with the same S__ code, and both sampling methods having identifiers on them. 

```{python}
def convert_sample_names(sample_names):
  """
  Creates a mapping dictionary to convert sample names from 'HUT<number>_...'
  to 'S<number>_...' format, ensuring paired samples get the same 'S' number.
  """
  # Find all unique HUT prefixes (e.g., 'HUT10', 'HUT23') from the sample names
  hut_prefixes = sorted(list(set(re.findall(r"(HUT\d+)", " ".join(sample_names)))))

  # Create a mapping from HUT prefix to a new S-based prefix
  s_map = {prefix: f"S{i+1:02d}" for i, prefix in enumerate(hut_prefixes)}

  # Create the final rename dictionary for all sample names
  rename_dict = {}
  for name in sample_names:
    match = re.match(r"(HUT\d+)", name)
    if match:
      hut_prefix = match.group(1)
      if hut_prefix in s_map:
        # Replace the HUT prefix with the corresponding S prefix and 'biopsy' with 'tissue'
        new_name = name.replace(hut_prefix, s_map[hut_prefix], 1).replace("biopsy", "tissue")
        rename_dict[name] = new_name
  return rename_dict

# apply the function on the sample dataframes
resampler = convert_sample_names(ccht_uf_pheno_unfilt.index)
ccht_uf_pheno = ccht_uf_pheno.rename(index=resampler)
ccht_uf_pheno_unfilt = ccht_uf_pheno_unfilt.rename(index=resampler)
ccht_uf_unfilt_raw = ccht_uf_unfilt_raw.rename(columns=resampler)
ccht_uf_unfilt_tpm = ccht_uf_unfilt_tpm.rename(columns=resampler)
ccht_uf_raw = ccht_uf_raw.rename(columns=resampler)
ccht_uf_tpm = ccht_uf_tpm.rename(columns=resampler)
comb_uf_pheno = comb_uf_pheno.rename(index=resampler)
comb_batch = comb_batch.rename(columns=resampler)
comb_raw = comb_raw.rename(columns=resampler)
frac_pred = frac_pred.rename(index=resampler)
# frac_pred.to_excel("main_fracs.xlsx")
frac_comb = frac_comb.rename(index=resampler)
# frac_comb.to_excel("comb_fracs.xlsx")
frac_comb_raw = frac_comb_raw.rename(index=resampler)
```

We also load in the different statistical testing tables for CCHT dataset.

```{python}
ccht_bio_stat = pd.read_excel(fractions_folder / "ccht_bio.xlsx", index_col=0).assign(
  group1=lambda x: x.group1.map(cyclephase_remap),
  group2=lambda x: x.group2.map(cyclephase_remap)
)
ccht_uf_stat = pd.read_excel(fractions_folder / "ccht_uf.xlsx", index_col=0).assign(
  group1=lambda x: x.group1.map(cyclephase_remap),
  group2=lambda x: x.group2.map(cyclephase_remap)
)
ccht_comp_stat = pd.read_excel(fractions_folder / "ccht_comp.xlsx", index_col=0)
```

Featurecounts results for the samples from the MultiQC report.

```{python}
features_ev = (
  pd.read_table(
    Path(raw_data_folder) / "multiqc/star_rsem/multiqc_data/multiqc_featurecounts_biotype_plot.txt"
    )
  .rename(columns={"Sample": "samplename"})
  # .query("samplename in @frac_pred.index") # don't filter out  here
  .assign(
    samplename=lambda x: x.samplename
      .str.replace("HU10", "HUT10", regex=False)
      .str.replace(r'(?<=HUT)0+(?=\d)', '', regex=True)
  )
  .set_index("samplename")
  .rename(index=resampler)
)
```

QualiMap results for the samples from the MultiQC report.

```{python}
qualimap_ev = (
  pd.read_table(
    Path(raw_data_folder) / "multiqc/star_rsem/multiqc_data/qualimap_rnaseq_genome_results.txt"
    )
  .rename(columns={"Sample": "samplename"})
  .assign(
    samplename=lambda x: x.samplename
      .str.replace("HU10", "HUT10", regex=False)
      .str.replace(r'(?<=HUT)0+(?=\d)', '', regex=True)
  )
  .set_index("samplename")
  .rename(index=resampler)
)
```

The color schemes that we are going to use

```{python}
def create_lineage_aware_colors(general_cells_df):
  """Create color mapping with unique colors within each lineage using tab20 palette."""

  # Get the tab20 color palette using seaborn
  default_colors = sns.color_palette("colorblind", n_colors=20)
  alt_colors = sns.color_palette("tab20")
  color_mapping = {}
  
  for lineage_idx, (lineage, group) in enumerate(general_cells_df.groupby('lineage')):
    celltypes = group.index.tolist()
    
    # Use different color variations based on lineage index
    if lineage_idx % 4 == 0:
      colors_to_use = list(default_colors)
    elif lineage_idx % 4 == 1:
      colors_to_use = list(reversed(default_colors))
    elif lineage_idx % 4 == 2:
      colors_to_use = list(alt_colors)
    else:  # lineage_idx % 4 == 3
      colors_to_use = list(reversed(alt_colors))
    
    # For each lineage, use colors from the selected order
    for i, celltype in enumerate(celltypes):
      # Use modulo to cycle through colors if more celltypes than colors
      color_idx = i % len(colors_to_use)
      # Convert RGB tuple to hex string
      color_hex = '#%02x%02x%02x' % tuple(int(c * 255) for c in colors_to_use[color_idx])
      color_mapping[celltype] = color_hex
  
  return color_mapping

phase_colors = {
  "Proliferative": "#006d2c", "P": "#006d2c", "EP": "#6ed5ff", "LP": "#006d2c",
  "Pre-receptive": "#00BA38", "ES": "#00BA38", "Early-receptive": "#00BFC4",
  "Receptive": "#619CFF", "MS": "#619CFF", "Secretory": "#619CFF",
  "Late-receptive": "#F58633", "Post-receptive": "#D11141", "LS": "#D11141",
  "Menstrual": "#d11141",
  "HRT+3": "#00BA38", "HRT+4": "#00BFC4", "HRT+5": "#619CFF", "HRT+6": "#F58633", "HRT+7": "#D11141",
  "No result": "#A4A4A4", "Bad quality": "#A4A4A4", "Non-receptive": "#f03b20"
}

phases = list(phase_colors.keys())
phcolors = list(phase_colors.values())
# color scale for the cycle phases
global_color_phase_all = alt.Scale(domain=phases, range=phcolors)
phases_subset = ["P", "ES", "MS", "LS"]
phase_colors_subset = {k: phase_colors[k] for k in phases_subset if k in phase_colors}
global_color_phase = alt.Scale(domain=phases_subset, range=list(phase_colors_subset.values()))
# color scale for the lineages
global_color_lineage = alt.Scale(domain=general_cells.lineage.unique().tolist(), scheme="category10")
# color scale for the celltypes

# Create the color mapping and scale
celltype_colors = create_lineage_aware_colors(general_cells)
global_color_ct = alt.Scale(
  domain=list(celltype_colors.keys()), 
  range=list(celltype_colors.values())
)
# color scale for the groups
global_color_group = alt.Scale(domain=["Tissue", "UF-EV"], scheme="set2")
global_color_group2 = alt.Scale(domain=["UF-EV", "Giacomini EV"], range=["#00BFC4", "#F58633"])
global_color_group3 = alt.Scale(domain=["Tissue", "UF-EV", "scRNA-seq"], scheme="dark2")
```


The preprocessed spatial slides with spatial deconvolution

```{python}
gen_sc_file = Path(anndata_folder).expanduser() / "gen_sc_ev.h5ad"
gen_ccht_ev = sc.read_h5ad(gen_sc_file)
gen_ccht_ev.obs.replace({"lineage": {"Mesenchymal": "Stromal"}}, inplace=True)
gen_sc_file = Path(anndata_folder).expanduser() / "gen_sc_biopsy.h5ad"
gen_ccht_bio = sc.read_h5ad(gen_sc_file)
gen_ccht_bio.obs.replace({"lineage": {"Mesenchymal": "Stromal"}}, inplace=True)
```

```{python}
slide_ids = ["152807", "152811"]
data_directory = Path(anndata_folder).expanduser()
# load only the early secretory samples
adata_collection = load_spatial_data(data_directory)
# create the subset using a dictionary comprehension
adata_collection = {key: value for key, value in adata_collection.items() if key[0] in set(slide_ids)}
```

```{python}
# some preliminary metrics
jaccard_thresh = 0.25 # Use lower quartile for Jaccard and Centroid distance
# but then read in the stats table anyways
stats_df = pd.read_csv(Path(data_folder).expanduser() / "st_stats_table.csv", index_col=0)
stats_df.replace({"lineage": {"Mesenchymal": "Stromal"}}, inplace=True)
```

# Methods

## Pre-processing pipeline for the RNA-seq data

```{bash}
#| code-fold: false
#| eval: false
#| echo: true

## nf-core/rnaseq v3.12 (https://nf-co.re/rnseq/3.12.0)
nextflow run nf-core/rnaseq \
  -r 3.12.0 \
  --input samplesheet_mrna.csv \
  --genome GRCh37 \
  --aligner star_rsem \
  --outdir "./results_mrna/" \
  -c nextflow.config \
  -profile singularity
```

## Differential expression analysis

>Not used currently in the report, but left in here for future reference.

Differential expression (DE) analysis was done in R (v4.3) programming language. For differential analysis, we used both DESeq2 and limma-voom algorithms to measure the differences between gene expression levels in different sample groups and to perform statistical testing on the gene-wise differences [[DESeq2](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8), [limma-voom](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29)]. While DESeq2 DE results were used for downstream analysis, we used the limma-voom toolset as an alternative approach as it has been shown to have more stringent multiple hypothesis testing in regards to type I error [[Robles et al.](https://link.springer.com/article/10.1186/1471-2164-13-484), [Soneson et al.](https://link.springer.com/article/10.1186/1471-2105-14-91)].

```{python}
# de_ccht_phases = pd.read_feather(Path(data_folder) / "filtered" / "de" / "voom_phases.feather").set_index("locus")
# de_ccht_group = pd.read_feather(Path(data_folder) / "filtered" / "de" / "voom_methods.feather").set_index("locus")
```

## Sample selection and quality control

The following code is an excerpt from the `ev_raw.r` script, describing the main filtering step:
```{r}
#| code-fold: false
#| eval: false
#| echo: true
#### FILTER
# HUT10, HUT1, HUT71, HUT53, HUT17 were excluded due to poor clustering
# HUT10 does not have a paired biopsy sample
# HUT33, HUT53, HUT17 were excluded due to low intronic proportion
removals <- c(
  "HUT71_UF", "HUT71_biopsy", "HUT71_biopsy_2", "HUT71_biopsy_3",
  "HUT10_UF", "HUT1_UF", "HUT1_biopsy",
  "HUT53_UF", "HUT53_biopsy", "HUT17_UF", "HUT17_biopsy"
)
# HUT23_UF was swapped with HUT23_biopsy based on clustering
```

## Deconvolutional model parameters

>Create supplementary figures visualising the training loss and the model performance.

```{python}
#| code-fold: false
#| eval: false
#| echo: true

model_params = {
  "celltype_key": "celltype",
  "top_marker_num": 250, # reduce it from the default parameter of 500
  "max_single_cells": round(len(sc_dat.obs.index) / 8),
  "ratio_num": 1,
  "gpu": 0
}

frac_params = {
  "batch_size": 512,
  "epochs": 1000, # looking at loss plot then 500 seems to be already enough, but 1000 seems to have more accurate representatoin of the cell types.
  "method": "tape", # define this, otherwise defaults for scaden
  "scaler": "ss", # harmonises distributions better
  "mode": "high-resolution" # for using VAE's for cell type inference
}
```

# Results with Figures

## FIG 1: Study Design

Main points of interest:

* Bulk samples are paired, biopsy and EV samples are taken from the same patients.
* We observed the featureCounts mRNA ratio to other transcript types to indicate the quality of the samples, especially in the EV samples with lower genomic input.
* We have also included samples from the late-secretory phase of the menstrual cycle to show the differences in the cell type proportions leading up to the decidualisation of the endometrium.

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Analysis Steps {.unnumbered .unlisted}

```{python}
# placeholder image
study_schema = spacer_with_text(height=500, width=700)
```

### Overview of the Samples {.unnumbered .unlisted}

> Figure out how to visualise all the different celltypes in per cycle phase.

```{python}
# barplot of the number of samples throughout the cycle phase
barplot_ev_sum = alt.Chart(ccht_uf_pheno).mark_bar().encode(
  x=alt.X("cyclephase:N", sort=phases).title("").axis(labelAngle=0),
  y=alt.Y("count(group):Q").title("Nr. of Samples"),
  color=alt.Color("group:N", scale=global_color_group).legend(orient="bottom", titleOrient="left")
).properties(width=150, height=150)
barplot_ev_sum.interactive()
```

```{python}
# include single cell data overview as extra column
barplot_sc_sum = alt.Chart(
  sc_dat.obs[["cyclephase", "samplename", "dataset"]].value_counts(["cyclephase", "dataset"]).reset_index()
).mark_bar().encode(
  x=alt.X("cyclephase:N", sort=phases).title("").axis(labelAngle=-45),
  y=alt.Y("count:Q").title("Nr. of Cells"),
  color=alt.Color("dataset:N").legend(orient="right", titleOrient="top", columns=1)
).properties(width=150, height=150)
barplot_sc_sum.interactive()
```

### Feature Counts {.unnumbered .unlisted}

Here we look at only the final samples that were selected for the analysis, the raw featurecounts table is in Supplementary Fig 1.

Plot 10 top features per FeatureCounts output on log scale. Show the cutoff point for QC of 15% proteion coding RNA reads.

```{python}
# Get top 10 biotypes and prepare data
top_biotypes = features_ev.sum().sort_values(ascending=False).head(10).index.tolist()
sample_totals = features_ev[top_biotypes].sum(axis=1)

# Create melted dataframe with percentages
df_melted = (
  features_ev
  .reset_index()
  .query("samplename in @frac_pred.index")
  .melt(id_vars=['samplename'], value_vars=top_biotypes, var_name='biotype', value_name='count')
  .assign(
    percentage=lambda x: x.apply(
      lambda row: (row['count'] / sample_totals[row['samplename']]) * 100 
      if sample_totals[row['samplename']] > 0 else 0, axis=1
    ),
    sample_group=lambda x: x['samplename'].apply(lambda s: 'Tissue' if 'tissue' in s else 'UF-EV')
  )
)

# Create protein_coding plot with threshold
protein_coding_plot = alt.Chart(df_melted.query("biotype == 'protein_coding'")).mark_boxplot(extent=1.5).encode(
  x=alt.X('biotype:N', title=None).axis(labelAngle=-30),
  y=alt.Y('percentage:Q', title='Percentage (%)').scale(domain=(80, 100)),
  color=alt.Color('sample_group:N', scale=global_color_group).legend(None),
  xOffset='sample_group:N'
).properties(height=150, width=60)

# Create other biotypes plot
other_biotypes = [bt for bt in top_biotypes if bt != 'protein_coding']
other_biotypes_plot = alt.Chart(df_melted.query("biotype != 'protein_coding'")).mark_boxplot(extent=1.5).encode(
  x=alt.X('biotype:N', title='10 Top Biotypes', sort=other_biotypes).axis(labelAngle=-30),
  y=alt.Y('percentage:Q', title=None),
  color=alt.Color('sample_group:N', scale=global_color_group).legend(title="Sample Group", orient="right", titleOrient="top"),
  xOffset='sample_group:N'
).properties(height=150, width=400)

featurecounts_chart = protein_coding_plot | other_biotypes_plot
```

:::

```{python}
fig1 = (study_schema & (barplot_ev_sum | featurecounts_chart).resolve_scale(color="independent"))
# export the chart to svg
fig1.save(fig_loc / "fig_1.svg", scale_factor=5)

fig1.display()
```

## FIG 2: Cell Type Deconvolution Profiles throughout the Menstrual Cycle

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Proportions Plot of both Biopsy and EV {.unnumbered .unlisted}

```{python}
fractions_long = peruvian_transform(
  fractions=frac_pred,
  phenotype=ccht_uf_pheno,
  general_cells=general_cells,
  grouping_ids=["cyclephase", "group"]
)

peruvian_bio_ev = peruvian_grouped(
  fractions_df=fractions_long,
  grouping_id="group",
  global_color_scale=global_color_ct,
  dims=(150, 120)
)

peruvian_bio_ev.show()
```

### Proportions Plot with added scRNA-seq cell type ratios {.unnumbered .unlisted}

```{python}
# Define the specific mapping for cycle phases, that also summarises the proliferative phases into one
prolif_mapping = { "EP": "P", "LP": "P" }

# Calculate scRNA-seq percentages and prepare for concatenation
sc_ratios_prep = (
  sc_dat.obs
  .query("cyclephase != 'Menstrual'") # Remove "Menstrual" phase samples
  .assign(
    cyclephase_mapped=lambda df: pd.Categorical(
      df.cyclephase.map(prolif_mapping).fillna(df.cyclephase),
      categories=["P", "ES", "MS", "LS"], # Ensure correct order
      ordered=True
    )
  )
  .groupby(["cyclephase_mapped", "celltype"])
  .size()
  .pipe(lambda s: (s / s.groupby(level="cyclephase_mapped").sum())) # Calculate percentages
  .reset_index(name="fractions")
  .assign(group="scRNA-seq")
  .rename(columns={"celltype": "variable", "cyclephase_mapped": "cyclephase"}) # Rename mapped phase to 'cyclephase'
  .merge(
    general_cells.reset_index().assign(variable = lambda x: x.celltype), # Adds 'lineage'
    on="variable",
    how="left"
  )
)

# Concatenate with the existing fractions_long and set cyclephase to categorical
fractions_long = (
  pd.concat([fractions_long, sc_ratios_prep], ignore_index=True)
)

peruvian_all = peruvian_grouped(
  fractions_df=fractions_long,
  grouping_id="group",
  global_color_scale=global_color_ct,
  dims=(150, 125)
)

peruvian_all.show()
```

### Biplot of the Fractions {.unnumbered .unlisted}

```{python}
biplot, pca = biplot_fractions(
  frac_pred,
  ccht_uf_pheno,
  color_field="cyclephase",
  color_scale=global_color_phase,
  style_field="group",
  text_limit = 0.05, # controls on how much labels are shown
  dims = (320, 260)
  )
biplot.show()
```

In addition, make a histogram of the main loadings to make the contributions more clearer. `TODO: make it into percentages?`

```{python}
def format_loadings(pca_obj, celltypes):
  """
  Get the euclidean distance of explained variance per component of `pca_obj`.
  Generate a dataframe with the "Variance Explained" and the "Feature" column from `celltypes` list.
  """
  loadings = np.linalg.norm(pca_obj.components_.T * np.sqrt(pca_obj.explained_variance_), axis=1)
  return pd.DataFrame({
    "Variance Explained": loadings, "Feature": celltypes
  }).sort_values("Variance Explained", ascending=False).reset_index(drop=True)

pca_all = pca # save it with another name for clarity
loadings_all = format_loadings(pca_all, frac_pred.columns).rename(columns={"Variance Explained": "Combined"}).set_index("Feature")

pheno_tmp = ccht_uf_pheno.query("group == 'UF-EV'")
_, pca_uf = biplot_fractions(frac_pred.loc[pheno_tmp.index], pheno_tmp, color_field="cyclephase")
loadings_uf = format_loadings(pca_uf, frac_pred.columns).rename(columns={"Variance Explained": "UF-EV"}).set_index("Feature")

pheno_tmp = ccht_uf_pheno.query("group == 'Tissue'")
_, pca_bio = biplot_fractions(frac_pred.loc[pheno_tmp.index], pheno_tmp)
loadings_bio = format_loadings(pca_bio, frac_pred.columns).rename(columns={"Variance Explained": "Tissue"}).set_index("Feature")


## The plot part - visualise all the different loadings
loadings_combined = (
  pd.concat([loadings_all, loadings_uf, loadings_bio], axis=1)
  .stack()
  .reset_index()
  .rename(columns={"level_1": "Group", 0: "Variance Explained"})
  )

loadings_plt = alt.Chart(loadings_combined).mark_line(
    point=alt.OverlayMarkDef(filled=False, fill="white", size=10)
  ).encode(
  x=alt.X("Feature:N", sort=None).axis(labelAngle=-45, labelFontSize=11),
  y=alt.Y("Variance Explained:Q").axis(labelFontSize=12),
  color=alt.Color("Group:N").legend(labelFontSize=12, titleFontSize=13)
).properties(
  title='Loadings for Principal Component',
  width=500,
  height=175
)

loadings_plt.show()
```

### Testing the Differences of the Deconvolution Proportions through Cycle Phases {.unnumbered .unlisted}

Here we create a visual representation of the statistical testing and correlation analysis results of the UF and Biopsy samples. We present the most statistically significant changes throughout the cycle phases.

```{python}
# Helper function to swap group1 and group2 in the DataFrame for specified pairs
def swap_groups(df, to_swap):
  for g1, g2 in to_swap:
    stats_view = (df.group1 == g1) & (df.group2 == g2)
    swapped_view = df.loc[stats_view].rename(columns={"group1": "group2", "group2": "group1"})
    swapped_view["meandiff"] *= -1
    df.loc[stats_view] = swapped_view
  return df

# Configuration for data processing and plotting
swapper = [("LS", "MS"), ("MS", "ES"), ("ES", "P")]
comp_order = ["P_vs_ES", "ES_vs_MS", "MS_vs_LS"]
cycle_order = ["P", "ES", "MS", "LS"]
plt_width, plt_height = (650, 130) # Plot dimensions

from itertools import product

# Prepare base statistical data
base_data = (
  pd.concat([ccht_bio_stat.assign(method="bio"), ccht_uf_stat.assign(method="uf")])
  .query("`anova p-val` <= 0.05")
  .pipe(swap_groups, swapper)
  .assign(comparison_orig=lambda x: x.group1 + "_vs_" + x.group2)
)

# Create a scaffold for all desired combinations
unique_celltypes = base_data.celltype.unique()
all_methods = ['bio', 'uf']
full_scaffold = pd.DataFrame(
  list(product(unique_celltypes, all_methods, comp_order)),
  columns=['celltype', 'method', 'comparison']
)

# Merge scaffold with base_data and derive final columns
stat_comb_prim = (
  pd.merge(
    full_scaffold,
    base_data.rename(columns={'comparison_orig': 'comparison'}),
    on=['celltype', 'method', 'comparison'],
    how='left' # Keep all scaffold rows, fill missing data with NaN
  ).assign(
    group1=lambda df: df['comparison'].str.split('_vs_', expand=True)[0],
    group2=lambda df: df['comparison'].str.split('_vs_', expand=True)[1],
    p_stars=lambda x: np.select(
        [x["p-adj"] <= 0.001, x["p-adj"] <= 0.01, x["p-adj"] <= 0.05, True],
        ["***", "**", "*", ""], default=""
    ),
    meandiff_format=lambda x: "Δ " + x.meandiff.mul(100).round(2).astype(str) + "%",
    padj_format=lambda x: np.select(
        [x["p-adj"] < 0.01, x["p-adj"] < 0.05, True],
        ["FDR<0.01", "FDR " + x["p-adj"].round(2).astype(str), "n.s."],
        default="n.s."
    )
  ).join(general_cells, on="celltype") # Add lineage information
  .assign(comparison_cat=lambda df: pd.Categorical(df['comparison'], categories=comp_order, ordered=True))
  .sort_values(["lineage", "celltype", "method", "comparison_cat"])
  .drop(columns=['comparison_cat'])
  .reset_index(drop=True)
)

# Define heatmap cell height and calculate total plot height
heatmap_target_cell_height = 40
num_y_categories = stat_comb_prim.celltype.nunique()
calculated_heatmap_height = heatmap_target_cell_height * num_y_categories if num_y_categories > 0 else plt_width

```

For the Biopsy samples comparison:

```{python}
stat_comb = stat_comb_prim.query("method == 'bio'")
stat_comb_celltypes = stat_comb.celltype.drop_duplicates().values

# create a dummy dataframes for the custom scale hack
# This dataframe seems intended for a very specific annotation,
# as 'celltype' is fixed to the first unique celltype.
stat_tmp_groups = pd.DataFrame({
  "base": cycle_order,
  "celltype": stat_comb_celltypes[-1],
  "loc": np.linspace(0,1,len(cycle_order))
  })

# set up basechart for the Y axis (previously X) and X axis (previously Y)
base_chart = alt.Chart(stat_comb).encode(
  x=alt.X("comparison:N", sort=comp_order).axis(labels=True, labelAngle=-30, ticks=True, title=None, labelFontSize=12),
  y=alt.Y("celltype:N", sort=stat_comb_celltypes).axis(labels=True, title=None, labelFontSize=12)
)

# the base heatmap
heatmap = base_chart.mark_rect().encode(
  color=alt.Color("meandiff:Q").scale(scheme="blueorange", domain=[-.2,.2]).legend(None))

# the grey background for the missing values
grey_background = base_chart.mark_rect().encode(
  color=alt.condition(alt.datum.meandiff == None, alt.value("lightgrey"), alt.value(None)))

# This layer creates a color strip for lineages, positioned to the right of the main plot.
yaxis_color_strip = alt.Chart(stat_comb).mark_rect().encode(
  y=alt.Y("celltype:N", sort=stat_comb_celltypes),
  xOffset=alt.value(10), # was yOffset, using o, increased for spacing
  color=alt.Color("lineage:N", scale=global_color_lineage).legend(None)
)

# the significance testing texty part
base_text = base_chart.encode(
  x=alt.X("comparison:N", sort=comp_order).axis(labels=False, ticks=False, title=None))
# Use dy for vertical positioning, dx for horizontal if needed (or align)
text_overlay_stars = base_text.mark_text(fontWeight="bold", fontSize=20, align="center", dy=-8).encode(
  text=alt.Text("p_stars"),
  color=alt.condition((alt.datum.meandiff > 0.15) | (alt.datum.meandiff < -0.15), alt.value('white'), alt.value('black'))
)
text_overlay_pval = base_text.mark_text(fontSize=9, align="center", dy=0).encode(
  text=alt.Text("padj_format:N"),
  color=alt.condition((alt.datum.meandiff > 0.15) | (alt.datum.meandiff < -0.15), alt.value('white'), alt.value('black'))
)
text_overlay_diff = base_text.mark_text(fontSize=9, align="center", dy=12).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("meandiff_format:N")),
  color=alt.condition((alt.datum.meandiff > 0.15) | (alt.datum.meandiff < -0.15), alt.value('white'), alt.value('black'))
)
text_overlay_ns = base_text.mark_text(fontSize=9, align="center", dy=0).encode(
  text=alt.when(~alt.datum.reject).then(alt.Text("padj_format:N")),
  color=alt.value("grey")
)

comp_stats_bio_plt = (
  yaxis_color_strip + grey_background + heatmap +
  text_overlay_stars + text_overlay_diff + text_overlay_pval + text_overlay_ns
).properties(width=plt_height, height=calculated_heatmap_height) # Use calculated height

comp_stats_bio_plt.show()
```

For the UF samples comparison:

```{python}
stat_comb = stat_comb_prim.query("method == 'uf'")
stat_comb_celltypes = stat_comb.celltype.drop_duplicates().values
# move meandiff to percentages
stat_comb.meandiff = stat_comb.meandiff * 100

# create a dummy dataframes for the custom scale hack
stat_tmp_groups = pd.DataFrame({
  "base": cycle_order,
  "celltype": stat_comb_celltypes[-1],
  "loc": np.linspace(0,1,len(cycle_order))
  })

# set up basechart for the Y axis (previously X) and X axis (previously Y)
base_chart = alt.Chart(stat_comb).encode(
  x=alt.X("comparison:N", sort=comp_order).axis(labels=True, labelAngle=-30, ticks=True, title=None, titleY=25, labelFontSize=12),
  y=alt.Y("celltype:N", sort=stat_comb_celltypes).axis(labels=False, ticks=False, title=None, labelFontSize=12)
)

# the base heatmap
heatmap = base_chart.mark_rect().encode(
  color=alt.Color("meandiff:Q").scale(scheme="blueorange", domain=[-20,20]).legend(title="Mean Delta (%)", labelFontSize=12, titleFontSize=13)
  )

# the grey background for the missing values
grey_background = base_chart.mark_rect().encode(
  color=alt.condition(alt.datum.meandiff == None, alt.value("lightgrey"), alt.value(None)))

# This layer creates a color strip for lineages, positioned to the right of the main plot.
yaxis_color_strip = alt.Chart(stat_comb).mark_rect().encode(
  y=alt.Y("celltype:N", sort=stat_comb_celltypes).axis(title=None),
  x2=alt.value(-10), # set to 0 to not draw it behind the main heatmap (shows small lines)
  color=alt.Color("lineage:N", scale=global_color_lineage).legend(title="Lineage", labelFontSize=12, titleFontSize=13)
)

# the significance testing texty part
# base_text overrides the x-axis of the base_chart for text mark positioning
base_text = base_chart.encode(
  x=alt.X("comparison:N", sort=comp_order).axis(labels=False, ticks=False, title=None))
# Use dy for vertical positioning of text
text_overlay_stars = base_text.mark_text(fontWeight="bold", fontSize=20, align="center", dy=-8).encode(
  text=alt.Text("p_stars"),
  color=alt.condition((alt.datum.meandiff > 15) | (alt.datum.meandiff < -15), alt.value('white'), alt.value('black'))
)

text_overlay_pval = base_text.mark_text(fontSize=9, align="center", dy=0).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("padj_format:N")),
  color=alt.condition((alt.datum.meandiff > 15) | (alt.datum.meandiff < -15), alt.value('white'), alt.value('black'))
)

text_overlay_ns = base_text.mark_text(fontSize=9, align="center", dy=0).encode(
  text=alt.when(~alt.datum.reject).then(alt.Text("padj_format:N")),
  color=alt.value("grey")
)

text_overlay_diff = base_text.mark_text(fontSize=9, align="center", dy=12).encode(
  text=alt.when(alt.datum.reject).then(alt.Text("meandiff_format:N")),
  color=alt.condition((alt.datum.meandiff > 15) | (alt.datum.meandiff < -15), alt.value('white'), alt.value('black'))
)

comp_stats_uf_plt = (
  yaxis_color_strip + grey_background + heatmap +
  text_overlay_stars + text_overlay_diff + text_overlay_pval + text_overlay_ns
).properties(width=plt_height, height=calculated_heatmap_height) # Use calculated height

comp_stats_uf_plt.show()
```

And combined on top of each other

```{python}
# remove the legend from one of those plots, id does not sync it for some reason
# TODO: the lineage colors are still not synchronised
comp_stats_plt = (comp_stats_bio_plt | comp_stats_uf_plt).resolve_scale(x="independent")
comp_stats_plt.show()
```

:::

Combining them all into one.

```{python}
# have to resolve the color scale, otherwise the loadings_plt will override the biplot's scale
fig2 = (
  (peruvian_all | comp_stats_plt) &
  (biplot | loadings_plt).resolve_scale(color="independent", shape="independent")
).resolve_scale(color="independent", shape="independent")

fig2.save(fig_loc / "fig_2.svg", scale_factor=5)

fig2.show()
  ```

## FIG 3: Comparison of Biopsy and EV Sampling Methods

Here we focus on the comparison of the paired sample profiles from **both** biopsy and UF origin.

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Dendro-barplot of Fractions {.unnumbered .unlisted}

```{python}

# Get unique cycle phases
unique_cycle_phases = ccht_uf_pheno.cyclephase.cat.categories

# Initialize a list to store the plots
phase_plots = []
num_phases = len(unique_cycle_phases)

# Loop through each cycle phase and generate a plot
for i, phase in enumerate(unique_cycle_phases):
  # Filter phenotype data for the current phase
  pheno_subset = ccht_uf_pheno[ccht_uf_pheno['cyclephase'] == phase]
  # Filter fraction data for the samples in the current phase
  frac_subset = frac_pred.loc[pheno_subset.index]

  # Determine if legend should be shown
  show_legend_for_plot = (i == num_phases - 1)

  # Create the dendro-barplot for the current phase
  dendro_barplot_phase = create_dendro_barplot(
    fractions_df=frac_subset,
    phenotype_df=pheno_subset,
    general_cells_df=general_cells,
    plot_title=f"Phase: {phase}",
    plot_width=max(80, len(frac_subset.index) * 20),
    plot_height=150,
    group_color_scale=global_color_group,
    lineage_color_scale=global_color_lineage,
    show_legend=show_legend_for_plot  # Pass the legend visibility argument
  )
  phase_plots.append(dendro_barplot_phase)

# Combine the plots horizontally if there are any plots
combined_plot = alt.hconcat(*phase_plots).resolve_scale(color='shared')
combined_plot.show()

```

### Correlation Heatmap of the Paired Samples {.unnumbered .unlisted}

```{python}
# calculate the correlation matrix and prepare data for the plot
# first we create a phenotype file to order the samples after
prepped_pheno = (
  ccht_uf_pheno
  .loc[frac_pred.index]
  .assign(HUT=lambda x: x.index.str.extract(r"(S\d+)", expand=False))
  .sort_values(["cyclephase", "HUT"])
)

# select only samples with corresponding HUT pair
paired_samples_stem = prepped_pheno.HUT.value_counts().to_frame().query("count > 1").index
prepped_pheno = prepped_pheno.query("HUT in @paired_samples_stem")

# run a corr matrix with itself
corr_mat = (
  # transpose to run correlation against the samples
  frac_pred.loc[prepped_pheno.index].T.corr(method="spearman")
  # select out only cols with UF in columns and biopsy in rows
  .filter(regex="UF", axis=0).filter(regex="tissue", axis=1)
  # stack it into long version for Altair
  .stack().rename("correlation").to_frame().reset_index(names=["y_vars", "x_vars"])
  # now add a cols with the locations of last groups
  .join(prepped_pheno[["cyclephase"]], on="x_vars")
  .join(prepped_pheno[["cyclephase"]], on="y_vars", lsuffix="_y")
)
```

```{python}
# create Altair plot
base_heatmap = alt.Chart(corr_mat).mark_rect().encode(
  x=alt.X('x_vars:O', sort=corr_mat.x_vars.unique(), title=None).axis(offset=10),
  y=alt.Y('y_vars:O', sort=corr_mat.y_vars.unique(), title=None).axis(orient="right", offset=10),
  color=alt.Color('correlation:Q').scale(scheme='magma', domain=[0, .8]).title("Spearman's ρ") # Quantitative for correlation values, using magma colormap with 0-1 domain
)

# add the color groupings 
x_group_colors = base_heatmap.mark_rect().encode(
  x=alt.X('x_vars:O', sort=corr_mat.x_vars.unique(), title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase:N", scale=global_color_phase).title("Cycle Phase"),
  xOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

y_group_colors = base_heatmap.mark_rect().encode(
  y=alt.Y('y_vars:O', sort=corr_mat.y_vars.unique(), title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase_y:N", scale=global_color_phase).legend(None),
  yOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

# add horizontal and vertical lines to separate the groups
x_lines = alt.Chart(
  corr_mat.groupby('cyclephase_y').last().apply(lambda x: x.iloc[:-1]).reset_index(drop=True)
).mark_rule(color='white', strokeWidth=2, xOffset=10).encode(
  x=alt.X("x_vars:O", sort=corr_mat.x_vars.unique())
)
y_lines = alt.Chart(
  corr_mat.groupby('cyclephase').last().apply(lambda x: x.iloc[:-1]).reset_index(drop=True)
).mark_rule(color='white', strokeWidth=2, yOffset=10).encode(
  y=alt.Y("y_vars:O", sort=corr_mat.y_vars.unique())
)

# Layer heatmap and colors
final_chart = (
  x_group_colors + y_group_colors + base_heatmap + x_lines + y_lines
  ).resolve_scale(x='shared', y='shared', color='shared')

# Display the chart
final_chart
```

In addition to the heatmap, we can calculate the average correlation between the biopsy and UF samples for each cycle phase combination. This could be later on added on top of the heatmap or used to create a separate summary table.

```{python}
# Calculate the average correlation for each combination of
# x_vars' cyclephase (biopsy samples) and y_vars' cyclephase (UF samples)
avg_cyclephase_correlation_matrix = (
  corr_mat.groupby(['cyclephase', 'cyclephase_y'])['correlation']
  .mean()
  .reset_index()
  .rename(columns={'cyclephase_y': 'biopsy_cyclephase', 'cyclephase': 'uf_cyclephase', 'correlation': 'avg_correlation'})
)

# Create the heatmap
# The sort=cycle_order argument ensures the phases are ordered as "pro", "pre", "rec", "LS"
heatmap_avg_corr = alt.Chart(avg_cyclephase_correlation_matrix).mark_rect().encode(
    x=alt.X('biopsy_cyclephase:N', title='Biopsy Cycle Phase', sort=cycle_order),
    y=alt.Y('uf_cyclephase:N', title='UF Cycle Phase', sort=cycle_order).axis(orient='right'),
    color=alt.Color('avg_correlation:Q', scale=alt.Scale(scheme='magma', domain=[0, 1]), legend=alt.Legend(title="Avg. Correlation"))
).properties(
    title='Average Correlation between Tissue and UF-EV Samples by Cycle Phase',
    width=200,
    height=200
)

# Create the text layer
text_avg_corr = heatmap_avg_corr.mark_text(baseline='middle').encode(
    text=alt.Text('avg_correlation:Q', format='.2f'),
    color=alt.condition(
        alt.datum.avg_correlation < 0.6,  # Adjust threshold for better contrast
        alt.value('white'),
        alt.value('black')
    )
)

# Combine heatmap and text
avg_corr_heatmap_plot = heatmap_avg_corr + text_avg_corr
avg_corr_heatmap_plot.show()

```

### Volcano plot with the difference in deconvolution profiles {.unnumbered .unlisted}

Here we transform the deconvolution profiles into a volcano plot, where we show the differences in the proportions of the cell types between the biopsy and UF samples.

```{python}
## calculate the diff
avg_uf = frac_pred.loc[prepped_pheno.query("group == 'UF-EV'").index,].agg("mean")
avg_bio = frac_pred.loc[prepped_pheno.query("group == 'Tissue'").index,].agg("mean")
# calculate bonferroni correction for the p-values
diff_df = (
  pd.DataFrame({"diff": avg_uf - avg_bio})
  .join(ccht_comp_stat)
  .rename(columns={"p-val": "pval"})
  .assign(p_adj_bonf = lambda x: (x["pval"] * len(ccht_comp_stat.index)).clip(upper=1.0))
)
threshold_p = .05

## base plot
volcano_base = alt.Chart(
  diff_df.reset_index(), view=alt.ViewConfig(strokeWidth=0)
).mark_point(
  filled=True, opacity=.7
).encode(
  x=alt.X("diff:Q").scale(domain=[-.12, .12]).axis(title="Mean Proportion Difference (UF-EV - Tissue)", tickCount=4),
  y=alt.Y("p_adj_bonf:Q").scale(type="log", base=10, reverse=True).axis(title="Adjusted p-value (Bonferroni)", tickCount=8),
  color=alt.condition(alt.datum.p_adj_bonf < threshold_p, alt.value("red"), alt.value("grey"))
)

## the text for the top two diff celltypes
volcano_annot = alt.Chart(
  diff_df.reset_index().sort_values("pval").query("p_adj_bonf < @threshold_p").assign(text_angle=lambda x: np.where(x["diff"] < 0, 330, 30))
).mark_text(align="center", dy=-8, angle=alt.expr(alt.datum.text_angle)).encode(
  x=alt.X("diff:Q"), y=alt.Y("p_adj_bonf:Q"),
  text=alt.Text("celltype:N")
)

## the dividing line
rule_tmp = pd.DataFrame({"threshold_p": [ threshold_p ]})
rule_y = alt.Chart(rule_tmp).mark_rule(color='black', strokeDash=[3,3]).encode(y="threshold_p")
volcano = volcano_base + volcano_annot + rule_y
volcano.interactive()
```

:::

```{python}
fig3 = (combined_plot & (final_chart | volcano)).resolve_scale(color="independent")

fig3.save(fig_loc / "fig_3.svg", scale_factor=5)

fig3.show()
```

## FIG 4: Comparison of Giacomini et al. and our sampling methods

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Dendro-barplot of Fractions {.unnumbered .unlisted}

```{python}
# Get unique cycle phases from the phenotype data
unique_cycle_phases = comb_uf_pheno['cyclephase'].unique()

# Initialize a list to store the plots for each cycle phase
phase_plots = []
num_phases = len(unique_cycle_phases)

# Loop through each unique cycle phase to create a separate plot
for i, phase in enumerate(unique_cycle_phases):
  # Filter phenotype data for the current phase
  pheno_subset = comb_uf_pheno[comb_uf_pheno['cyclephase'] == phase]
  # Filter fraction data for the samples in the current phase
  frac_subset = frac_comb.loc[pheno_subset.index]

  # Determine if legend should be shown (e.g., only for the last plot)
  show_legend_for_plot = (i == num_phases - 1)

  # Call the create_dendro_barplot function for the current phase
  dendro_bar_phase_chart = create_dendro_barplot(
    fractions_df=frac_subset,
    phenotype_df=pheno_subset.drop(columns=["group"]).rename(columns={"dataset": "group"}),
    general_cells_df=general_cells,
    plot_title=f"Combined UF Samples: {phase.upper()}", # Title indicating the phase
    plot_width=max(300, len(frac_subset.index) * 25), # Adjust width based on number of samples
    plot_height=150,
    bar_width=16, # Width of the bar
    group_color_scale=global_color_group2,
    lineage_color_scale=global_color_lineage,
    show_legend=show_legend_for_plot
  )
  phase_plots.append(dendro_bar_phase_chart)

dendro_bar = alt.hconcat(*phase_plots).resolve_scale(
  color='shared' # Share color scale for cell types across plots
)

dendro_bar.show()
```



### Correlation Heatmap of UF samples {.unnumbered .unlisted}

```{python}
# run a corr matrix with itself and select out the interesting rows
corr_mat = (
  # transpose to run correlation against the samples, not celltypes
  frac_comb.loc[comb_uf_pheno.sort_values(["dataset", "cyclephase"], key=lambda x: pd.Categorical(x, categories=["pre", "rec"])).index].T.corr(method="spearman")
  # select out Vigano and CCHT in both axes
  .filter(regex="plus", axis=0).filter(regex="UF", axis=1)
)

corr_long = (
  corr_mat
  # stack it into long version for Altair
  .stack().rename("correlation").to_frame().reset_index(names=["y_vars", "x_vars"])
  # Assign 'cyclephase_x' by mapping 'x_vars' to 'comb_uf_pheno.cyclephase'
  .assign(
    cyclephase_y = lambda df: df['y_vars'].map(comb_uf_pheno['cyclephase'].astype(str)),
    cyclephase_x = lambda df: df['x_vars'].map(comb_uf_pheno['cyclephase'].astype(str))
  )
)
```

```{python}
# Order the x and y samplenames based on cyclephase as defined with cycle_order
ordnung_x = (
  corr_long[["x_vars", "cyclephase_x"]]
  .drop_duplicates(ignore_index=False)
  .sort_values("cyclephase_x", key=lambda x: pd.Categorical(x, categories=["ES", "MS"], ordered=True))
  ["x_vars"]
)
ordnung_y = corr_long[["y_vars", "cyclephase_y"]].drop_duplicates(ignore_index=False)

# Create Altair plot
base_heatmap = alt.Chart(corr_long).mark_rect().encode(
  x=alt.X('x_vars:N', sort=ordnung_x, title=None).axis(offset=10),
  y=alt.Y('y_vars:N', sort=ordnung_y, title=None).axis(orient="right", offset=10),
  color=alt.Color('correlation:Q').legend(title="Spearman's ρ").scale(scheme='magma', domain=[0, 1]) # Quantitative for correlation values, using magma colormap
  )

# add the color groupings 
x_group_colors = base_heatmap.mark_rect().encode(
  x=alt.X('x_vars:N', sort=ordnung_x, title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase_x:N", scale=alt.Scale(domain=["ES", "MS"], range=[phase_colors["ES"], phase_colors["MS"]])).legend(None),
  yOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

y_group_colors = base_heatmap.mark_rect().encode(
  y=alt.Y('y_vars:N', sort=ordnung_y, title=None), # Nominal for categorical x-axis
  color=alt.Color("cyclephase_y:N").legend(title="Cycle Phase").scale(
    domain=["ES", "MS"], 
    range=[phase_colors["ES"], phase_colors["MS"]]),
  xOffset=alt.value(10), # set it to +10 of the plot height so that it would overlap
)

# add horizontal and vertical lines to separate the groups
x_lines = alt.Chart(
  corr_long.groupby('cyclephase_x').last().apply(lambda x: x.iloc[:-1]).reset_index(drop=True)
).mark_rule(color='white', strokeWidth=2, xOffset=10).encode(
  x=alt.X("x_vars:O", sort=ordnung_x, title=None)
)
y_lines = alt.Chart(
  corr_long.groupby('cyclephase_y').last().apply(lambda x: x.iloc[:-1]).reset_index(drop=True)
).mark_rule(color='white', strokeWidth=2, yOffset=10).encode(
  y=alt.Y("y_vars:O", sort=ordnung_y, title=None)
)

# Layer heatmap and colors
dendro_corrplot = (
  y_group_colors + x_group_colors + base_heatmap + x_lines + y_lines
  ).resolve_scale(x='shared', y='shared', color='independent').properties(width=150, height=450)
dendro_corrplot.show()
```

In addition to the base heatmap, we can calculate the average correlation between the Celvia and Vigano group samples for each cycle phase combination. This could be later on added on top of the heatmap or used to create a separate summary table.

```{python}
# Calculate the average correlation for each combination of
# x_vars' cyclephase (biopsy samples) and y_vars' cyclephase (UF samples)
avg_cyclephase_correlation_matrix = (
  corr_long.groupby(['cyclephase_x', 'cyclephase_y'])['correlation']
  .mean()
  .reset_index()
  .rename(columns={'cyclephase_x': 'celvia_cyclephase', 'cyclephase_y': 'vigano_cyclephase', 'correlation': 'avg_correlation'})
)

# Create the heatmap
# The sort=cycle_order argument ensures the phases are ordered as "pro", "pre", "rec", "post"
heatmap_avg_corr = alt.Chart(avg_cyclephase_correlation_matrix).mark_rect().encode(
  x=alt.X('celvia_cyclephase:N', title='Celvia Cycle Phase', sort=cycle_order),
  y=alt.Y('vigano_cyclephase:N', title='Vigano Cycle Phase', sort=cycle_order).axis(orient='right'),
  color=alt.Color(
    'avg_correlation:Q', 
    scale=alt.Scale(scheme='magma', domain=[0, 1]), 
    legend=alt.Legend(title="Avg. Correlation")
    )
).properties(
  title='Average Correlation between Celvia and Vigano Samples by Cycle Phase',
  width=200,
  height=200
)

# Create the text layer
text_avg_corr = heatmap_avg_corr.mark_text(baseline='middle').encode(
  text=alt.Text('avg_correlation:Q', format='.2f'),
  color=alt.condition(
    alt.datum.avg_correlation < 0.6,  # Adjust threshold for better contrast
    alt.value('white'),
    alt.value('black')
  )
)

# Combine heatmap and text
avg_corr_heatmap_plot = heatmap_avg_corr + text_avg_corr
avg_corr_heatmap_plot.show()

```

### Deconvolution with batch correction

```{python}
# some params for the pcas
shape_range = ["diamond", "square"]
dims = {"height": 200, "width": 200}
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(frac_comb), columns=["PC1", "PC2"])
  .set_index(frac_comb.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_one = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N").scale(global_color_group2).legend(None),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range).legend(None)
).properties(title="Deconvolution with batch correction", **dims)
pca_one
```

### Deconvolution without batch correction

```{python}
# filter out biopsy samples
frac_tmp = frac_comb_raw.loc[~frac_comb_raw.index.str.contains("tissue")]
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(frac_tmp), columns=["PC1", "PC2"])
  .set_index(frac_tmp.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_two = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N").scale(global_color_group2).legend(None),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range).legend(None)
).properties(title="Deconvolution without batch correction", **dims)
pca_two
```

### Raw counts with batch correction

```{python}
# filter out biopsy samples
counts_tmp = comb_batch.T.loc[~comb_batch.T.index.str.contains("tissue")]
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(counts_tmp), columns=["PC1", "PC2"])
  .set_index(counts_tmp.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_three = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N").scale(global_color_group2),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Raw counts with batch correction", **dims)
pca_three
```

### Raw counts without batch correction

```{python}
# filter out biopsy samples
counts_tmp = comb_raw.T.loc[~comb_raw.T.index.str.contains("tissue")]
# PCA calculation
pca = PCA(n_components=2)
pca_df = (
  pd.DataFrame(data=pca.fit_transform(counts_tmp), columns=["PC1", "PC2"])
  .set_index(counts_tmp.index)
  .merge(comb_uf_pheno, left_index=True, right_index=True)
)
expl_var = pca.explained_variance_ratio_

# --- Create the base scatter plot ---
pca_four = alt.Chart(pca_df).mark_point(
  size=40, filled=True
).encode(
  x=alt.X("PC1:Q", axis=alt.Axis(title=f"PC1 ({expl_var[0]:.2%})", tickCount=1)),
  y=alt.Y("PC2:Q", axis=alt.Axis(title=f"PC2 ({expl_var[1]:.2%})", tickCount=1)),
  color=alt.Color("dataset:N").scale(global_color_group2),
  shape=alt.Shape("cyclephase:N").scale(range=shape_range)
).properties(title="Raw counts without batch correction", **dims)
pca_four
```


:::

```{python}
pca_block = (
  (pca_one & pca_two).resolve_scale(color="independent", shape="independent")
  | (pca_three & pca_four).resolve_scale(color="shared", shape="shared")
  ).resolve_scale(color="independent", shape="independent")
fig4 = (
  (
    dendro_bar &
      (pca_block | dendro_corrplot).resolve_scale(color="independent", shape="independent")
  )
)

fig4.save(fig_loc / "fig_4.svg", scale_factor=5)

fig4.show()
```

## FIG 5 & Supp. FIG 2: Spatial Projections

Given the nature of the data, we expect to see a high correlation between the projected biopsy and the reference raw scRNA-seq data. The projected UF data should be more dispersed, as the UF samples are not directly comparable to the biopsy samples. Still, the UF samples should show a similar pattern of cell type distribution as the biopsy samples, per the assumption that the abundances of cell types in the UF samples indicate where the EV's are coming from in the tissue.

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### Example of a ST slide

```{python}
# show the example slide sample
adat = adata_collection[(slide_ids[0], "ref")].to_memory()
crop_coords = get_spatial_crop_coords(adat)
sq.pl.spatial_scatter(
  adat,
  color=[None], crop_coord=crop_coords,
  ncols=2,
  figsize=(6, 3),
  save=fig_loc / "fig_5a_1.svg"
  )
```

### Example of the projected abundcances with single cell type

```{python}
# and then show a single exemplary cell type in different projections
cts = ["Glandular"]

sq.pl.spatial_scatter(
  adat,
  cmap='magma',
  color=cts,
  crop_coord=crop_coords,
  size=1.3, title="Glandular - Reference scRNA-seq",
  figsize=(6, 3),
  save=fig_loc / "fig_5a_2.svg"
)
sq.pl.spatial_scatter(
  adata_collection[(slide_ids[0], "ev")],
  cmap='magma',
  color=cts,
  crop_coord=crop_coords,
  size=1.3, title="Glandular - UF-EV pSC",
  figsize=(6, 3),
  save=fig_loc / "fig_5a_3.svg"
)
sq.pl.spatial_scatter(
  adata_collection[(slide_ids[0], "bio")],
  cmap='magma',
  color=cts,
  crop_coord=crop_coords,
  size=1.3, title="Glandular - Tissue pSC",
  figsize=(6, 3),
  save=fig_loc / "fig_5a_4.svg"
)
```

### Example of the UMAP clustering of generated single cell data

The cell types are now separated by the lineage class they belong to.

```{python}
# Also plot the tissue data for comparison
unique_lineages_bio = gen_ccht_bio.obs['lineage'].unique()
color_map_dict = celltype_colors
# Add gray color for all unique lineages
color_map_dict["Other"] = 'lightgray'

def plot_lineage_umap(adata_bio, adata_ev, lineage, color_map_dict, figsize=(8, 3), save=None):
  """Plot UMAP for both tissue and EV datasets for a specific lineage."""
  def mask_celltype_by_lineage(adata, lineage):
    """Mask celltypes not in the current lineage."""
    temp_adata = adata.copy()
    temp_adata.obs['celltype_masked'] = (
      temp_adata.obs['celltype']
      .astype(str)
      .where(temp_adata.obs['lineage'] == lineage, other="Other")
      .pipe(lambda s: pd.Categorical(
        s, 
        categories=[val for val in s.unique() if val != "Other"] + 
                    (["Other"] if "Other" in s.unique() else []),
        ordered=True
      ))
    )
    return temp_adata
  
  # Mask celltypes for both datasets
  temp_adata_bio = mask_celltype_by_lineage(adata_bio, lineage)
  temp_adata_ev = mask_celltype_by_lineage(adata_ev, lineage)
  
  # Create subplot with fixed size
  fig, axes = plt.subplots(1, 2, figsize=figsize)
  # Disable automatic tight_layout which can resize plots
  fig.subplots_adjust(left=0.05, right=0.85, top=0.9, bottom=0.1, wspace=0.2)
  # Add lineage title to the right edge
  fig.text(-.015, 0.5, f"{lineage}", rotation=90, va='center', ha='left', 
      fontsize=14, transform=fig.transFigure)
  
  # Plot tissue data
  # Set the figure size explicitly before plotting
  axes[0].set_aspect('equal')  # Keep aspect ratio
  
  sc.pl.embedding(
    temp_adata_bio, 
    basis='X_umap', color='celltype_masked', title="Tissue pSC", 
    legend_loc=None,
    palette=color_map_dict,
    ax=axes[0],
    frameon=False,
    show=False
  )
  
  # Plot EV data
  sc.pl.embedding(
    temp_adata_ev, 
    basis='X_umap', color='celltype_masked', title="UF-EV pSC", 
    legend_loc="right margin", legend_fontsize=7, legend_fontoutline=2,
    palette=color_map_dict,
    ax=axes[1],
    frameon=False,
    show=False
  )
  
  # Ensure all colors from the lineage are shown in the legend
  # Get all celltypes for this lineage from the original data
  lineage_celltypes = general_cells[general_cells['lineage'] == lineage].index.tolist()
  
  # Create custom legend patches for all celltypes in this lineage
  legend_patches = [
    mpatches.Patch(color=color_map_dict[ct], label=ct) 
    for ct in lineage_celltypes + ["Other"] if ct in color_map_dict
  ]
  
  # Add the legend to the right subplot
  axes[1].legend(
    handles=legend_patches, 
    loc='center left', 
    bbox_to_anchor=(1, 0.5),
    fontsize=10,
    frameon=False
  )

  if save:
    plt.savefig(save, bbox_inches='tight')
  plt.show()

# Plot for all lineages
for lineage in unique_lineages_bio:
  plot_lineage_umap(gen_ccht_bio, gen_ccht_ev, lineage, color_map_dict, save=fig_loc / f"fig_5b_{lineage}.svg")
```

### The boxplots of different comparison methods

```{python}
# --- Data Preparation ---
plot_df_pairwise = stats_df[stats_df['comparison'].isin(['ev_vs_ref', 'bio_vs_ref'])].copy()
plot_df_pairwise = plot_df_pairwise.query("lineage in ['Epithelial', 'Stromal', 'Immune']") # Filter for relevant lineages
stats_df[["lineage", "celltype"]].drop_duplicates()
exclude_metrics = ["Pearson Correlation"]  # Metrics to exclude from visualization
col_wrap = 3  # Number of columns for facet wrapping

# Filter out excluded metrics
filtered_df = plot_df_pairwise[~plot_df_pairwise['metric'].isin(exclude_metrics)]

# --- Altair Plot Construction ---
# 1. Define the base boxplot
boxplot = alt.Chart(filtered_df).mark_boxplot(extent='min-max').encode(
  x=alt.X('lineage:N', title=None, axis=alt.Axis(labelAngle=45)),  # Rotate x-axis labels
  y=alt.Y('value:Q', title='Value'),  # Statistic value on Y-axis
  xOffset=alt.XOffset('comparison:N', title=None),  # Rotate x-axis labels
  color=alt.Color('comparison:N', legend=alt.Legend(title='Comparison'))  # Color by comparison
)

# 2. Apply faceting
boxplots = boxplot.facet(
  column=alt.Column('metric:N', title=None, header=alt.Header(labelOrient='top')),  # Facet by metric
  row=alt.Row('cyclephase:N', title=None, header=alt.Header(labelOrient='right'))  # Facet by cyclephase
).resolve_scale(
  x='independent',
  y='independent'
).properties(
  title=alt.TitleParams(
    'Boxplots of Statistics by Metric and Comparison',
    anchor='middle'  # Center the title
  )
)

# To display in a Jupyter environment:
boxplots.save(fig_loc / 'fig_s3.svg', scale_factor=5)  # Save the plot as SVG with high resolution
boxplots.interactive()
```

### Pearson correlation

```{python}
# 0. Prepare the data for the scatter plot
metric_to_plot = 'Pearson Correlation' # Choose a metric
scatter_df = (
  plot_df_pairwise[plot_df_pairwise['metric'] == metric_to_plot]
  # Add cyclephase to the index for faceting
  .pivot_table(index=['slide_id', 'celltype', 'lineage', 'cyclephase'], columns='comparison', values='value')
  .reset_index()
)
scatter_df.dropna(inplace=True) # Drop rows if one comparison is missing

# 1. Define the base scatter plot layer
# Data will be passed during faceting because we layer first
points = alt.Chart().mark_point(filled=True, size=60, opacity=0.7).encode(
  x=alt.X('ev_vs_ref', title='UF-EV pSC vs scRNA-seq'), # Set axis title
  y=alt.Y('bio_vs_ref', title='Tissue pSC vs scRNA-seq'), # Set axis title
  color=alt.Color('celltype', legend=alt.Legend(title="Celltype", orient='bottom-right', labelFontSize=9, offset=0)), # Add legend title
  tooltip=['slide_id', 'celltype', 'lineage', 'ev_vs_ref', 'bio_vs_ref'] # Tooltips
)

# 2. Prepare data for the y=x diagonal line
# Calculate overall min/max across both relevant columns IN THE FILTERED DATA
min_val = min(scatter_df['ev_vs_ref'].min(), scatter_df['bio_vs_ref'].min())
max_val = max(scatter_df['ev_vs_ref'].max(), scatter_df['bio_vs_ref'].max())
# Add a small buffer to ensure the line extends slightly beyond points
buffer = (max_val - min_val) * 0.05
min_val = min_val - buffer if min_val - buffer is not np.nan else 0 # Handle potential NaN from empty df
max_val = max_val + buffer if max_val + buffer is not np.nan else 1 # Handle potential NaN

# 3. Define the diagonal line layer and the connecting line layer
line_df = pd.DataFrame({'x': [min_val, max_val], 'y': [min_val, max_val]})
diagonal_line = alt.Chart(line_df).mark_line(
  color='black',
  strokeDash=[5,5], # Dashed line style
  opacity=0.25      # Corresponds to alpha=0.25
).encode(x='x', y='y')

# Create the line layer connecting points within each celltype per facet
lines = points.mark_line(opacity=0.2).encode(order='celltype')

# 4. Layer the diagonal line and the points
# Line first so points are drawn on top
chart_layers = diagonal_line + lines + points

# 5. Apply faceting to the layered chart
corr_plots = chart_layers.facet(
  data=scatter_df, # Provide the data for faceting here
  # Add row faceting by cyclephase
  row=alt.Row('cyclephase', header=alt.Header(titleOrient="right", labelOrient="right", title=None)),
  column=alt.Column('lineage', header=alt.Header(titleOrient="top", labelOrient="top", title=None)), # Facet by lineage, remove default header title
  columns=3 # Corresponds to col_wrap=3
).resolve_scale(
  x='independent', # Don't share x-axis scale/limits
  y='independent', # Don't share y-axis scale/limits
  color='independent' # Don't share color scale/limits
).properties(
  title=alt.TitleParams( # Set overall title
    f'{metric_to_plot}: UF-EV pSC vs scRNA-seq & Tissue pSC vs scRNA-seq',
    anchor='middle' # Center the title
  )
)

# Display the chart
corr_plots.save(fig_loc / 'fig_s4.svg', scale_factor=5) # Save the plot as SVG with high resolution
corr_plots.interactive() # Enable zooming and panning and tooltips and selection and other fun interactivity
```

### Moran's autocorrelation

And now for the Moran's I compared to the Morans' simulated FDR (based on 1000 iterations). The Moran's I is a measure of spatial autocorrelation, and the FDR is a measure of how significant the Moran's I is compared to random distributions. We will plot the Moran's I against the FDR for each cell type and lineage, with a horizontal line at FDR = 0.05 to indicate significance.

```{python}
# Filter for Moran's I metrics
moran_df = stats_df[stats_df['metric'].isin(['Moran I', 'Moran I FDR'])].copy()

# Pivot the table to get metrics as columns
moran_pivot = (
  moran_df.pivot_table(
    index=['slide_id', 'celltype', 'lineage', 'comparison', 'cyclephase'],
    columns='metric',
    values='value'
  )
  .reset_index()
  .rename_axis(None, axis=1) # Remove the 'metric' name from columns index
  .replace({"comparison": {"bio": "Tissue", "ev": "UF-EV", "ref": "scRNA-seq"}}) # Rename comparison values
)

# Create dummy slide_id by appending comparison
moran_pivot['dummy_slide_id'] = moran_pivot['slide_id'].astype(str) + '_' + moran_pivot['comparison']

# --- Pivot for Heatmap Data and Mask ---
# Pivot for Moran I values (contains NaNs where data is missing)
heatmap_data = moran_pivot.pivot(index='celltype', columns='dummy_slide_id', values='Moran I')

# Pivot for Moran I FDR values (contains NaNs where data is missing)
fdr_data = moran_pivot.pivot(index='celltype', columns='dummy_slide_id', values='Moran I FDR')

# Create the mask: True where FDR >= 0.05 OR where FDR is NaN (missing)
# Mask should hide non-significant values.
mask = (fdr_data >= 0.05) | fdr_data.isna()

# --- Create column colors ---
# Need info for *all* columns in heatmap_data
col_info = moran_pivot[['dummy_slide_id', 'cyclephase', 'comparison']].drop_duplicates().set_index('dummy_slide_id')
# Ensure order matches heatmap columns and handle potential missing columns
heatmap_cols_info = col_info.reindex(heatmap_data.columns)

# 1. Cyclephase colors
unique_cyclephases = heatmap_cols_info['cyclephase'].dropna().unique()
cyclephase_color_map = {k: v for k, v in phase_colors.items() if k in unique_cyclephases}
cyclephase_colors = heatmap_cols_info['cyclephase'].map(cyclephase_color_map)

# 2. Comparison colors
unique_comparisons = heatmap_cols_info['comparison'].dropna().unique()
comparison_color_map = dict(zip(unique_comparisons, sns.color_palette(global_color_group3.scheme.capitalize(), len(unique_comparisons))))
comparison_colors = heatmap_cols_info['comparison'].map(comparison_color_map)

# Combine into a DataFrame for clustermap
# Providing a DataFrame to col_colors automatically triggers legend creation by seaborn
col_colors_df = pd.DataFrame({
  'Cycle Phase': cyclephase_colors,
  'Generated dataset': comparison_colors
})
col_colors_df.index = heatmap_data.columns # Ensure index matches heatmap columns

# Generate clustermap
g = sns.clustermap(
  heatmap_data.fillna(0), # Pass data with NaNs and significant/non-significant values
  mask=mask, # Pass the mask to hide non-significant values (where mask is True)
  row_cluster=True,
  col_cluster=True,
  col_colors=col_colors_df, # Pass the DataFrame with multiple annotations
  cmap="magma", # Or a diverging map like "vlag" if center is not None
  cbar_pos=(0.02, .82, .05, .16), # Adjust colorbar position
  figsize=(9, 9) # Adjust figsize if legends are cramped or cut off
)

# Angle the x-axis labels
g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right')

# Create handles for Cycle Phase legend
cycle_handles = [mpatches.Patch(color=cyclephase_color_map[name], label=name) for name in unique_cyclephases]
# Add the first legend - Position relative to the FIGURE edge
legend1 = g.fig.legend(handles=cycle_handles, title='Cycle Phase', bbox_to_anchor=(0.80, 1), loc='upper left', borderaxespad=0., frameon=False, alignment='left')

# Create handles for Projection dataset legend
comp_handles = [mpatches.Patch(color=comparison_color_map[name], label=name) for name in unique_comparisons]
# Add the second legend - Position below the first one
legend2 = g.fig.legend(handles=comp_handles, title='Generated dataset', bbox_to_anchor=(0.80, 0.93), loc='upper left', borderaxespad=0., frameon=False, alignment='left')

plt.suptitle("Clustered Heatmap of Significant Moran's I (FDR < 0.05)", y=1.02) # Add title
plt.savefig(fig_loc / "fig_5c.svg", bbox_inches='tight', dpi=300) # Save the figure
plt.show() # Display the plot
```

:::

> As these plots can't be visualised using a single framework (contains both matplotlib and Altair libraries), then these are the subplots that are generated separately and compiled later manually

```{python}
# # Try to make a layout plot with the spacers placeholder image
# raw_st_example = spacer_with_text(height=550, width=400)
# projection_example = spacer_with_text(height=550, width=400)
# (
#   (raw_st_example & projection_example) |
#   (boxplots & corr_plots & morans_chart)
# )
```


## SUPP FIG 1: QC and sample selection

We have excluded the following samples with their corresponding pair due to

* HUT10, HUT1, HUT71, HUT53, HUT17 were excluded due to poor clustering
* HUT10 does not have a paired biopsy sample
* HUT71, HUT53, HUT17 were excluded due to low biotype proportion
* HUT23_UF was swapped with HUT23_biopsy based on clustering, but excluded for the analysis

The correlation between techical replicates HUT71_biopsy, HUT71_biopsy_2, HUT71_biopsy_3 for TPM reads (average and the correlation matrix) is shown below.

```{python}
# Select columns containing "HUT71_biopsy"
hut71_biopsy_samples = ccht_uf_unfilt_tpm.filter(regex=resampler["HUT71_biopsy_1"].replace("_1", ""))

# Calculate the correlation between these samples
correlation_hut71 = hut71_biopsy_samples.corr(method='spearman')

# Average correlation between replicates is
# take it from the entry above the diagonal
print_corr = correlation_hut71.where(np.triu(np.ones(correlation_hut71.shape), k=1).astype(bool)).stack().mean()
print(f"Average correlation between tissue replicates: {print_corr:.2f}")

# Optional: visualize with seaborn if desired for a nicer output in the report
plt.figure(figsize=(4, 3))
sns.heatmap(correlation_hut71, annot=True, cmap="viridis", fmt=".2f")
plt.title("Correlation of Tissue Replicates")
plt.savefig(fig_loc / "fig_s1e.svg", bbox_inches='tight', dpi=300)
plt.show()
```

::: {.panel-tabset}

### Select a tab: {.unnumbered .unlisted}

### UMAP of the unfiltered and filtered samplesets {.unnumbered .unlisted}

```{python}
# Prepare data for UMAP
data_for_umap = ccht_uf_unfilt_tpm.T  # Transpose so samples are rows

# Perform UMAP
reducer = UMAP(random_state=42, n_neighbors=10, min_dist=0.5) # Use UMAP directly
embedding = reducer.fit_transform(data_for_umap)

# Create DataFrame for plotting
umap_df = pd.DataFrame(embedding, columns=['UMAP1', 'UMAP2'], index=data_for_umap.index)
umap_df = umap_df.join(ccht_uf_pheno_unfilt[["cyclephase", "group"]]).reset_index().rename(columns={"index": "samplename"})

# Create Altair plot
umap_plot_unfilt = alt.Chart(umap_df).mark_point(size=60, filled=True).encode(
  x=alt.X('UMAP1:Q', title='UMAP 1').scale(zero=False),
  y=alt.Y('UMAP2:Q', title='UMAP 2').scale(zero=False),
  color=alt.Color('cyclephase:N').legend(title='Cycle Phase').scale(global_color_phase),
  shape=alt.Shape('group:N', title='Sample Group'),
  tooltip=['samplename', 'cyclephase', 'group']
).properties(
  title='UMAP of unfiltered samples',
  width=250,
  height=250
)
```

```{python}
# Prepare data for UMAP
data_for_umap = ccht_uf_tpm.T  # Transpose so samples are rows

# Perform UMAP
reducer = UMAP(random_state=42, n_neighbors=10, min_dist=0.5) # Use UMAP directly
embedding = reducer.fit_transform(data_for_umap)

# Create DataFrame for plotting
umap_df = pd.DataFrame(embedding, columns=['UMAP1', 'UMAP2'], index=data_for_umap.index)
umap_df = umap_df.join(ccht_uf_pheno[["cyclephase", "group"]]).reset_index().rename(columns={"index": "samplename"})

# Create Altair plot
umap_plot = alt.Chart(umap_df).mark_point(size=60, filled=True).encode(
  x=alt.X('UMAP1:Q', title='UMAP 1').scale(zero=False),
  y=alt.Y('UMAP2:Q', title='UMAP 2').scale(zero=False),
  color=alt.Color('cyclephase:N').legend(title='Cycle Phase').scale(global_color_phase),
  shape=alt.Shape('group:N', title='Sample Group'),
  tooltip=['samplename', 'cyclephase', 'group']
).properties(
  title='UMAP of filtered samples',
  width=250,
  height=250
)
```

Plot the UMAPs below each other for comparison.

```{python}
umap_plot_unfilt.save(fig_loc / "fig_s1d.svg", scale_factor=5)  # Save the unfiltered UMAP
(umap_plot_unfilt & umap_plot).interactive()
```

### Correlation plot of the unfiltered sampleset {.unnumbered .unlisted}

```{python}
corr_mat_unfilt = ccht_uf_unfilt_tpm.corr(method='spearman')
pheno_unfilt_idx = ccht_uf_pheno_unfilt.query("samplename in @corr_mat_unfilt.index")

cyc_unfilt_u = pheno_unfilt_idx['cyclephase'].dropna().unique().tolist()
cyc_map_unfilt = dict(zip(global_color_phase.domain, sns.color_palette(global_color_phase.range)))
cyc_cols_unfilt = pd.Series([cyc_map_unfilt.get(phase) for phase in pheno_unfilt_idx['cyclephase']], index=pheno_unfilt_idx.index, name='cyclephase')

grp_unfilt_u = pheno_unfilt_idx['group'].dropna().unique().tolist()
# Create a color map from the altair scale object
grp_map_unfilt = dict(zip(global_color_group.domain, sns.color_palette(global_color_group.scheme.capitalize())))
# Create the palette list in the order of the unique groups found in the data
grp_pal_unfilt = [grp_map_unfilt[group] for group in grp_unfilt_u]

grp_map_unfilt = dict(zip(grp_unfilt_u, grp_pal_unfilt))
grp_cols_unfilt = pd.Series([grp_map_unfilt.get(group) for group in pheno_unfilt_idx['group']], index=pheno_unfilt_idx.index, name='group')

row_colors_df = pd.DataFrame({"": cyc_cols_unfilt, " ": grp_cols_unfilt}, index=corr_mat_unfilt.index)

g_unfilt = sns.clustermap(
  corr_mat_unfilt.fillna(0), col_colors=row_colors_df, method="complete",
  cmap="magma", vmin=0, vmax=1, figsize=(6, 8), cbar_pos=(0.85, .82, .02, .16),
  xticklabels=True, yticklabels=False, dendrogram_ratio=(0, .25)
)

# Reduce the size of x-axis tick labels
g_unfilt.ax_heatmap.set_xticklabels(g_unfilt.ax_heatmap.get_xmajorticklabels(), fontsize = 7)
g_unfilt.ax_heatmap.set_yticklabels(g_unfilt.ax_heatmap.get_ymajorticklabels(), fontsize = 7)

cyc_handles = [mpatches.Patch(color=cyc_map_unfilt[name], label=name) for name in cyc_unfilt_u]
g_unfilt.fig.legend(handles=cyc_handles, title='Cycle Phase', bbox_to_anchor=(.8, .98), loc='upper right', borderaxespad=0.)
grp_handles = [mpatches.Patch(color=grp_map_unfilt[name], label=name) for name in grp_unfilt_u]
g_unfilt.fig.legend(handles=grp_handles, title='Sample Group', bbox_to_anchor=(.6, .98), loc='upper right', borderaxespad=0.)
g_unfilt.fig.suptitle("Correlation Heatmap of Unfiltered Samples (Spearman)", y=1.02)
plt.savefig(fig_loc / "fig_s1a.svg", bbox_inches='tight', dpi=300)  # Save the plot as SVG with high resolution
plt.show()
```

### Correlation plot of the raw reads {.unnumbered .unlisted}

```{python}
corr_mat = ccht_uf_tpm.corr(method='spearman')
pheno = ccht_uf_pheno.query("samplename in @corr_mat.index")

cyc = pheno['cyclephase'].dropna().unique().tolist()
cyc_map = dict(zip(global_color_phase.domain, sns.color_palette(global_color_phase.range)))
cyc_cols = pd.Series([cyc_map.get(phase) for phase in pheno['cyclephase']], index=pheno.index, name='cyclephase')

grp = pheno['group'].dropna().unique().tolist()
grp_map = dict(zip(global_color_group.domain, sns.color_palette(global_color_group.scheme.capitalize())))
grp_cols = pd.Series([grp_map.get(group) for group in pheno['group']], index=pheno.index, name='group')

row_colors_df = pd.DataFrame({"": cyc_cols, " ": grp_cols}, index=corr_mat.index)

g = sns.clustermap(
  corr_mat.fillna(0), col_colors=row_colors_df, method="complete",
  cmap="magma", vmin=0, vmax=1, figsize=(6,8), cbar_pos=(0.85, .82, .02, .16),
  xticklabels=True, yticklabels=False, dendrogram_ratio=(0, .25)
)

# Reduce the size of x-axis tick labels
g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xmajorticklabels(), fontsize = 7)
g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_ymajorticklabels(), fontsize = 7)

cyc_handles = [mpatches.Patch(color=cyc_map[name], label=name) for name in cyc]
g.fig.legend(handles=cyc_handles, title='Cycle Phase', bbox_to_anchor=(.8, .98), loc='upper right', borderaxespad=0.)
grp_handles = [mpatches.Patch(color=grp_map[name], label=name) for name in grp]
g.fig.legend(handles=grp_handles, title='Sample Group', bbox_to_anchor=(.6, .98), loc='upper right', borderaxespad=0.)
g.fig.suptitle("Correlation Heatmap of TPM counts (Spearman)", y=1.02)
```

### Featurecounts plot too for unfiltered groups {.unnumbered .unlisted}

```{python}
# Calculate total counts for each biotype across all samples
biotype_counts = features_ev.sum().sort_values(ascending=False)

# Get the top 10 biotypes
top_biotypes = biotype_counts.head(10).index.tolist()

# Calculate total counts per sample for the selected top_biotypes (denominator for percentage)
sample_totals_top_biotypes = features_ev[top_biotypes].sum(axis=1)

# Melt the DataFrame for plotting, including only the top biotypes
df_melted = (
  features_ev
  .reset_index()
  .pipe(lambda df: df[df['samplename'].str.contains("S\\d+", na=False)])
  .melt(id_vars=['samplename'], value_vars=top_biotypes, var_name='biotype', value_name='count')
)

# Calculate percentage relative to the sum of these top_biotypes for that sample
df_melted['percentage'] = df_melted.apply(
  lambda row: (row['count'] / sample_totals_top_biotypes[row['samplename']])
  if sample_totals_top_biotypes[row['samplename']] > 0 else 0,
  axis=1
)

# Sort samples by the percentage of "protein_coding" if it's in top_biotypes
# If not, sample_order will be empty, and Altair will use default order.
protein_coding_percentages = df_melted[df_melted['biotype'] == 'protein_coding'].set_index('samplename')['percentage']
sample_order = protein_coding_percentages.sort_values(ascending=False).index.tolist()

# --- Plotting logic starts here ---
biotype_prop = alt.Chart(df_melted).mark_bar(clip=True).encode(
  x=alt.X('samplename:N', title='Sample', sort=sample_order, axis=alt.Axis(labelAngle=-45)), # Swapped from y, added labelAngle
  y=alt.Y('percentage:Q', title='Percentage (%)', scale=alt.Scale(domain=(.8, 1)), axis=alt.Axis(format='%')), # Swapped from x
  color=alt.Color('biotype:N', title='Biotype', sort=top_biotypes, scale=alt.Scale(scheme='tableau10')),
  order=alt.Order('color_biotype_sort_index:N') # sort by the color fields
).properties(
  width=alt.Step(12), # Adjust bar width by setting step, now applied to width
  height=100, # Was width, now height
  title="Biotype Proportions per Sample (Unfiltered, Top 10 Biotypes)"
)

biotype_prop.save(fig_loc / "fig_s1c.svg", scale_factor=5)  # Save the plot as SVG with high resolution
biotype_prop.interactive()
```

### Qualimap read type plot for unfiltered groups {.unnumbered .unlisted}

```{python}
# Select relevant columns and samples
cols_to_plot = ["reads_aligned_exonic", "reads_aligned_intronic", "reads_aligned_intergenic"]
plot_data = qualimap_ev.reset_index().rename(columns={"index": "samplename"})
plot_data = plot_data[plot_data['samplename'].str.contains("S\\d+", na=False)][["samplename"] + cols_to_plot].copy()

# Calculate total reads for percentage calculation
plot_data['total_reads'] = plot_data[cols_to_plot].sum(axis=1)

# Calculate percentages
for col in cols_to_plot:
  plot_data[col + '_perc'] = (plot_data[col] / plot_data['total_reads'])

# Determine sort order based on intronic reads percentage BEFORE melting
sample_order = (
  plot_data
  .sort_values('reads_aligned_intronic_perc', ascending=False)['samplename']
  .tolist()
)

# Melt the DataFrame for Altair
plot_data_melted = plot_data.melt(
  id_vars=['samplename'],
  value_vars=[col + '_perc' for col in cols_to_plot],
  var_name='read_type',
  value_name='percentage'
)

# Clean up read_type names
plot_data_melted['read_type'] = plot_data_melted['read_type'].str.replace('reads_aligned_', '').str.replace('_perc', '')

# Create the Altair plot
qualimap_plot = alt.Chart(plot_data_melted).mark_bar().encode(
  x=alt.X('samplename:N', title='Sample', sort=sample_order, axis=alt.Axis(labelAngle=-45)),
  y=alt.Y('percentage:Q', axis=alt.Axis(format='%', title='Percentage of Reads'), stack='normalize'),
  color=alt.Color('read_type:N', title='Read Type', scale=alt.Scale(scheme='category10')),
  order=alt.Order(field='read_type', type='nominal'), # Ensures consistent stacking order
  tooltip=['samplename', 'read_type', alt.Tooltip('percentage:Q', format='.2%')]
).properties(
  title='Read Alignment Distribution (Exonic, Intronic, Intergenic)',
  width=alt.Step(12), # Adjust bar width for each sample
  height=100 # Overall height of the plot
)

# Add a rule (line) at y=85%
rule = alt.Chart(pd.DataFrame({'percentage': [0.85]})).mark_rule(strokeDash=[5, 5], color='red', strokeWidth=3).encode(
  y=alt.Y('percentage:Q') # Rule is now horizontal
)

qualimap_plot = (qualimap_plot + rule)
qualimap_plot.save(fig_loc / "fig_s1b.svg", scale_factor=5)  # Save the plot as SVG with high resolution
qualimap_plot.interactive()
```

:::

Lower half of supp. fig. 1

```{python}
supp_1 = (
  (biotype_prop & qualimap_plot).resolve_scale(color="independent", y="independent", x="independent") |
    (umap_plot_unfilt & umap_plot).resolve_scale( x="independent", y="independent") 
  ).resolve_scale(
    x="independent", y="independent", color="independent", shape="independent"
    )

supp_1.interactive()
```