---
title: "Single cell perspective into Extracellular Vesicules projected onto Spatial Transcriptomics"
format:
  html:
    code-fold: true
    code-tools: true
    embed-resources: true
    self-contained-math: true
jupyter: python3
---

# Load in data

Set up the environment and load the deps:

```{python}
#| output: false

import re
import pandas as pd
pd.set_option('display.max_columns', 100)
import scanpy as sc
import omicverse as ov
import anndata as an
import numpy as np
import seaborn as sns
import plotly.express as px
import seaborn.objects as so
import matplotlib.pyplot as plt
from pathlib import Path
from os import getenv
from dotenv import load_dotenv
from scipy.sparse import csr_matrix
from scipy.stats import ttest_ind
from scipy.stats import spearmanr
from scipy.stats import f_oneway
from scipy.stats import tukey_hsd
from statsmodels.stats.multicomp import pairwise_tukeyhsd
from sklearn.decomposition import PCA
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
from matplotlib.gridspec import GridSpec
from matplotlib.patches import Patch

## Do you want to rerun all the models?
rerun_all = True

## load the environment variables from the .env file
load_dotenv()
if getenv("DATA_FOLDER") is None:
  load_dotenv(Path.cwd() / ".env")

anndata_folder = getenv("ANNDATA_FOLDER")
atlas_folder = getenv("ATLAS_FOLDER")
data_folder = getenv("DATA_FOLDER")
st_folder = getenv("ST_FOLDER")
model_folder = Path(data_folder).expanduser() / "saved_models"
raw_data_folder = getenv("RAW_DATA_FOLDER")


# some prelims for data standardisation
replace_dict = {
  "Proliferative Early": "EP",
  "Proliferative Late": "LP",
  "Secretory Early": "ES",
  "Secretory Mid": "MS",
  "Secretory Late": "LS",
  "Secretory Early-Mid": "MS",
  # "Secretory": "Secretory Mid",
  "Mid-Secretory": "MS",
  "Proliferative Disordered": "EP"
}

replace_immu = {
  "Lymphatic": ["uNK1", "uNK1_cycling", "uNK2", "uNK3", "ILC3", "Peripheral_lymphocyte", "Lymphatic", "Immune_Lymphoid"],
  "Myeloid": ["eM1", "eM2", "cDC1", "cDC2", "pDC", "Monocyte", "Immune_Myeloid"],
  "B-cells": ["B_cell", "Plasma_B_cell"],
  "T-cells": ["T_Reg", "T_cell_CD8", "T_cell_CD4", "T_cell_cycling"]
}
inv_replace_immu = {value: key for key, values in replace_immu.items() for value in values}

```

Load in the data, filter out "Hormones" celltypes and non-endometriotic samples and finally do some preprocessing:

```{python}
#| output: false

## load in the modified HECA atlas
snapshot_an_loc = Path(data_folder).expanduser() / "sc_deconv_snapshot.h5ad"
sc_dat = an.read_h5ad(snapshot_an_loc)

## load in the EV CCHT only data and drop the "none" gene id in the end
ccht_uf_raw = pd.read_feather(Path(data_folder).expanduser() / "filtered" / "annot_raw.feather").set_index("gene_id").iloc[:-1]
ccht_uf_pheno = pd.read_table(Path(data_folder).expanduser() / "filtered" / "phenotype.tsv").set_index("samplename")
## Filter out some samples that are not behaving very well...
terminator = ["HUT26_UF", "HUT26_biopsy"]
ccht_uf_pheno = ccht_uf_pheno.query("samplename not in @terminator")
ccht_uf_raw = ccht_uf_raw.drop(columns=terminator)

```

Load in the spatial slides experiments

```{python}

slides_path = Path(st_folder).expanduser()
vis_dats = {}
for vis_fold in slides_path.iterdir():
  if vis_fold.is_dir():
    slide_id = vis_fold.stem
    print("Working on slide " + str(slide_id))
    vis_dat = sc.read_visium(path=vis_fold) # for vento data
    # vis_dat = sc.read_visium(path=vis_fold / "outs") # for inhouse data
    vis_dat.var_names_make_unique()
    vis_dat.var["mt"] = vis_dat.var_names.str.startswith("MT-")
    sc.pp.calculate_qc_metrics(vis_dat, qc_vars=["mt"], inplace=True)

    vis_dat = vis_dat[:, vis_dat.var['total_counts'] > 100]
    vis_dat = ov.pp.preprocess(vis_dat, mode='shiftlog|pearson', n_HVGs=3000, target_sum=1e4)
    ## new recommended preproc - does not work
    # vis_dat = ov.space.svg(vis_dat, mode="prost", n_svgs=3000, target_sum=1e4, platform="visium")
    vis_dat.raw = vis_dat
    vis_dat = vis_dat[:, vis_dat.var.highly_variable_features]
    vis_dats[slide_id] = vis_dat

# set the exemplary sample to use for downstream tasks
example_sample = "152807" # "E184-1_bottom"
vis_keys = list(vis_dats.keys())

```

# Bulk deconvolution and projection onto single cells

We'd be interested in using scRNA-seq atlas to deconvolve the EV data. This helps us understand where are those EV produced and which tissue signal they are capturing. To run single cell and projection, we are gonna use [TAPE](https://www.nature.com/articles/s41467-022-34550-9) algorithm. This algorithm also enables us to use the trained VAE model to estimate the number and the distribution of original cell populations.

First we'll need to reformat the raw bulk RNA samples from EV to matrix form and prepare some plotting functions.

```{python}
#| output: false

model_params = {
  "celltype_key": "celltype",
  "top_marker_num": 150,
  "max_single_cells": round(len(sc_dat.obs.index) / 8),
  # "max_single_cells": 8000, # increase the single cell count for sampling
  "ratio_num": 1, # might solve some of the artifact problems
  "gpu": 0
}

frac_params = {
  "batch_size": 512,
  "epochs": 1000, # looking at loss plot then 500 seems to be already enough, and we don't need the fractions really
  "scaler": "ss", # seems to harmonise distributions better
  "method": "tape",
  "mode": "high-resolution"
}

vae_params = {
  "batch_size": 512,
  "hidden_size": 256,
  "epoch_num": 100 # looking at loss plot then 500 seems to be already enough
}

```

Train the model on the single cell reference data and generate the pseudo-single-cell data from the bulk samples. Here we divide the original dataset into "biopsy" and "EV" groups, which then summarises all of the corresponding sampling method samples into one representative group. This would also increase the confidence of cell profiles while normalising individual variance.

::: {.panel-tabset}

## EV group

```{python}

gen_sc_file = Path(anndata_folder).expanduser() / "gen_sc_ev.h5ad"
if gen_sc_file.exists() and not rerun_all:
  gen_ccht_ev = sc.read_h5ad(gen_sc_file, backed="r").to_memory()
else:
  model_obj = ov.bulk2single.Bulk2Single(
    bulk_data=ccht_uf_raw[ccht_uf_pheno.query("group=='UF'").index],
    single_data=sc_dat.to_memory(),
    **model_params
  )
  # you have to run this to set the model_obj.cell_target_sum
  # and not run the single_preprocess_lazy() as it seems to override cell_num attribute and does needless normalisation
  _ = model_obj.predicted_fraction(**frac_params)
  model_obj.bulk_preprocess_lazy()
  model_obj.train(
    vae_save_dir=Path(model_folder).expanduser() / "pseudosc_model",
    vae_save_name="pseudosc_ev",
    generate_save_dir=Path(model_folder).expanduser() / "pseudosc_gen",
    generate_save_name="pseudosc_ev_gen",
    **vae_params
    )
  gen_ccht_ev = model_obj.generate()
  gen_ccht_ev.obs = (
    gen_ccht_ev.obs
    .join(
      sc_dat.obs[["celltype", "lineage"]].drop_duplicates(keep="first").set_index("celltype"),
      on="celltype"
    )
    # and now fix the join bc pandas does not seem to understand what "left join" means
    .reset_index(names="barcodes")
    .drop_duplicates(subset="barcodes", keep="first")
  ).set_index("barcodes")
  gen_ccht_ev.write(gen_sc_file)
  del model_obj

```

The generated dataset is then preprocessed, scaled, embedded into lower dimensions and clustered via Leiden. The visualisation is done using celltype annotation from HECA

```{python}

gen_ccht_ev = ov.pp.preprocess(gen_ccht_ev, mode="shiftlog|pearson", n_HVGs=2000)
ov.pp.scale(gen_ccht_ev)
ov.pp.pca(gen_ccht_ev, layer='scaled', n_pcs=50)

gen_ccht_ev.obsm['X_pca']=gen_ccht_ev.obsm['scaled|original|X_pca']
ov.pl.embedding(
  gen_ccht_ev,
  basis='X_pca',
  color='celltype',
  frameon='small'
)

ov.pp.neighbors(
  gen_ccht_ev,
  n_neighbors=15,
  n_pcs=50,
  use_rep='scaled|original|X_pca'
)

ov.pp.umap(gen_ccht_ev)

ov.pl.embedding(
  gen_ccht_ev,
  basis='X_umap',
  color='celltype',
  frameon='small'
)

ov.pl.embedding(
  gen_ccht_ev,
  basis='X_umap',
  color='lineage',
  frameon='small'
)

```

## Biopsy group

```{python}

gen_sc_file = Path(anndata_folder).expanduser() / "gen_sc_biopsy.h5ad"
if gen_sc_file.exists() and not rerun_all:
  gen_ccht_bio = sc.read_h5ad(gen_sc_file, backed="r").to_memory()
else:
  model_obj = ov.bulk2single.Bulk2Single(
    bulk_data=ccht_uf_raw[ccht_uf_pheno.query("group=='biopsy'").index],
    single_data=sc_dat.to_memory(),
    **model_params
  )
  _ = model_obj.predicted_fraction(**frac_params) # you have to run this to set the model_obj.cell_target_sum
  model_obj.bulk_preprocess_lazy()
  model_obj.train(
    vae_save_dir=Path(model_folder).expanduser() / "pseudosc_model",
    vae_save_name="pseudosc_bio",
    generate_save_dir=Path(model_folder).expanduser() / "pseudosc_gen",
    generate_save_name="pseudosc_bio_gen",
    **vae_params
    )
  gen_ccht_bio = model_obj.generate()
  gen_ccht_bio.obs = (
    gen_ccht_bio.obs
    .join(
      sc_dat.obs[["celltype", "lineage"]].drop_duplicates(keep="first").set_index("celltype"),
      on="celltype"
    )
    # and now fix the join bc pandas does not seem to understand what "left join" means
    .reset_index(names="barcodes")
    .drop_duplicates(subset="barcodes", keep="first")
  ).set_index("barcodes")
  gen_ccht_bio.write(gen_sc_file)
  del model_obj

```

The generated dataset is then preprocessed, scaled, embedded into lower dimensions and clustered via Leiden.

```{python}

gen_ccht_bio = ov.pp.preprocess(gen_ccht_bio, mode="shiftlog|pearson", n_HVGs=2000)
ov.pp.scale(gen_ccht_bio)
ov.pp.pca(gen_ccht_bio, layer='scaled', n_pcs=50)

gen_ccht_bio.obsm['X_pca'] = gen_ccht_bio.obsm['scaled|original|X_pca']
ov.pl.embedding(
  gen_ccht_bio,
  basis='X_pca',
  color='celltype',
  frameon='small'
)

ov.pp.neighbors(
  gen_ccht_bio,
  n_neighbors=15,
  n_pcs=50,
  use_rep='scaled|original|X_pca'
)

ov.pp.umap(gen_ccht_bio)

ov.pl.embedding(
  gen_ccht_bio,
  basis='X_umap',
  color='celltype',
  frameon='small'
)

ov.pl.embedding(
  gen_ccht_bio,
  basis='X_umap',
  color='lineage',
  frameon='small'
)

```

:::


# Projection of generated counts to Spatial Transcriptomic slides

And now use the generated pseudo-single-cell dataset and project it to the spatial transcriptomic slide.

```{python}
sc.pl.spatial(
  vis_dats[example_sample].to_memory(),
  color=[None, "log1p_total_counts"],
  ncols=2
  )
```

## Tangram + cell2location

Next, we try out the classical spatial deconvolution method `Tangram` to integrate the Visium slide and the generated scRNA-seq dataset. Then, we apply `cell2location` to perform spatial deconvoluion. The benefit of this approach is that it is less computationally heavy and we are not anymore limited by GPU VRAM, while being still performing on par with previous methods.

```{python}

def plotter_spat(gen_data, vis_data, ct_group):
  cts = ( # avoid some errors from celltypes having same name as genes
    gen_data.obs
    .query("(lineage==@ct_group) & celltype not in @vis_data.var.index & celltype in @vis_data.obs.columns")
    .celltype
    .unique()
  )
  sc.pl.spatial(
    vis_data,
    cmap='magma',
    color=cts,
    ncols=3, size=1.3,
    img_key='hires',
    # limit color scale at 99% quantile of cell abundance
    vmin=0, vmax='p95'
  )
  
```

::: {.panel-tabset}

## EV group

```{python}

gen_st_file = Path(anndata_folder).expanduser() / "c2l_st_ev.h5ad"
if gen_st_file.exists() and not rerun_all:
  vis_dat_proj = sc.read_h5ad(gen_st_file, backed="r").to_memory()
else:
  model_obj = ov.space.Tangram(
    gen_ccht_ev.to_memory(),
    vis_dats[example_sample].to_memory(),
    clusters="celltype"
  )
  model_obj.train(mode="cells", num_epochs=500, device="cuda:0")
  vis_dat_proj = model_obj.cell2location()
  vis_dat_proj.write(gen_st_file)
  del model_obj

```

Visualise the results

::: {.panel-tabset}

### Mesenchymal 
```{python}
plotter_spat(gen_ccht_ev, vis_dat_proj, "Mesenchymal")
```

### Endothelial
```{python}
plotter_spat(gen_ccht_ev, vis_dat_proj, "Endothelial")
```

### Epithelial
```{python}
plotter_spat(gen_ccht_ev, vis_dat_proj, "Epithelial")
```

### Immune
```{python}
plotter_spat(gen_ccht_ev, vis_dat_proj, "Immune")
```

:::

## Biopsy group

```{python}

gen_st_file = Path(anndata_folder).expanduser() / "c2l_st_bio.h5ad"
gen_ccht_bio = gen_ccht_bio[gen_ccht_bio.obs.query("celltype not in @gen_ccht_bio.var.index & celltype not in ['ILC3']").index, :]
if gen_st_file.exists() and not rerun_all:
  vis_dat_proj = sc.read_h5ad(gen_st_file, backed="r").to_memory()
else:
  model_obj = ov.space.Tangram(
    gen_ccht_bio.to_memory(),
    vis_dats[example_sample].to_memory(),
    clusters="celltype"
  )
  model_obj.train(mode="cells", num_epochs=500, device="cuda:0")
  vis_dat_proj = model_obj.cell2location()
  vis_dat_proj.write(gen_st_file)
  del model_obj

```

Visualise the results

::: {.panel-tabset}

### Mesenchymal
```{python}
plotter_spat(gen_ccht_bio, vis_dat_proj, "Mesenchymal")
```

### Endothelial
```{python}
plotter_spat(gen_ccht_bio, vis_dat_proj, "Endothelial")
```

### Epithelial
```{python}
plotter_spat(gen_ccht_bio, vis_dat_proj, "Epithelial")
```

### Immune
```{python}
plotter_spat(gen_ccht_bio, vis_dat_proj, "Immune")
```

:::

:::
